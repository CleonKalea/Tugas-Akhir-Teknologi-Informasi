{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/STAGE 4 FINAL MERGED DATA/STAGE_4_MERGED_FINAL_ENCODED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "klasifikasi_perkara_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "penuntut_umum_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hakim_encoded",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "jumlah_saksi",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "maks_penjara_berdasarkan_pasal",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "terdakwa",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summarized_dakwaan",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total_pidana_penjara_bulan",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4dac845a-80a9-40a8-8f6b-02bed4b6f36d",
       "rows": [
        [
         "0",
         "0",
         "0",
         "0",
         "6",
         "80",
         "GEDE DARMAYASA",
         "Terdakwa Gede Darmayasa didakwa telah melakukan tindak pidana pencurian buah durian di tiga lokasi berbeda di wilayah Kintamani, Kabupaten Bangli, pada bulan Mei 2024. Pada hari Selasa, 21 Mei 2024, sekitar pukul 06.00 hingga 06.30 WITA, terdakwa mencuri sebanyak 37 buah durian dari kebun milik I Wayan Sukerena, SE dan 27 buah durian dari kebun milik I Nyoman Susila. Durian-durian tersebut kemudian dijual sebagian kepada saksi Komang Ayu Anggreni dengan harga Rp4.316.000 dan sisanya dibawa pulang. Selanjutnya, pada hari Kamis, 23 Mei 2024, terdakwa menjual lagi 40 buah durian kepada Komang Sujana, di mana 24 di antaranya merupakan hasil pencurian. Kemudian pada hari Sabtu, 25 Mei 2024, sekitar pukul 06.00 WITA, terdakwa kembali melakukan pencurian sebanyak 20 buah durian dari kebun milik I Ketut Tindih dan menjual 15 buah di antaranya seharga Rp1.485.000. Total durian yang dicuri terdakwa berjumlah 67 buah tanpa seizin pemiliknya, dengan maksud untuk dimiliki secara melawan hukum dan hasil penjualannya digunakan untuk kebutuhan sehari-hari. Akibat perbuatan terdakwa, I Wayan Sukerena mengalami kerugian sebesar Rp3.330.000, I Ketut Tindih sebesar Rp3.500.000, dan I Nyoman Susila sebesar Rp2.000.000. Perbuatan terdakwa diancam pidana berdasarkan Pasal 362 KUHP jo. Pasal 65 Ayat (1) KUHP.",
         "5.0"
        ],
        [
         "1",
         "1",
         "1",
         "1",
         "4",
         "48",
         "IDA BAGUS MADE DARMA WIGUNA",
         "Pada bulan Februari dan Maret 2024, terdakwa Ida Bagus Made Darma Wiguna alias Gus Manik didakwa melakukan tindak pidana penggelapan secara berlanjut terhadap saksi korban Ni Wayan Anik Artini. Berawal dari perkenalan melalui media sosial TikTok pada Desember 2023, terdakwa dan korban menjalin hubungan hingga pada 13 Februari 2024 korban menyerahkan perhiasan kalung emas 21 karat seberat 24,55 gram untuk disimpan di rumah terdakwa. Pada 17 Februari 2024, terdakwa meminjam kalung tersebut untuk digadaikan dengan janji akan menebusnya dalam dua hari. Kalung itu kemudian digadaikan di Kantor Pegadaian Bangli seharga Rp 8.000.000. Namun, tanpa seizin korban, pada 21 Februari 2024 terdakwa kembali ke Pegadaian dan menambah nilai gadai menjadi Rp 19.600.000, menerima pencairan tambahan sebesar Rp 11.397.000, yang seluruhnya digunakan untuk keperluan pribadi. Kemudian, pada 10 Maret 2024, terdakwa meminjam ponsel Samsung Galaxy A04E milik korban dengan alasan untuk komunikasi, namun ponsel tersebut dijual seharga Rp 600.000 dan hasilnya juga dipakai untuk kebutuhan sehari-hari. Meskipun korban telah beberapa kali meminta barang-barangnya dikembalikan, terdakwa selalu mengelak dengan berbagai alasan. Akibat perbuatan terdakwa, korban mengalami kerugian sebesar Rp 26.000.000. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 372 jo. 64 Ayat (1) KUHP, dan dakwaan subsidair Pasal 378 jo. 64 Ayat (1) KUHP.",
         "24.0"
        ],
        [
         "2",
         "0",
         "0",
         "2",
         "6",
         "84",
         "HANDRI JOHANAS",
         "Terdakwa Handri Johanes pada Rabu, 24 April 2024 sekitar pukul 03.00 WITA di sebuah kamar di Puri Kanginan, Lingkungan Banjar Puri Kanginan No. 2 Bangli, telah melakukan pencurian satu unit handphone OPPO A53 warna hitam milik I Nengah Sukadana. Kejadian bermula ketika terdakwa yang sebelumnya pernah bekerja di mebel milik Gung Aji Kartika dan terbiasa keluar masuk area puri, datang mencari temannya yang dahulu tinggal di sana. Setelah tidak menemukan temannya dan hendak pulang, terdakwa melihat sebuah handphone sedang diisi daya dalam kamar yang pintunya sedikit terbuka. Ia kemudian mengambil handphone tersebut dengan memasukkan tangan melalui celah pintu. Setelah sampai di bengkel tempat tinggalnya, terdakwa mengetahui bahwa handphone tersebut terkunci, lalu beberapa hari kemudian menjualnya kepada seseorang bernama Denny Firmansyah di Klungkung seharga Rp300.000. Uang hasil penjualan itu kemudian ia kirim ke anaknya di Lombok. Akibat perbuatan tersebut, saksi I Nengah Sukadana mengalami kerugian sebesar Rp3.999.000. Perbuatan terdakwa diancam pidana berdasarkan Pasal 363 Ayat (1) ke-3 KUHP.",
         "4.0"
        ],
        [
         "3",
         "2",
         "2",
         "1",
         "2",
         "144",
         "I GEDE ARIADI alias BERNAD",
         "Pada hari Minggu, 14 April 2024 sekitar pukul 16.35 WITA, terdakwa I Gede Ariadi alias Bernad ditangkap di Jl. Brigjen Ngurah Rai, Kelurahan Kawan, Bangli oleh tim Opsnal Satresnarkoba Polres Bangli karena kedapatan membawa narkotika jenis sabu. Kronologi bermula pada 9 April 2024 saat terdakwa berkenalan dengan seseorang bernama Kadek (DPO) melalui Facebook, lalu berkomunikasi intens melalui WhatsApp dan sepakat untuk menggunakan sabu bersama. Pada 14 April 2024 pagi, terdakwa diberi tahu oleh Mang Donal (DPO) bahwa sabu sudah tersedia dan ditempel di bawah tiang listrik di daerah Bendul, Klungkung. Terdakwa mengambil sabu yang dibungkus dalam tabung micro tube dan menyimpannya di tas selempang. Sore harinya, terdakwa berangkat menuju Bangli sesuai petunjuk lokasi dari Kadek. Setibanya di lokasi, terdakwa diamankan polisi dan saat digeledah ditemukan satu plastik klip berisi kristal sabu seberat 0,20 gram netto beserta barang bukti lainnya seperti handphone dan sepeda motor. Berdasarkan hasil uji laboratorium, kristal tersebut positif mengandung Metamfetamina yang tergolong Narkotika Golongan I. Terdakwa tidak memiliki izin dari Menteri Kesehatan atau instansi terkait untuk memiliki narkotika tersebut. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 112 Ayat (1) UU RI No. 35 Tahun 2009 tentang Narkotika, dan dakwaan subsidair Pasal 127 Ayat (1) huruf a Undang-Undang RI No. 35 Tahun 2009 Tentang Narkotika.",
         "14.0"
        ],
        [
         "4",
         "2",
         "3",
         "1",
         "2",
         "144",
         "I GEDE ARIADI alias BERNAD",
         "Pada hari Minggu, 14 April 2024 sekitar pukul 16.35 WITA, terdakwa I Gede Ariadi alias Bernad ditangkap di Jl. Brigjen Ngurah Rai, Kelurahan Kawan, Bangli oleh tim Opsnal Satresnarkoba Polres Bangli karena kedapatan membawa narkotika jenis sabu. Kronologi bermula pada 9 April 2024 saat terdakwa berkenalan dengan seseorang bernama Kadek (DPO) melalui Facebook, lalu berkomunikasi intens melalui WhatsApp dan sepakat untuk menggunakan sabu bersama. Pada 14 April 2024 pagi, terdakwa diberi tahu oleh Mang Donal (DPO) bahwa sabu sudah tersedia dan ditempel di bawah tiang listrik di daerah Bendul, Klungkung. Terdakwa mengambil sabu yang dibungkus dalam tabung micro tube dan menyimpannya di tas selempang. Sore harinya, terdakwa berangkat menuju Bangli sesuai petunjuk lokasi dari Kadek. Setibanya di lokasi, terdakwa diamankan polisi dan saat digeledah ditemukan satu plastik klip berisi kristal sabu seberat 0,20 gram netto beserta barang bukti lainnya seperti handphone dan sepeda motor. Berdasarkan hasil uji laboratorium, kristal tersebut positif mengandung Metamfetamina yang tergolong Narkotika Golongan I. Terdakwa tidak memiliki izin dari Menteri Kesehatan atau instansi terkait untuk memiliki narkotika tersebut. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 112 Ayat (1) UU RI No. 35 Tahun 2009 tentang Narkotika, dan dakwaan subsidair Pasal 127 Ayat (1) huruf a Undang-Undang RI No. 35 Tahun 2009 Tentang Narkotika.",
         "14.0"
        ],
        [
         "5",
         "0",
         "4",
         "1",
         "4",
         "60",
         "R. Sabirin",
         "Pada hari Selasa, 26 Maret 2024 sekitar pukul 17.10 WITA, bertempat di pinggir Jalan Raya Kintamani, Desa Kintamani, Kecamatan Kintamani, Kabupaten Bangli, Terdakwa melakukan pencurian dengan mengambil satu unit sepeda motor Honda Scoopy warna merah hitam DK 6384 PQ, yang sebagian atau seluruhnya milik orang lain, dengan maksud untuk dimiliki secara melawan hukum. Sebelumnya, pada 25 Maret 2024 pukul 13.00 WITA, Terdakwa berangkat dari Panarukan, Singaraja menuju Terminal Ubung Denpasar dengan menumpang truk, dengan tujuan mencuri sepeda motor. Tiba di Terminal Ubung sekitar pukul 14.30 WITA, Terdakwa menginap semalam karena hujan deras. Esok harinya, Terdakwa dijemput oleh temannya, WAHYU EKA JAYA (DPO), yang datang mengendarai sepeda motor Yamaha Vixion warna hitam. Mereka lalu pergi ke Kintamani untuk jalan-jalan. Sekitar pukul 17.10 WITA, mereka melihat sebuah motor Honda Scoopy terparkir di pinggir jalan dengan kunci masih tergantung. Setelah WAHYU EKA JAYA pergi meninggalkannya, Terdakwa mendekati motor tersebut, lalu mendorongnya sejauh sekitar 10 meter sebelum akhirnya menyalakan mesin dan melarikan diri menuju Denpasar melalui Payangan, Gianyar. Di daerah Ubud, Terdakwa dihentikan oleh seorang petugas Polsek Kintamani bernama I Gede Dipta Wirama Darma dan tidak dapat menunjukkan STNK kendaraan. Terdakwa kemudian diamankan beserta barang bukti ke Polsek Kintamani. Akibat perbuatan tersebut, korban, Ni Wayan Srimertanadi, mengalami kerugian sekitar Rp20.000.000\\. Perbuatan Terdakwa diatur dan diancam pidana dalam Pasal 362 KUHP.",
         "14.0"
        ],
        [
         "6",
         "2",
         "4",
         "1",
         "4",
         "144",
         "NOVANI ARI HIFNI Alias ARI",
         "Pada Minggu, 17 Maret 2024 sekitar pukul 18.10 WITA, terdakwa Novani Ari Hifni alias Ari ditangkap di pinggir Jalan Merdeka, Tamanbali, Bangli oleh petugas Satresnarkoba Polres Bangli karena kedapatan membawa narkotika jenis sabu. Sebelumnya, terdakwa menghubungi rekannya bernama Wewe (DPO) melalui Facebook untuk mencari sabu, kemudian diarahkan untuk menghubungi Rizal (DPO). Rizal menyanggupi permintaan terdakwa dengan sistem hutang dan mengirimkan lokasi pengambilan barang di Bangli. Terdakwa lalu mengajak temannya, saksi K. M. Sahrijal Jabar, untuk mengantarkan ke lokasi dengan imbalan uang. Setelah mengambil sabu yang disembunyikan di dekat tembok dengan berpura-pura buang air kecil, terdakwa melanjutkan perjalanan, namun akhirnya dihentikan dan diamankan oleh petugas. Saat digeledah, ditemukan satu plastik berisi sabu dalam botol Yakult serta peralatan hisap lainnya di dalam tas terdakwa, sementara pada saksi Sahrijal tidak ditemukan barang terlarang. Hasil pemeriksaan laboratorium terhadap kristal bening dan urine terdakwa menunjukkan keduanya positif mengandung metamfetamina, yang tergolong Narkotika Golongan I. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 112 Ayat (1) Undang-Undang RI No. 35 Tahun 2009 tentang Narkotika, dan dakwaan subsidair Pasal 127 Ayat (1) huruf a Undang-Undang RI No. 35 Tahun 2009 tentang Narkotika.",
         "24.0"
        ],
        [
         "7",
         "2",
         "5",
         "1",
         "4",
         "144",
         "NOVANI ARI HIFNI Alias ARI",
         "Pada Minggu, 17 Maret 2024 sekitar pukul 18.10 WITA, terdakwa Novani Ari Hifni alias Ari ditangkap di pinggir Jalan Merdeka, Tamanbali, Bangli oleh petugas Satresnarkoba Polres Bangli karena kedapatan membawa narkotika jenis sabu. Sebelumnya, terdakwa menghubungi rekannya bernama Wewe (DPO) melalui Facebook untuk mencari sabu, kemudian diarahkan untuk menghubungi Rizal (DPO). Rizal menyanggupi permintaan terdakwa dengan sistem hutang dan mengirimkan lokasi pengambilan barang di Bangli. Terdakwa lalu mengajak temannya, saksi K. M. Sahrijal Jabar, untuk mengantarkan ke lokasi dengan imbalan uang. Setelah mengambil sabu yang disembunyikan di dekat tembok dengan berpura-pura buang air kecil, terdakwa melanjutkan perjalanan, namun akhirnya dihentikan dan diamankan oleh petugas. Saat digeledah, ditemukan satu plastik berisi sabu dalam botol Yakult serta peralatan hisap lainnya di dalam tas terdakwa, sementara pada saksi Sahrijal tidak ditemukan barang terlarang. Hasil pemeriksaan laboratorium terhadap kristal bening dan urine terdakwa menunjukkan keduanya positif mengandung metamfetamina, yang tergolong Narkotika Golongan I. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 112 Ayat (1) Undang-Undang RI No. 35 Tahun 2009 tentang Narkotika, dan dakwaan subsidair Pasal 127 Ayat (1) huruf a Undang-Undang RI No. 35 Tahun 2009 tentang Narkotika.",
         "24.0"
        ],
        [
         "8",
         "2",
         "6",
         "1",
         "4",
         "240",
         "MULYADI alias MUL",
         "Pada Selasa, 9 Januari 2024 sekitar pukul 17.30 WITA di Jalan Bima, Kelurahan Cempaga, Bangli, terdakwa Mulyadi alias Mul ditangkap karena tanpa hak menawarkan dan membawa narkotika jenis sabu. Sebelumnya, terdakwa dihubungi oleh rekannya, Kadek (DPO), untuk mengantarkan sabu ke Bangli. Setelah bertemu dengan kurir Kadek di Lapangan Lumintang, Denpasar, terdakwa menerima sabu dalam amplop putih, sempat mencicipinya, dan menyimpannya di dashboard mobil lalu berpindah ke tas pinggang. Sekitar pukul 15.00 WITA, terdakwa berangkat ke Bangli dan tiba di lokasi yang diarahkan Kadek. Saat tiba di kos-kosan milik kakak Kadek, terdakwa diamankan oleh polisi. Dalam penggeledahan, ditemukan sabu, alat isap, korek api modifikasi, dan barang bukti lainnya. Berdasarkan hasil laboratorium, kristal yang disita terbukti mengandung metamfetamina yang termasuk Narkotika Golongan I, sedangkan urine terdakwa tidak mengandung narkotika. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 114 Ayat (1) UU RI No. 35 Tahun 2009 tentang Narkotika, dan dakwaan subsidair Pasal 112 Ayat (1) UU RI No. 35 tahun 2009 tentang Narkotika.",
         "51.0"
        ],
        [
         "9",
         "0",
         "7",
         "1",
         "6",
         "80",
         "I WAYAN ARTAYASA",
         "Terdakwa I Wayan Artayasa didakwa telah melakukan serangkaian pencurian secara berulang di Pasar Kidul Bangli, dengan sasaran utama dagangan milik ibunya sendiri, Ni Nyoman Suwini, serta milik pedagang lain seperti Ni Luh Utari dan Ni Ketut Suci. Perbuatan tersebut dilakukan sejak Desember 2023 hingga Februari 2024, pada dini hari antara pukul 03.00 hingga 04.00 WITA. Modus operandi yang digunakan adalah dengan masuk ke pasar melalui celah jeruji besi, membuka terpal dagangan, dan mengambil berbagai bahan pokok seperti kemiri, kacang tanah, gula merah, kacang hijau, dan beras. Barang-barang hasil curian tersebut kemudian dijual oleh terdakwa di Pasar Kidul Bangli dan Pasar Singamandawa Kintamani untuk memenuhi kebutuhan sehari-hari. Perbuatan terdakwa dilakukan tanpa seizin atau sepengetahuan para pemilik barang, dan telah menyebabkan kerugian bagi para korban. Berdasarkan perbuatannya tersebut, terdakwa didakwa dengan Pasal 362 KUHP jo. Pasal 65 Ayat (1) KUHP pada dakwaan primair dan Pasal 367 Ayat (2) KUHP jo. Pasal 65 Ayat (1) KUHP untuk dakwaan subsidair.",
         "12.0"
        ],
        [
         "10",
         "0",
         "4",
         "3",
         "4",
         "60",
         "RURY HERAWATI",
         "Terdakwa Rury Herawati pada tanggal 20 November 2023 sekitar pukul 15.15 WITA telah melakukan pencurian di Toko Ari Kebaya, Jalan Nusantara, Bangli. Terdakwa datang dari Denpasar dengan niat mencuri dan setelah mencari toko yang sepi, ia berpura-pura sebagai pembeli. Saat penjaga toko sedang membelakangi untuk mencarikan sandal, Terdakwa membuka lemari yang tidak terkunci dan mengambil tas kain berisi dua dompet dengan total uang Rp16.500.000,- milik saksi Ni Nengah Ngariasi. Setelah mengambil tas, Terdakwa berpura-pura hendak mengambil uang di ATM dan langsung pergi meninggalkan dua selendang yang sudah dibayar. Uang hasil pencurian digunakan untuk membeli berbagai barang seperti HP, emas, pakaian, serta kebutuhan sehari-hari. Sisa uang yang dicuri masih tersisa sebesar Rp5.778.000. Berdasarkan laporan polisi dan penyelidikan, Terdakwa mengakui perbuatannya dan kini telah diamankan bersama barang bukti untuk proses hukum lebih lanjut. Perbuatannya diancam pidana sesuai Pasal 362 KUHP.",
         "16.0"
        ],
        [
         "11",
         "3",
         "7",
         "1",
         "8",
         "48",
         "I KETUT SUPUTRA",
         "Bahwa para Terdakwa, yakni Terdakwa I Ketut Suputra dan Terdakwa II Ni Komang Warsiki, dalam kurun waktu antara bulan Mei 2019 sampai dengan Oktober 2020, bertempat di gudang milik para Terdakwa yang beralamat di Jalan Soekarno, Banjar Dukuh, Desa Bunutin, Kecamatan Bangli, Kabupaten Bangli, telah melakukan perbuatan melawan hukum dengan cara menguasai secara melawan hak barang titipan milik PT. Putra Dewata Sejati. Awalnya, Terdakwa I menjalin kerja sama usaha penjualan produk minuman bermerek Aqua dengan PT. Putra Dewata Sejati di bawah nama usaha UD. Sari Merta berdasarkan Surat Kesepakatan Nomor 002/SP/PDS-BALI/IV/2019 tanggal 6 April 2019. Dalam pelaksanaan kerja sama tersebut, PT. Putra Dewata Sejati menyerahkan sejumlah barang titipan kepada UD. Sari Merta untuk dijual kembali, dengan ketentuan bahwa harga pokok barang harus disetorkan kembali kepada PT. Putra Dewata Sejati setelah barang terjual, sedangkan selisih harga jual menjadi keuntungan bagi UD. Sari Merta. Dalam pelaksanaan usahanya, Terdakwa I selaku penanggung jawab operasional dan Terdakwa II sebagai bagian administrasi bertugas mengelola penjualan, keuangan, dan pembayaran kepada pihak supplier. Akan tetapi, sejak bulan Mei 2019, para Terdakwa mulai tidak menyetorkan secara penuh hasil penjualan barang, dan sejak bulan Oktober 2020 tidak lagi melakukan penyetoran sama sekali, padahal seluruh barang titipan telah terjual. Uang hasil penjualan tersebut justru digunakan oleh para Terdakwa untuk membayar gaji karyawan, menutupi biaya operasional, serta memenuhi kebutuhan hidup pribadi, tanpa seizin atau sepengetahuan PT. Putra Dewata Sejati. Perbuatan para Terdakwa tersebut telah mengakibatkan kerugian keuangan bagi PT. Putra Dewata Sejati sebesar Rp413.883.979,- (empat ratus tiga belas juta delapan ratus delapan puluh tiga ribu sembilan ratus tujuh puluh sembilan rupiah). Perbuatan tersebut dilakukan secara bersama-sama dan berlanjut, serta diatur dan diancam pidana dalam Pasal 372 KUHP jo. Pasal 55 Ayat (1) ke-1 KUHP jo. Pasal 64 Ayat (1) KUHP.",
         "18.0"
        ],
        [
         "12",
         "3",
         "5",
         "1",
         "8",
         "48",
         "I KETUT SUPUTRA",
         "Bahwa para Terdakwa, yakni Terdakwa I Ketut Suputra dan Terdakwa II Ni Komang Warsiki, dalam kurun waktu antara bulan Mei 2019 sampai dengan Oktober 2020, bertempat di gudang milik para Terdakwa yang beralamat di Jalan Soekarno, Banjar Dukuh, Desa Bunutin, Kecamatan Bangli, Kabupaten Bangli, telah melakukan perbuatan melawan hukum dengan cara menguasai secara melawan hak barang titipan milik PT. Putra Dewata Sejati. Awalnya, Terdakwa I menjalin kerja sama usaha penjualan produk minuman bermerek Aqua dengan PT. Putra Dewata Sejati di bawah nama usaha UD. Sari Merta berdasarkan Surat Kesepakatan Nomor 002/SP/PDS-BALI/IV/2019 tanggal 6 April 2019. Dalam pelaksanaan kerja sama tersebut, PT. Putra Dewata Sejati menyerahkan sejumlah barang titipan kepada UD. Sari Merta untuk dijual kembali, dengan ketentuan bahwa harga pokok barang harus disetorkan kembali kepada PT. Putra Dewata Sejati setelah barang terjual, sedangkan selisih harga jual menjadi keuntungan bagi UD. Sari Merta. Dalam pelaksanaan usahanya, Terdakwa I selaku penanggung jawab operasional dan Terdakwa II sebagai bagian administrasi bertugas mengelola penjualan, keuangan, dan pembayaran kepada pihak supplier. Akan tetapi, sejak bulan Mei 2019, para Terdakwa mulai tidak menyetorkan secara penuh hasil penjualan barang, dan sejak bulan Oktober 2020 tidak lagi melakukan penyetoran sama sekali, padahal seluruh barang titipan telah terjual. Uang hasil penjualan tersebut justru digunakan oleh para Terdakwa untuk membayar gaji karyawan, menutupi biaya operasional, serta memenuhi kebutuhan hidup pribadi, tanpa seizin atau sepengetahuan PT. Putra Dewata Sejati. Perbuatan para Terdakwa tersebut telah mengakibatkan kerugian keuangan bagi PT. Putra Dewata Sejati sebesar Rp413.883.979,- (empat ratus tiga belas juta delapan ratus delapan puluh tiga ribu sembilan ratus tujuh puluh sembilan rupiah). Perbuatan tersebut dilakukan secara bersama-sama dan berlanjut, serta diatur dan diancam pidana dalam Pasal 372 KUHP jo. Pasal 55 Ayat (1) ke-1 KUHP jo. Pasal 64 Ayat (1) KUHP.",
         "18.0"
        ],
        [
         "13",
         "3",
         "7",
         "1",
         "8",
         "48",
         "NI KOMANG WARSIKI",
         "Bahwa para Terdakwa, yakni Terdakwa I Ketut Suputra dan Terdakwa II Ni Komang Warsiki, dalam kurun waktu antara bulan Mei 2019 sampai dengan Oktober 2020, bertempat di gudang milik para Terdakwa yang beralamat di Jalan Soekarno, Banjar Dukuh, Desa Bunutin, Kecamatan Bangli, Kabupaten Bangli, telah melakukan perbuatan melawan hukum dengan cara menguasai secara melawan hak barang titipan milik PT. Putra Dewata Sejati. Awalnya, Terdakwa I menjalin kerja sama usaha penjualan produk minuman bermerek Aqua dengan PT. Putra Dewata Sejati di bawah nama usaha UD. Sari Merta berdasarkan Surat Kesepakatan Nomor 002/SP/PDS-BALI/IV/2019 tanggal 6 April 2019. Dalam pelaksanaan kerja sama tersebut, PT. Putra Dewata Sejati menyerahkan sejumlah barang titipan kepada UD. Sari Merta untuk dijual kembali, dengan ketentuan bahwa harga pokok barang harus disetorkan kembali kepada PT. Putra Dewata Sejati setelah barang terjual, sedangkan selisih harga jual menjadi keuntungan bagi UD. Sari Merta. Dalam pelaksanaan usahanya, Terdakwa I selaku penanggung jawab operasional dan Terdakwa II sebagai bagian administrasi bertugas mengelola penjualan, keuangan, dan pembayaran kepada pihak supplier. Akan tetapi, sejak bulan Mei 2019, para Terdakwa mulai tidak menyetorkan secara penuh hasil penjualan barang, dan sejak bulan Oktober 2020 tidak lagi melakukan penyetoran sama sekali, padahal seluruh barang titipan telah terjual. Uang hasil penjualan tersebut justru digunakan oleh para Terdakwa untuk membayar gaji karyawan, menutupi biaya operasional, serta memenuhi kebutuhan hidup pribadi, tanpa seizin atau sepengetahuan PT. Putra Dewata Sejati. Perbuatan para Terdakwa tersebut telah mengakibatkan kerugian keuangan bagi PT. Putra Dewata Sejati sebesar Rp413.883.979,- (empat ratus tiga belas juta delapan ratus delapan puluh tiga ribu sembilan ratus tujuh puluh sembilan rupiah). Perbuatan tersebut dilakukan secara bersama-sama dan berlanjut, serta diatur dan diancam pidana dalam Pasal 372 KUHP jo. Pasal 55 Ayat (1) ke-1 KUHP jo. Pasal 64 Ayat (1) KUHP.",
         "10.0"
        ],
        [
         "14",
         "3",
         "5",
         "1",
         "8",
         "48",
         "NI KOMANG WARSIKI",
         "Bahwa para Terdakwa, yakni Terdakwa I Ketut Suputra dan Terdakwa II Ni Komang Warsiki, dalam kurun waktu antara bulan Mei 2019 sampai dengan Oktober 2020, bertempat di gudang milik para Terdakwa yang beralamat di Jalan Soekarno, Banjar Dukuh, Desa Bunutin, Kecamatan Bangli, Kabupaten Bangli, telah melakukan perbuatan melawan hukum dengan cara menguasai secara melawan hak barang titipan milik PT. Putra Dewata Sejati. Awalnya, Terdakwa I menjalin kerja sama usaha penjualan produk minuman bermerek Aqua dengan PT. Putra Dewata Sejati di bawah nama usaha UD. Sari Merta berdasarkan Surat Kesepakatan Nomor 002/SP/PDS-BALI/IV/2019 tanggal 6 April 2019. Dalam pelaksanaan kerja sama tersebut, PT. Putra Dewata Sejati menyerahkan sejumlah barang titipan kepada UD. Sari Merta untuk dijual kembali, dengan ketentuan bahwa harga pokok barang harus disetorkan kembali kepada PT. Putra Dewata Sejati setelah barang terjual, sedangkan selisih harga jual menjadi keuntungan bagi UD. Sari Merta. Dalam pelaksanaan usahanya, Terdakwa I selaku penanggung jawab operasional dan Terdakwa II sebagai bagian administrasi bertugas mengelola penjualan, keuangan, dan pembayaran kepada pihak supplier. Akan tetapi, sejak bulan Mei 2019, para Terdakwa mulai tidak menyetorkan secara penuh hasil penjualan barang, dan sejak bulan Oktober 2020 tidak lagi melakukan penyetoran sama sekali, padahal seluruh barang titipan telah terjual. Uang hasil penjualan tersebut justru digunakan oleh para Terdakwa untuk membayar gaji karyawan, menutupi biaya operasional, serta memenuhi kebutuhan hidup pribadi, tanpa seizin atau sepengetahuan PT. Putra Dewata Sejati. Perbuatan para Terdakwa tersebut telah mengakibatkan kerugian keuangan bagi PT. Putra Dewata Sejati sebesar Rp413.883.979,- (empat ratus tiga belas juta delapan ratus delapan puluh tiga ribu sembilan ratus tujuh puluh sembilan rupiah). Perbuatan tersebut dilakukan secara bersama-sama dan berlanjut, serta diatur dan diancam pidana dalam Pasal 372 KUHP jo. Pasal 55 Ayat (1) ke-1 KUHP jo. Pasal 64 Ayat (1) KUHP.",
         "10.0"
        ],
        [
         "15",
         "0",
         "8",
         "0",
         "6",
         "144",
         "I KETUT JONI ADNYANA ADI PUTRA",
         "Terdakwa I Ketut Joni Adnyana Adi Putra dan Terdakwa II Rosita Evayanti Dewi melakukan pencurian sepeda motor di dua lokasi berbeda di wilayah Kintamani, Bangli. Aksi pertama dilakukan pada 10 September 2023 sekitar pukul 01.00 WITA di parkiran Sukawana Sunrise, di mana Terdakwa I mengambil sepeda motor Yamaha NMAX DK 3498 PT milik saksi Made Yusa Paramartha dengan cara mendorong motor yang tidak terkunci dan menyalakan mesin menggunakan alat-alat seperti obeng, tang, dan kunci L. Motor hasil curian ini digunakan untuk keperluan sehari-hari. Aksi kedua dilakukan pada 1 Oktober 2023 sekitar pukul 02.00 WITA di parkiran Le Monte Sunrise. Dengan menggunakan mobil sewaan, kedua terdakwa kembali ke Kintamani dan Terdakwa I mencuri motor Yamaha NMAX DK 6992 LB milik I Kadek Indrawan dengan modus serupa. Sepeda motor tersebut kemudian dijual secara daring seharga Rp5.300.000. Akibat perbuatan kedua terdakwa, saksi Made Yusa Paramartha mengalami kerugian sebesar Rp25.500.000,- dan saksi I Kadek Indrawan mengalami kerugian sebesar Rp26.700.000,-. Perbuatan para terdakwa diancam pidana berdasarkan Pasal 363 Ayat (1) ke-4 KUHP jo. Pasal 65 Ayat (1) KUHP.",
         "16.0"
        ],
        [
         "16",
         "0",
         "9",
         "0",
         "6",
         "144",
         "I KETUT JONI ADNYANA ADI PUTRA",
         "Terdakwa I Ketut Joni Adnyana Adi Putra dan Terdakwa II Rosita Evayanti Dewi melakukan pencurian sepeda motor di dua lokasi berbeda di wilayah Kintamani, Bangli. Aksi pertama dilakukan pada 10 September 2023 sekitar pukul 01.00 WITA di parkiran Sukawana Sunrise, di mana Terdakwa I mengambil sepeda motor Yamaha NMAX DK 3498 PT milik saksi Made Yusa Paramartha dengan cara mendorong motor yang tidak terkunci dan menyalakan mesin menggunakan alat-alat seperti obeng, tang, dan kunci L. Motor hasil curian ini digunakan untuk keperluan sehari-hari. Aksi kedua dilakukan pada 1 Oktober 2023 sekitar pukul 02.00 WITA di parkiran Le Monte Sunrise. Dengan menggunakan mobil sewaan, kedua terdakwa kembali ke Kintamani dan Terdakwa I mencuri motor Yamaha NMAX DK 6992 LB milik I Kadek Indrawan dengan modus serupa. Sepeda motor tersebut kemudian dijual secara daring seharga Rp5.300.000. Akibat perbuatan kedua terdakwa, saksi Made Yusa Paramartha mengalami kerugian sebesar Rp25.500.000,- dan saksi I Kadek Indrawan mengalami kerugian sebesar Rp26.700.000,-. Perbuatan para terdakwa diancam pidana berdasarkan Pasal 363 Ayat (1) ke-4 KUHP jo. Pasal 65 Ayat (1) KUHP.",
         "16.0"
        ],
        [
         "17",
         "0",
         "8",
         "0",
         "6",
         "144",
         "ROSITA EVAYANTI DEWI",
         "Terdakwa I Ketut Joni Adnyana Adi Putra dan Terdakwa II Rosita Evayanti Dewi melakukan pencurian sepeda motor di dua lokasi berbeda di wilayah Kintamani, Bangli. Aksi pertama dilakukan pada 10 September 2023 sekitar pukul 01.00 WITA di parkiran Sukawana Sunrise, di mana Terdakwa I mengambil sepeda motor Yamaha NMAX DK 3498 PT milik saksi Made Yusa Paramartha dengan cara mendorong motor yang tidak terkunci dan menyalakan mesin menggunakan alat-alat seperti obeng, tang, dan kunci L. Motor hasil curian ini digunakan untuk keperluan sehari-hari. Aksi kedua dilakukan pada 1 Oktober 2023 sekitar pukul 02.00 WITA di parkiran Le Monte Sunrise. Dengan menggunakan mobil sewaan, kedua terdakwa kembali ke Kintamani dan Terdakwa I mencuri motor Yamaha NMAX DK 6992 LB milik I Kadek Indrawan dengan modus serupa. Sepeda motor tersebut kemudian dijual secara daring seharga Rp5.300.000. Akibat perbuatan kedua terdakwa, saksi Made Yusa Paramartha mengalami kerugian sebesar Rp25.500.000,- dan saksi I Kadek Indrawan mengalami kerugian sebesar Rp26.700.000,-. Perbuatan para terdakwa diancam pidana berdasarkan Pasal 363 Ayat (1) ke-4 KUHP jo. Pasal 65 Ayat (1) KUHP.",
         "14.0"
        ],
        [
         "18",
         "0",
         "9",
         "0",
         "6",
         "144",
         "ROSITA EVAYANTI DEWI",
         "Terdakwa I Ketut Joni Adnyana Adi Putra dan Terdakwa II Rosita Evayanti Dewi melakukan pencurian sepeda motor di dua lokasi berbeda di wilayah Kintamani, Bangli. Aksi pertama dilakukan pada 10 September 2023 sekitar pukul 01.00 WITA di parkiran Sukawana Sunrise, di mana Terdakwa I mengambil sepeda motor Yamaha NMAX DK 3498 PT milik saksi Made Yusa Paramartha dengan cara mendorong motor yang tidak terkunci dan menyalakan mesin menggunakan alat-alat seperti obeng, tang, dan kunci L. Motor hasil curian ini digunakan untuk keperluan sehari-hari. Aksi kedua dilakukan pada 1 Oktober 2023 sekitar pukul 02.00 WITA di parkiran Le Monte Sunrise. Dengan menggunakan mobil sewaan, kedua terdakwa kembali ke Kintamani dan Terdakwa I mencuri motor Yamaha NMAX DK 6992 LB milik I Kadek Indrawan dengan modus serupa. Sepeda motor tersebut kemudian dijual secara daring seharga Rp5.300.000. Akibat perbuatan kedua terdakwa, saksi Made Yusa Paramartha mengalami kerugian sebesar Rp25.500.000,- dan saksi I Kadek Indrawan mengalami kerugian sebesar Rp26.700.000,-. Perbuatan para terdakwa diancam pidana berdasarkan Pasal 363 Ayat (1) ke-4 KUHP jo. Pasal 65 Ayat (1) KUHP.",
         "14.0"
        ],
        [
         "19",
         "0",
         "1",
         "0",
         "4",
         "60",
         "I NYOMAN BUDIAWAN Als. SUMAWAN",
         "Pada hari Rabu, 25 Oktober 2023 sekitar pukul 13.00 WITA, terdakwa I Nyoman Budiawan alias Sumawan melakukan pencurian kartu ATM BRI milik saksi Luh Putu Widiantari di Toko UD. Langsung Jaya, Jalan Raya Kintamani, Desa Kintamani, Kecamatan Kintamani, Kabupaten Bangli. Awalnya, terdakwa datang ke toko tersebut untuk mentransfer uang, namun saat mengetahui mesin BRI Link rusak dan pegawai toko pergi, terdakwa memanfaatkan situasi sepi untuk mengambil kartu ATM yang berada di atas meja kasir. Terdakwa kemudian pulang ke rumahnya dan menggunakan kartu ATM tersebut di mesin ATM BRI Toya Devasya, dengan memasukkan PIN 020202 yang telah ia ketahui sebelumnya karena sering melihat pegawai toko menggunakannya. Terdakwa melakukan penarikan tunai sebanyak empat kali dengan total Rp10.000.000. Setelah menerima laporan dari korban, pihak kepolisian melakukan olah TKP dan berhasil mengamankan terdakwa di rumahnya pada 28 Oktober 2023. Akibat perbuatannya, korban mengalami kerugian sebesar Rp10.000.000. Perbuatan terdakwa diancam pidana berdasarkan Pasal 362 KUHP.",
         "14.0"
        ],
        [
         "20",
         "0",
         "0",
         "0",
         "4",
         "60",
         "I NYOMAN BUDIAWAN Als. SUMAWAN",
         "Pada hari Rabu, 25 Oktober 2023 sekitar pukul 13.00 WITA, terdakwa I Nyoman Budiawan alias Sumawan melakukan pencurian kartu ATM BRI milik saksi Luh Putu Widiantari di Toko UD. Langsung Jaya, Jalan Raya Kintamani, Desa Kintamani, Kecamatan Kintamani, Kabupaten Bangli. Awalnya, terdakwa datang ke toko tersebut untuk mentransfer uang, namun saat mengetahui mesin BRI Link rusak dan pegawai toko pergi, terdakwa memanfaatkan situasi sepi untuk mengambil kartu ATM yang berada di atas meja kasir. Terdakwa kemudian pulang ke rumahnya dan menggunakan kartu ATM tersebut di mesin ATM BRI Toya Devasya, dengan memasukkan PIN 020202 yang telah ia ketahui sebelumnya karena sering melihat pegawai toko menggunakannya. Terdakwa melakukan penarikan tunai sebanyak empat kali dengan total Rp10.000.000. Setelah menerima laporan dari korban, pihak kepolisian melakukan olah TKP dan berhasil mengamankan terdakwa di rumahnya pada 28 Oktober 2023. Akibat perbuatannya, korban mengalami kerugian sebesar Rp10.000.000. Perbuatan terdakwa diancam pidana berdasarkan Pasal 362 KUHP.",
         "14.0"
        ],
        [
         "21",
         "1",
         "10",
         "0",
         "7",
         "48",
         "DESAK MADE CITRAWATI",
         "Pada bulan April 2023, terdakwa Desak Made Citrawati didakwa melakukan tindak pidana penipuan secara berlanjut terhadap dua korban, yaitu I Putu Sutarga dan Pande Ketut Suarca, dengan total kerugian mencapai lebih dari Rp 391 juta. Modus operandi terdakwa adalah membeli telur dan beras dalam jumlah besar dari kedua korban dengan dalih pembayaran menggunakan cek mundur, disertai pernyataan palsu bahwa ia memiliki aset tanah di Singaraja yang sedang dalam proses penjualan. Terdakwa memesan telur sebanyak 4.435 krei dari I Putu Sutarga senilai total Rp 228.600.000, dan beras sebanyak 14.500 kg dari Pande Ketut Suarca dengan total nilai Rp 162.400.000. Setiap transaksi dilakukan secara bertahap pada tanggal 21, 23, 25, dan 28 April 2023. Terdakwa meyakinkan para korban dengan janji pelunasan dan surat pengakuan utang, namun setelah cek jatuh tempo, tidak ada dana yang tersedia. Pemeriksaan terhadap klaim kepemilikan tanah menunjukkan bahwa terdakwa hanya memberikan uang muka atas tanah tersebut dan belum ada kepastian transaksi. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 378 jo. Pasal 64 Ayat (1) ke-1 KUHP, dan dakwaan subsidair 379a KUHP Jo. Pasal 64 Ayat (1) ke-1 KUHP.",
         "30.0"
        ],
        [
         "22",
         "0",
         "11",
         "4",
         "3",
         "108",
         "I KETUT DENA",
         "Pada hari Jumat, 5 Februari 2021 sekitar pukul 19.00 WITA, terdakwa I Ketut Dena bersama Dewa Made Sujana (dalam berkas terpisah) melakukan pencurian satu unit sepeda motor Honda Scoopy warna hitam kombinasi merah dengan nomor polisi DK 5807 PS yang terparkir di depan rumah saksi I Nengah Sumerta di Desa Yangapi, Kecamatan Tembuku, Kabupaten Bangli. Sebelumnya, kedua terdakwa sempat pergi ke beberapa lokasi sabung ayam. Saat melintasi lokasi kejadian, Dewa Made Sujana melihat motor dalam keadaan tidak terkunci dan memerintahkan Ketut Dena untuk berjaga sementara dirinya mengambil sepeda motor tersebut. Setelah berhasil menghidupkan dan membawa motor itu, mereka menyembunyikannya di bawah jembatan di Gianyar. Keesokan harinya, motor tersebut diambil kembali dan diganti plat nomornya menggunakan plat dari motor lain, kemudian dibawa ke rumah Dewa Made Sujana. Sore harinya, Dewa Made Sujana ditangkap karena kasus pencurian handphone dan meminta Ketut Dena mengambil motor tersebut. Karena motor terkunci dan kuncinya masih disimpan Dewa Made Sujana, Ketut Dena memanggil tukang kunci untuk membuat duplikat. Motor curian itu lalu digadaikan oleh Ketut Dena kepada saksi Luh Sriani seharga Rp2.000.000 tanpa dokumen STNK atau BPKB. Korban, I Wayan Miyasa, melaporkan kehilangan tersebut ke Polsek Tembuku. Sekitar seminggu kemudian, Ketut Dena ditangkap atas kasus penadahan, mengakui perbuatannya, dan membantu polisi mencari motor dan kunci aslinya yang ditemukan di tas milik Dewa Made Sujana. Akibat perbuatan tersebut, korban mengalami kerugian sekitar Rp15.000.000. Tindak pidana ini diancam dengan 2 dakwaan yaitu dakwaan primair dengan Pasal 363 ayat (1) ke-4 KUHP serta dakwaan subsidair dengan Pasal 326 KUHP.",
         "12.0"
        ],
        [
         "23",
         "0",
         "11",
         "4",
         "6",
         "84",
         "DEWA MADE SUJANA",
         "Pada hari Jumat, 5 Februari 2021 sekitar pukul 09.30 WITA, Terdakwa Dewa Made Sujana bersama I Ketut Dena (berkas terpisah) pergi ke Nongan, Karangasem untuk menonton sabung ayam dengan mengendarai sepeda motor Honda Scoopy warna coklat hitam. Sekitar pukul 14.30 WITA, mereka mendengar ada sabung ayam di Pulasari, Tembuku, namun karena acara tersebut tidak ada, mereka kembali melewati Banjar Sideparna, Desa Yangapi, Bangli. Di lokasi tersebut, Terdakwa melihat sepeda motor Honda Scoopy warna hitam kombinasi merah yang terparkir dengan kunci masih menggantung, lalu meminta I Ketut Dena berhenti untuk mengawasi sekitar. Setelah merasa aman, Terdakwa menyalakan dan membawa kabur sepeda motor tersebut, sedangkan I Ketut Dena mengikuti dengan motor yang mereka gunakan sebelumnya. Motor hasil curian tersebut disembunyikan di bawah jembatan dekat Pantai Lebih, Gianyar. Keesokan harinya, mereka kembali mengambil motor tersebut dan mengganti plat nomornya dengan yang diambil dari motor lain, kemudian motor dibawa ke rumah Terdakwa di Ubud dan diparkir di garasi. Pada sore harinya, Terdakwa ditangkap oleh Polsek Sukawati atas kasus pencurian handphone. Saat penggeledahan, ditemukan kunci asli motor curian di tas milik Terdakwa yang diserahkan oleh istrinya. Akibat perbuatan tersebut, saksi korban I Wayan Miyasa mengalami kerugian sebesar Rp15.000.000. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 363 Ayat (1) ke-4 KUHP, dan dakwaan subsidair Pasal 362 KUHP.",
         "15.0"
        ],
        [
         "24",
         "2",
         "12",
         "4",
         "2",
         "144",
         "I KOMANG RENDI YANA alis RENDI",
         "Pada Selasa, 6 Juni 2023 sekitar pukul 20.10 WITA di Jalan Tirta Geduh, Kelurahan Bebalang, Bangli, terdakwa I Komang Rendi Yana alias Rendi ditangkap karena tanpa hak memiliki dan menyimpan narkotika jenis sabu. Awalnya, terdakwa memesan sabu seharga Rp200.000 kepada seseorang bernama Gus Ucil (DPO), lalu mengambil paket tersebut di bawah pohon mahoni di Jalan Putra Yuda, Bangli, sesuai petunjuk. Setelah dikonsumsi sebagian di rumahnya di Banua, Kintamani, sisa sabu disimpan dalam gantungan handphone yang dibungkus stiker dan diselipkan di jaket. Saat hendak ke alun-alun Bangli, terdakwa diberhentikan oleh polisi dan ditemukan sabu seberat 0,10 gram netto dalam jaketnya. Barang bukti lainnya termasuk bong bekas pakai, handphone, dan sepeda motor juga diamankan. Hasil uji laboratorium menunjukkan sabu mengandung metamfetamina yang tergolong Narkotika Golongan I. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 112 Ayat (1) UU RI No. 35 Tahun 2009 tentang Narkotika, dan dakwaan subsidair Pasal 127 Ayat (1) huruf a UU RI No. 35 Tahun 2009 tentang Narkotika.",
         "15.0"
        ],
        [
         "25",
         "2",
         "5",
         "4",
         "2",
         "144",
         "I KOMANG RENDI YANA alis RENDI",
         "Pada Selasa, 6 Juni 2023 sekitar pukul 20.10 WITA di Jalan Tirta Geduh, Kelurahan Bebalang, Bangli, terdakwa I Komang Rendi Yana alias Rendi ditangkap karena tanpa hak memiliki dan menyimpan narkotika jenis sabu. Awalnya, terdakwa memesan sabu seharga Rp200.000 kepada seseorang bernama Gus Ucil (DPO), lalu mengambil paket tersebut di bawah pohon mahoni di Jalan Putra Yuda, Bangli, sesuai petunjuk. Setelah dikonsumsi sebagian di rumahnya di Banua, Kintamani, sisa sabu disimpan dalam gantungan handphone yang dibungkus stiker dan diselipkan di jaket. Saat hendak ke alun-alun Bangli, terdakwa diberhentikan oleh polisi dan ditemukan sabu seberat 0,10 gram netto dalam jaketnya. Barang bukti lainnya termasuk bong bekas pakai, handphone, dan sepeda motor juga diamankan. Hasil uji laboratorium menunjukkan sabu mengandung metamfetamina yang tergolong Narkotika Golongan I. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 112 Ayat (1) UU RI No. 35 Tahun 2009 tentang Narkotika, dan dakwaan subsidair Pasal 127 Ayat (1) huruf a UU RI No. 35 Tahun 2009 tentang Narkotika.",
         "15.0"
        ],
        [
         "26",
         "2",
         "13",
         "0",
         "3",
         "144",
         "I GUSTI LANANG MADE WIJAYA alias LANANG",
         "Pada Senin, 24 April 2023 sekitar pukul 22.30 WITA di pinggir Jalan Muhamad Hatta, Bebalang, Bangli, terdakwa I Gusti Lanang Made Wijaya alias Lanang tertangkap karena tanpa hak memiliki narkotika jenis sabu. Sebelumnya, terdakwa memesan sabu seharga Rp700.000 dari seseorang bernama Jung Tu (DPO) melalui WhatsApp dan mengambil barang tersebut di bawah pot bunga di Desa Semana, Badung. Setelah mengonsumsinya sebagian di rumahnya di Ubud, terdakwa menyimpan sisa sabu ke dalam bungkus rokok yang dimasukkan ke saku celana. Malam harinya, saat hendak menemui seorang wanita bernama Riena (DPO) di Bangli, terdakwa dihentikan oleh polisi dan dilakukan penggeledahan. Polisi menemukan sabu seberat 0,10 gram netto, satu handphone, dan sepeda motor yang digunakan terdakwa. Berdasarkan hasil pemeriksaan laboratorium, kristal bening tersebut positif mengandung metamfetamina yang tergolong Narkotika Golongan I. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 112 Ayat (1) UU RI No. 35 Tahun 2009 Tentang Narkotika, dan dakwaan subsidair Pasal 127 Ayat (1) huruf a UU RI No. 35 Tahun 2009 Tentang Narkotika.",
         "16.0"
        ],
        [
         "27",
         "2",
         "10",
         "2",
         "5",
         "144",
         "SELAMET HARIANTO alias SELAMET",
         "Terdakwa Selamet Harianto alias Selamet bersama Sodakoh Maliki alias Dakoh (dalam berkas terpisah) pada 15 Mei 2023 sekitar pukul 20.45 WITA, bertempat di Jalan Muhammad Hatta, Kelurahan Bebalang, Kecamatan Bangli, kedapatan memiliki narkotika jenis sabu seberat 0,15 gram netto tanpa izin dari pihak berwenang. Perbuatan ini berawal ketika Selamet menghubungi seseorang bernama Rizal (DPO) untuk mencari pekerjaan dan ditawari menjadi \"peluncur\" (PL), yaitu mengambil paket sabu di Bangli. Selamet kemudian mengajak Sodakoh Maliki untuk menemaninya dengan janji akan memakai sabu bersama. Mereka berangkat dari Denpasar ke Bangli dengan motor dan mengambil paket sabu yang disimpan di belakang tiang listrik sesuai petunjuk dari Rizal. Saat dalam perjalanan kembali ke Denpasar, mereka ditangkap oleh polisi di Jalan Muhammad Hatta dan ditemukan barang bukti sabu serta alat-alat konsumsi narkotika. Dalam penggeledahan, ditemukan pula sabu lain seberat 0,02 gram netto milik Sodakoh Maliki yang disimpan dalam tas pinggang, serta berbagai perlengkapan penggunaan sabu. Berdasarkan hasil uji laboratorium, kristal yang ditemukan terbukti mengandung metamfetamina, sedangkan hasil tes urine Selamet negatif narkotika. Selamet sebelumnya juga pernah dihukum dalam kasus serupa berdasarkan putusan PN Denpasar tahun 2019 dan baru bebas pada 7 Maret 2023. Terdakwa didakwa dengan Pasal 112 Ayat (1) UU RI No. 35 Tahun 2009 tentang Narkotika jo. Pasal 55 Ayat (1) ke-1 KUHP.",
         "75.0"
        ],
        [
         "28",
         "2",
         "13",
         "4",
         "5",
         "240",
         "RAIHAN RAHADI AZHAR alias RAIHAN",
         "Terdakwa Raihan Rahadi Azhar alias Raihan, bersama-sama dengan Gungggus Togar Manatar Pangaribuan alias Togar (yang berkas perkaranya terpisah), pada 14 Maret 2023 di Rutan Kelas IIB Bangli, diduga melakukan tindak pidana narkotika dengan tanpa hak atau melawan hukum menjadi perantara dalam jual beli narkotika golongan I berupa tembakau sintetis. Togar meminjam nama Raihan untuk menerima paket berisi tembakau sintetis yang dikirim melalui jasa ekspedisi JT. Raihan menyetujui permintaan tersebut dan menerima paket atas namanya pada 16 Maret 2023. Setelah menerima paket di ruang portir rutan, Raihan langsung diamankan petugas. Pemeriksaan terhadap paket menunjukkan adanya dua bungkus tembakau sintetis dengan total berat bersih 52 gram netto, yang masing-masing dikemas dalam plastik bermerek Violin dan Rhino. Berdasarkan hasil uji laboratorium, daun-daun kering tersebut positif mengandung MDMB-4en PINACA, zat yang termasuk dalam Narkotika Golongan I. Raihan tidak memiliki izin dari Kementerian Kesehatan atau instansi berwenang lainnya untuk memperjualbelikan atau menjadi perantara narkotika tersebut. Perbuatan Terdakwa didakwa dengan dakwaan pertama Pasal 114 Ayat (1) UU RI No. 35 Tahun 2009 tentang Narkotika jo. Pasal 55 Ayat (1) ke-1 KUHP, dakwaan kedua Pasal 112 Ayat (1) UU RI No. 35 Tahun 2009 Tentang Narkotika jo. Pasal 55 Ayat (1) ke-1 KUHP, dan dakwaan ketiga Pasal 111 Ayat (1) UU RI No. 35 Tahun 2009 Tentang Narkotika jo. Pasal 55 Ayat (1) ke-1 KUHP.",
         "90.0"
        ],
        [
         "29",
         "2",
         "13",
         "4",
         "5",
         "240",
         "GUNGGUS TOGAR MANATAR PANGARIBUAN alias TOGAR",
         "Terdakwa Gunggus Togar Manatar Pangaribuan alias Togar, baik sendiri maupun bersama-sama dengan Raihan Rahadi Azhar alias Raihan (terdakwa dalam berkas terpisah), pada 14 Maret 2023 sekitar pukul 12.00 WITA di kamar tahanan Blok B Rutan Kelas IIB Bangli, memesan narkotika golongan I berupa tembakau sintetis dari seorang bernama Zetas Networking (DPO). Terdakwa meminjam nama Raihan untuk menerima paket narkotika tersebut melalui jasa pengiriman JT. Setelah mentransfer uang sebesar Rp1.400.000 melalui OVO, Terdakwa meminta agar paket dikirim atas nama Raihan. Pada 16 Maret 2023, Raihan diamankan oleh petugas rutan saat menerima paket berisi dua bungkus tembakau sintetis, masing-masing dibungkus plastik bermerek Violin dan Rhino. Setelah diinterogasi, Raihan mengaku bahwa paket tersebut milik Terdakwa. Pemeriksaan barang bukti menunjukkan bahwa tembakau tersebut mengandung senyawa MDMB-4en PINACA yang tergolong dalam Narkotika Golongan I. Terdakwa tidak memiliki izin dari Menteri Kesehatan atau lembaga berwenang lainnya untuk memperjualbelikan atau menerima narkotika tersebut. Perbuatan Terdakwa didakwa dengan dakwaan pertama Pasal 114 Ayat (1) UU RI No. 35 Tahun 2009 tentang Narkotika jo. Pasal 55 Ayat (1) ke-1 KUHP, dakwaan kedua Pasal 112 Ayat (1) UU RI No. 35 Tahun 2009 Tentang Narkotika jo. Pasal 55 Ayat (1) ke-1 KUHP, dan dakwaan ketiga Pasal 111 Ayat (1) UU RI No. 35 Tahun 2009 Tentang Narkotika jo. Pasal 55 Ayat (1) ke-1 KUHP.",
         "102.0"
        ],
        [
         "30",
         "4",
         "14",
         "0",
         "4",
         "120",
         "I NYOMAN RAWAS",
         "Pada hari Senin, 27 Maret 2023 sekitar pukul 21.30 WITA, terdakwa I Nyoman Rawas bersama I Ketut Sudima menyelenggarakan permainan judi cap jeki di lapangan terbuka di Banjar Kedisan, Desa Kedisan, Kecamatan Kintamani, Kabupaten Bangli. Kegiatan ini telah diberitahukan sebelumnya kepada para penjudi, dan terdakwa menyiapkan berbagai peralatan seperti perlak angka, handuk, kotak kaleng, kartu ceki, dan uang modal sebesar Rp 2.000.000. Dalam permainan tersebut, I Nyoman Rawas bertindak sebagai bandar yang mengendalikan jalannya permainan dan menentukan hasil, sementara I Ketut Sudima berperan sebagai kasir yang membayar kemenangan atau mengambil taruhan yang kalah. Permainan dilakukan dengan dua sistem, yaitu sistem “melok” (seri) dan “nyolot” (menang-kalah), yang masing-masing memiliki ketentuan kemenangan dan pembayarannya sendiri. Pada malam itu, para terdakwa melangsungkan enam putaran permainan dan memperoleh keuntungan sebesar Rp 370.000 sebelum akhirnya ditangkap oleh pihak kepolisian. Dari hasil penyelidikan, diketahui bahwa para terdakwa telah berulang kali menyelenggarakan permainan serupa di berbagai lokasi dan menjadikannya sebagai sumber penghasilan untuk kebutuhan sehari-hari. Seluruh kegiatan perjudian tersebut dilakukan tanpa izin resmi dan merupakan bentuk perjudian yang bersifat untung-untungan. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 303 Ayat (1) ke-1 KUHP jo. Pasal 2 Undang-Undang No. 7 Tahun 1974 tentang Penertiban Perjudian, dan dakwaan subsidair Pasal 303 Ayat (1) ke-2 KUHP jo. Pasal 2 Undang-Undang No. 7 Tahun 1974 Tentang Penertiban Perjudian.",
         "7.0"
        ],
        [
         "31",
         "4",
         "14",
         "0",
         "4",
         "120",
         "I KETUT SUDIMA",
         "Pada hari Senin, 27 Maret 2023 sekitar pukul 21.30 WITA, terdakwa I Nyoman Rawas bersama I Ketut Sudima menyelenggarakan permainan judi cap jeki di lapangan terbuka di Banjar Kedisan, Desa Kedisan, Kecamatan Kintamani, Kabupaten Bangli. Kegiatan ini telah diberitahukan sebelumnya kepada para penjudi, dan terdakwa menyiapkan berbagai peralatan seperti perlak angka, handuk, kotak kaleng, kartu ceki, dan uang modal sebesar Rp 2.000.000. Dalam permainan tersebut, I Nyoman Rawas bertindak sebagai bandar yang mengendalikan jalannya permainan dan menentukan hasil, sementara I Ketut Sudima berperan sebagai kasir yang membayar kemenangan atau mengambil taruhan yang kalah. Permainan dilakukan dengan dua sistem, yaitu sistem “melok” (seri) dan “nyolot” (menang-kalah), yang masing-masing memiliki ketentuan kemenangan dan pembayarannya sendiri. Pada malam itu, para terdakwa melangsungkan enam putaran permainan dan memperoleh keuntungan sebesar Rp 370.000 sebelum akhirnya ditangkap oleh pihak kepolisian. Dari hasil penyelidikan, diketahui bahwa para terdakwa telah berulang kali menyelenggarakan permainan serupa di berbagai lokasi dan menjadikannya sebagai sumber penghasilan untuk kebutuhan sehari-hari. Seluruh kegiatan perjudian tersebut dilakukan tanpa izin resmi dan merupakan bentuk perjudian yang bersifat untung-untungan. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 303 Ayat (1) ke-1 KUHP jo. Pasal 2 Undang-Undang No. 7 Tahun 1974 tentang Penertiban Perjudian, dan dakwaan subsidair Pasal 303 Ayat (1) ke-2 KUHP jo. Pasal 2 Undang-Undang No. 7 Tahun 1974 Tentang Penertiban Perjudian.",
         "6.0"
        ],
        [
         "32",
         "0",
         "13",
         "0",
         "3",
         "84",
         "NI LUH PUSPA DEWI",
         "Pada hari Minggu, 4 Juli 2021 sekitar pukul 11.00 WITA, Terdakwa Ni Luh Puspa Dewi dalam perjalanan menuju ladang orang tuanya di Desa Suter, Bangli, melewati sebuah rumah kosong di Banjar Munduk Waru, Desa Buahan, Kintamani, dan timbul niat untuk mencuri. Setelah memastikan keadaan sekitar aman, terdakwa masuk ke rumah tersebut dan menemukan kunci di lemari kaca dalam salah satu kamar. Ia kemudian membuka kamar lain dengan kunci tersebut dan menemukan dompet biru bermotif bunga berisi berbagai perhiasan emas, termasuk kalung, gelang, cincin, dan anting-anting dengan total berat puluhan gram. Semua barang tersebut diambil dan disimpan di sakunya, lalu terdakwa meninggalkan lokasi. Perhiasan hasil curian dijual di Pasar Kidul kepada seorang wanita tak dikenal seharga Rp80.000.000, yang kemudian digunakan untuk kebutuhan sehari-hari dan membeli sejumlah pakaian, sandal, serta cincin emas. Berdasarkan laporan polisi tertanggal 6 Februari 2023, terdakwa akhirnya mengakui seluruh perbuatannya. Akibat kejadian ini, korban I Nyoman Mawa mengalami kerugian sekitar Rp80.000.000. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 363 Ayat (1) ke-5 KUHP, dan dakwaan subsidair Pasal 362 KUHP.",
         "6.0"
        ],
        [
         "33",
         "0",
         "15",
         "4",
         "5",
         "80",
         "I Wayan Nawa",
         "Terdakwa I Wayan Nawa didakwa melakukan pencurian pada dua kesempatan berbeda di wilayah Kintamani, Bangli. Pada 2 Oktober 2022, setelah menjual salak, terdakwa menuju ke kebun milik I Wayan Suardana di Banjar Pludu, Desa Bayung Gede, dan berpura-pura menawarkan pupuk ayam. Saat korban lengah, terdakwa mencuri handphone Redmi Note 10S beserta uang tunai sekitar Rp400.000 yang disimpan di kandang sapi. Kemudian, pada 9 November 2022, terdakwa kembali melakukan pencurian di pondokan milik I Wayan Panggih di Desa Binyan dengan modus serupa. Setelah memastikan korban pergi, terdakwa mencuri handphone Redmi Note 7 yang sedang dicas. Kedua handphone tersebut dijual ke konter berbeda dengan total hasil sekitar Rp1.800.000, yang kemudian digunakan untuk kebutuhan sehari-hari. Berdasarkan laporan korban, polisi melakukan penyelidikan dan berhasil menangkap terdakwa pada 9 Februari 2023 di Karangasem. Akibat perbuatannya, korban I Wayan Suardana mengalami kerugian sekitar Rp3.400.000 dan I Wayan Panggih sekitar Rp3.000.000. Terdakwa dijerat dengan Pasal 362 KUHP jo. Pasal 65 Ayat (1) KUHP tentang pencurian yang dilakukan berulang kali.",
         "6.0"
        ],
        [
         "34",
         "0",
         "13",
         "3",
         "5",
         "60",
         "JRO GEDE BUDI",
         "Pada Sabtu, 28 Januari 2023, di Pemandian Tirta Usadha Toya Bungkah, Desa Batur Tengah, Kintamani, Bangli, terdakwa Jro Gede Budi didakwa melakukan pencurian. Setelah selesai berendam, terdakwa melihat sebuah tas hitam bertuliskan \"Steve Madden\" milik korban Ni Jro Luh Putri di bawah loker, lalu mengambilnya dan membawanya pulang menggunakan sepeda motor. Di perjalanan, terdakwa membuka tas tersebut dan menemukan tas merah maroon bertuliskan \"Michael Kors\" berisi uang tunai sebesar Rp5.700.000 serta sebuah dompet berisi perhiasan emas berupa kalung dan cincin, dan dua nota pembelian dari Toko Emas Ratna. Terdakwa mengambil Rp1.000.000 untuk dirinya dan menyembunyikan sisa uang serta perhiasan di bawah pohon di dekat rumahnya, sedangkan tas-tas tersebut disimpan di jok motor. Berdasarkan laporan korban, polisi berhasil mengamankan terdakwa beserta barang-barang bukti, termasuk sepeda motor dan hoodie yang digunakan untuk membungkus barang curian. Atas perbuatannya, korban mengalami kerugian sekitar Rp19.700.000, dan terdakwa dijerat dengan Pasal 362 KUHP tentang pencurian.",
         "5.0"
        ],
        [
         "35",
         "0",
         "1",
         "4",
         "3",
         "84",
         "RIFQI ABDURAHMAN",
         "Pada Minggu, 11 Desember 2022 sekitar pukul 00.30 WITA, terdakwa I Rifqi Abdurahman dan terdakwa II Gunawan melakukan pencurian sepeda motor di pinggir Jalan Raya Kayuambua, Bangli. Sebelumnya, pada 10 Desember 2022, terdakwa II meminta terdakwa I mencarikan sepeda motor Kawasaki KLX untuk dibeli seharga Rp3.000.000. Keduanya lalu berangkat ke daerah Kintamani dengan sepeda motor modifikasi tanpa nomor polisi. Saat tiba di lokasi, mereka melihat motor Kawasaki KLX 150 C tanpa nomor polisi dan kunci kontak, lalu terdakwa I mendorong motor tersebut menjauh sementara terdakwa II mengawasi. Karena motor cetul milik terdakwa II rusak, terdakwa I mendorong motor sendirian dan sempat dicegat dua saksi yang curiga. Setelah berhasil menyalakan motor dan mengendarainya sejauh 100 meter, motor mogok karena kehabisan bensin. Terdakwa I lalu mendorong ke SPBU Sekardadi dan tertidur di sana. Sementara itu, saksi korban mengonfirmasi kehilangan motornya dan bersama saksi lainnya serta polisi, menemukan terdakwa I di SPBU. Polisi kemudian menangkap terdakwa II di Desa Dumilih saat tertidur di emper toko. Akibat perbuatan para terdakwa, korban I Wayan Eva Kusuma Putra mengalami kerugian sekitar Rp16.000.000. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 363 Ayat (1) ke-4 KUHP, dan dakwaan subsidair Pasal 362 KUHP.",
         "8.0"
        ],
        [
         "36",
         "0",
         "1",
         "4",
         "3",
         "84",
         "GUNAWAN",
         "Pada Minggu, 11 Desember 2022 sekitar pukul 00.30 WITA, terdakwa I Rifqi Abdurahman dan terdakwa II Gunawan melakukan pencurian sepeda motor di pinggir Jalan Raya Kayuambua, Bangli. Sebelumnya, pada 10 Desember 2022, terdakwa II meminta terdakwa I mencarikan sepeda motor Kawasaki KLX untuk dibeli seharga Rp3.000.000. Keduanya lalu berangkat ke daerah Kintamani dengan sepeda motor modifikasi tanpa nomor polisi. Saat tiba di lokasi, mereka melihat motor Kawasaki KLX 150 C tanpa nomor polisi dan kunci kontak, lalu terdakwa I mendorong motor tersebut menjauh sementara terdakwa II mengawasi. Karena motor cetul milik terdakwa II rusak, terdakwa I mendorong motor sendirian dan sempat dicegat dua saksi yang curiga. Setelah berhasil menyalakan motor dan mengendarainya sejauh 100 meter, motor mogok karena kehabisan bensin. Terdakwa I lalu mendorong ke SPBU Sekardadi dan tertidur di sana. Sementara itu, saksi korban mengonfirmasi kehilangan motornya dan bersama saksi lainnya serta polisi, menemukan terdakwa I di SPBU. Polisi kemudian menangkap terdakwa II di Desa Dumilih saat tertidur di emper toko. Akibat perbuatan para terdakwa, korban I Wayan Eva Kusuma Putra mengalami kerugian sekitar Rp16.000.000. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 363 Ayat (1) ke-4 KUHP, dan dakwaan subsidair Pasal 362 KUHP.",
         "8.0"
        ],
        [
         "37",
         "0",
         "1",
         "0",
         "6",
         "80",
         "Gede Kastawa",
         "Terdakwa Gede Kastawa didakwa melakukan serangkaian tindak pidana pencurian ayam di wilayah Kintamani, Bangli, pada bulan Oktober 2022. Pada 21 Oktober 2022, terdakwa mencuri 6 ekor ayam dari belakang rumah korban I Wayan Sukada di Desa Belantih, lalu menjualnya di Pasar Anyar Singaraja seharga Rp800.000. Hasil penjualan digunakan untuk membeli ayam aduan dan berjudi. Kemudian, pada 28 Oktober 2022, terdakwa mencuri 15 ekor ayam milik korban I Made Terus dari kebun jeruk di Desa Belanga, yang kembali dijual dan hasilnya dipakai untuk berjudi. Selanjutnya, pada 30 Oktober 2022, terdakwa beraksi di pondokan milik korban I Wayan Lusin di Desa Belanga, mencuri seekor ayam namun aksinya diketahui oleh saksi dan warga sehingga berhasil diamankan. Total kerugian para korban mencapai sekitar Rp3.500.000. Terdakwa mengaku melakukan pencurian karena alasan ekonomi. Perbuatannya diancam pidana sesuai Pasal 362 jo. Pasal 65 Ayat (1) KUHP.",
         "30.0"
        ],
        [
         "38",
         "0",
         "14",
         "0",
         "6",
         "80",
         "Gede Kastawa",
         "Terdakwa Gede Kastawa didakwa melakukan serangkaian tindak pidana pencurian ayam di wilayah Kintamani, Bangli, pada bulan Oktober 2022. Pada 21 Oktober 2022, terdakwa mencuri 6 ekor ayam dari belakang rumah korban I Wayan Sukada di Desa Belantih, lalu menjualnya di Pasar Anyar Singaraja seharga Rp800.000. Hasil penjualan digunakan untuk membeli ayam aduan dan berjudi. Kemudian, pada 28 Oktober 2022, terdakwa mencuri 15 ekor ayam milik korban I Made Terus dari kebun jeruk di Desa Belanga, yang kembali dijual dan hasilnya dipakai untuk berjudi. Selanjutnya, pada 30 Oktober 2022, terdakwa beraksi di pondokan milik korban I Wayan Lusin di Desa Belanga, mencuri seekor ayam namun aksinya diketahui oleh saksi dan warga sehingga berhasil diamankan. Total kerugian para korban mencapai sekitar Rp3.500.000. Terdakwa mengaku melakukan pencurian karena alasan ekonomi. Perbuatannya diancam pidana sesuai Pasal 362 jo. Pasal 65 Ayat (1) KUHP.",
         "30.0"
        ],
        [
         "39",
         "0",
         "16",
         "0",
         "5",
         "84",
         "Elias Fanggi",
         "Terdakwa Elias Fanggi didakwa melakukan pencurian tiga ekor anak babi milik saksi I Komang Sucitra pada Sabtu, 27 Maret 2021 sekitar pukul 22.30 WITA di kandang babi yang terletak di Desa Abuan, Kecamatan Kintamani, Kabupaten Bangli. Awalnya, terdakwa datang ke kandang pada sore hari untuk membersihkan tempat tersebut. Namun pada malam harinya, terdakwa masuk ke dalam kandang melalui pintu yang tidak terkunci, lalu mengambil tiga ekor anak babi dan memasukkannya ke dalam karung plastik yang telah disiapkannya. Ia kemudian membawa hasil curian itu dengan sepeda motor milik saksi Leonardus Pendi dengan maksud untuk dijual. Aksi tersebut diketahui oleh pemilik kandang, yang kemudian melaporkan terdakwa ke pihak berwajib. Akibat perbuatan tersebut, saksi I Komang Sucitra mengalami kerugian sebesar Rp3.600.000. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 363 Ayat (1) ke-1 KUHP, dan dakwaan subsidair Pasal 374 KUHP.",
         "6.0"
        ],
        [
         "40",
         "0",
         "17",
         "0",
         "5",
         "84",
         "Elias Fanggi",
         "Terdakwa Elias Fanggi didakwa melakukan pencurian tiga ekor anak babi milik saksi I Komang Sucitra pada Sabtu, 27 Maret 2021 sekitar pukul 22.30 WITA di kandang babi yang terletak di Desa Abuan, Kecamatan Kintamani, Kabupaten Bangli. Awalnya, terdakwa datang ke kandang pada sore hari untuk membersihkan tempat tersebut. Namun pada malam harinya, terdakwa masuk ke dalam kandang melalui pintu yang tidak terkunci, lalu mengambil tiga ekor anak babi dan memasukkannya ke dalam karung plastik yang telah disiapkannya. Ia kemudian membawa hasil curian itu dengan sepeda motor milik saksi Leonardus Pendi dengan maksud untuk dijual. Aksi tersebut diketahui oleh pemilik kandang, yang kemudian melaporkan terdakwa ke pihak berwajib. Akibat perbuatan tersebut, saksi I Komang Sucitra mengalami kerugian sebesar Rp3.600.000. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 363 Ayat (1) ke-1 KUHP, dan dakwaan subsidair Pasal 374 KUHP.",
         "6.0"
        ],
        [
         "41",
         "0",
         "17",
         "0",
         "15",
         "112",
         "I Wayan Edi Rusmawan",
         "Terdakwa I Wayan Edi Rusmawan didakwa melakukan serangkaian pencurian antara bulan Juni 2020 hingga Januari 2021 di berbagai lokasi di wilayah Kecamatan Kintamani, Kabupaten Bangli. Terdakwa mengambil barang-barang milik sejumlah korban di antaranya I Wayan Sutiana, I Ketut Carem, I Ketut Sudadi, I Nyoman Keneh, Ni Nengah Suantini, I Nyoman Birawan, Ni Ketut Supadmi, I Wayan Darma, I Wayan Ramanto, I Nengah Sapa, dan I Made Sadswadarma. Aksi pencurian tersebut dilakukan terdakwa dengan cara merusak, memanjat, atau masuk secara diam-diam ke kebun, pondokan, warung, dan gudang milik para korban, dengan maksud untuk memiliki barang-barang tersebut secara melawan hukum. Karena dilakukan berulang kali di tempat dan waktu yang berbeda, perbuatan terdakwa dianggap sebagai beberapa kejahatan yang berdiri sendiri. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 363 Ayat (1) ke-5 KUHP jo. Pasal 65 ayat (1) KUHP, dan dakwaan subsidair Pasal 362 KUHP Jo Pasal 65 Ayat (1) KUHP.",
         "24.0"
        ],
        [
         "42",
         "0",
         "0",
         "0",
         "15",
         "112",
         "I Wayan Edi Rusmawan",
         "Terdakwa I Wayan Edi Rusmawan didakwa melakukan serangkaian pencurian antara bulan Juni 2020 hingga Januari 2021 di berbagai lokasi di wilayah Kecamatan Kintamani, Kabupaten Bangli. Terdakwa mengambil barang-barang milik sejumlah korban di antaranya I Wayan Sutiana, I Ketut Carem, I Ketut Sudadi, I Nyoman Keneh, Ni Nengah Suantini, I Nyoman Birawan, Ni Ketut Supadmi, I Wayan Darma, I Wayan Ramanto, I Nengah Sapa, dan I Made Sadswadarma. Aksi pencurian tersebut dilakukan terdakwa dengan cara merusak, memanjat, atau masuk secara diam-diam ke kebun, pondokan, warung, dan gudang milik para korban, dengan maksud untuk memiliki barang-barang tersebut secara melawan hukum. Karena dilakukan berulang kali di tempat dan waktu yang berbeda, perbuatan terdakwa dianggap sebagai beberapa kejahatan yang berdiri sendiri. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 363 Ayat (1) ke-5 KUHP jo. Pasal 65 ayat (1) KUHP, dan dakwaan subsidair Pasal 362 KUHP Jo Pasal 65 Ayat (1) KUHP.",
         "24.0"
        ],
        [
         "43",
         "2",
         "18",
         "5",
         "4",
         "144",
         "ANJAR RUCHIMAT",
         "Terdakwa Anjar Ruchimat dan Irga Krisna Haryanto R, pada 4 Februari 2020 sekitar pukul 21.30 WITA di pinggir Jalan Raya Merdeka, Bebalang, Bangli, diduga melakukan permufakatan jahat bersama seorang bernama Made Bleteng (DPO) untuk memiliki, menyimpan, menguasai, atau menyediakan Narkotika Golongan I bukan tanaman tanpa hak. Selain itu, Anjar Ruchimat juga terbukti menggunakan narkotika untuk diri sendiri pada 1 Februari 2020 sekitar pukul 15.00 WITA di sebuah penginapan di Kuta, Badung. Demikian pula, Irga Krisna Haryanto R menggunakan narkotika untuk diri sendiri pada 28 Januari 2020 sekitar pukul 22.30 WITA di kamar kontrakannya di Dalung, Badung. Meskipun tempat kejadian perkara berada di wilayah hukum Pengadilan Negeri Denpasar, perkara ini diperiksa oleh Pengadilan Negeri Bangli berdasarkan ketentuan Pasal 84 ayat (2) KUHAP. Perbuatan para terdakwa diancam pidana berdasarkan Pasal 132 Ayat (1) jo. Pasal 112 Ayat (1), serta Pasal 127 Ayat (1) huruf a UU RI No. 35 Tahun 2009 tentang Narkotika.",
         "16.0"
        ],
        [
         "44",
         "2",
         "18",
         "5",
         "4",
         "144",
         "IRGA KRISNA HARYANTO R",
         "Terdakwa Anjar Ruchimat dan Irga Krisna Haryanto R, pada 4 Februari 2020 sekitar pukul 21.30 WITA di pinggir Jalan Raya Merdeka, Bebalang, Bangli, diduga melakukan permufakatan jahat bersama seorang bernama Made Bleteng (DPO) untuk memiliki, menyimpan, menguasai, atau menyediakan Narkotika Golongan I bukan tanaman tanpa hak. Selain itu, Anjar Ruchimat juga terbukti menggunakan narkotika untuk diri sendiri pada 1 Februari 2020 sekitar pukul 15.00 WITA di sebuah penginapan di Kuta, Badung. Demikian pula, Irga Krisna Haryanto R menggunakan narkotika untuk diri sendiri pada 28 Januari 2020 sekitar pukul 22.30 WITA di kamar kontrakannya di Dalung, Badung. Meskipun tempat kejadian perkara berada di wilayah hukum Pengadilan Negeri Denpasar, perkara ini diperiksa oleh Pengadilan Negeri Bangli berdasarkan ketentuan Pasal 84 ayat (2) KUHAP. Perbuatan para terdakwa diancam pidana berdasarkan Pasal 132 Ayat (1) jo. Pasal 112 Ayat (1), serta Pasal 127 Ayat (1) huruf a UU RI No. 35 Tahun 2009 tentang Narkotika.",
         "16.0"
        ],
        [
         "45",
         "2",
         "18",
         "6",
         "6",
         "240",
         "FENNY YANTHI ESMIDAR",
         "Terdakwa Fenny Yanthi Esmidar pada Kamis, 9 Januari 2020 sekitar pukul 23.15 WITA ditangkap di Gang Buntu, belakang Alfamart Jalan Brigjen Ngurah Rai, Bangli, saat baru saja mengambil narkotika jenis sabu yang disembunyikan di semak-semak. Penangkapan dilakukan oleh anggota Satresnarkoba Polres Bangli setelah menerima informasi dari masyarakat. Sebelumnya, terdakwa dihubungi oleh seseorang bernama Desi untuk mengambil narkotika di lokasi tersebut. Dari hasil penggeledahan, ditemukan dua paket sabu dengan berat netto masing-masing 0,08 gram dan 0,05 gram, yang disimpan dalam bungkus rokok dan tas milik terdakwa. Berdasarkan hasil pemeriksaan laboratorium forensik, kedua paket tersebut positif mengandung metamfetamina yang termasuk dalam Narkotika Golongan I. Namun, hasil tes urine terdakwa menunjukkan negatif narkotika/psikotropika. Perbuatan Terdakwa didakwa dengan dakwaan pertama Pasal 114 Ayat (1) UU RI No. 35 Tahun 2009 tentang Narkotika, dan dakwaan kedua Pasal 112 Ayat (1) UU RI No. 35 Tahun 2009 Tentang Narkotika.",
         "102.0"
        ],
        [
         "46",
         "0",
         "19",
         "7",
         "4",
         "84",
         "I WAYAN SUDARPA",
         "Terdakwa I Wayan Sudarpa pada Rabu, 12 Februari 2020 sekitar pukul 01.00 WITA melakukan pencurian tiga ekor sapi milik I Wayan Kasir di Br. Tiying Desa, Desa Pengotan, Kecamatan Bangli. Aksi tersebut direncanakan sebelumnya bersama I Nyoman Bintang, dengan dalih ingin menjual sapi miliknya untuk membayar utang. Pada malam hari yang telah disepakati, terdakwa mendatangi kandang sapi korban dan secara bertahap membawa ketiga sapi tersebut ke mobil pick up milik I Nyoman Bintang yang menunggu di dekat lokasi. Sapi-sapi itu kemudian dibawa dan dijual di Pasar Bringkit, Badung. Dari hasil penjualan, terdakwa menerima uang sebesar Rp20.156.000 setelah dikurangi biaya operasional. Namun, diketahui sapi-sapi tersebut bukan milik terdakwa melainkan milik I Wayan Kasir, yang tidak pernah memberikan izin untuk pengambilan maupun penjualan. Akibat perbuatan terdakwa, korban mengalami kerugian sekitar Rp20.500.000. Tindakan terdakwa diancam pidana berdasarkan Pasal 363 Ayat (1) ke-1 KUHP.",
         "6.0"
        ],
        [
         "47",
         "4",
         "20",
         "8",
         "3",
         "120",
         "Wayan Suartaya",
         "Pada tanggal 21 November 2018 sekitar pukul 18.00 WITA, terdakwa I Ketut Sarjana dan Wayan Suartaya mengadakan permainan judi cap jeki di halaman rumah Ketut Sarjana di Banjar Merta, Desa Awan, Kecamatan Kintamani, Kabupaten Bangli. Mereka menyiapkan berbagai alat perjudian seperti kotak kaleng, perlak, handuk, kartu ceki, serta menyediakan hadiah uang tunai sebesar Rp 5.000.000 bagi pemenang. Ketut Sarjana bertindak sebagai kasir sekaligus bandar yang membayar kemenangan dan mengambil uang taruhan pemain yang kalah, sedangkan Wayan Suartaya bertugas mengocok kartu ceki. Permainan dilakukan dengan dua sistem, yakni sistem \"melok\" (draw) dan \"nyolot\" (menang-kalah), yang masing-masing memiliki aturan dan hadiah berbeda. Saat permainan berlangsung, petugas dari Dit. Reskrimum POLDA Bali melakukan penggerebekan dan menemukan sejumlah barang bukti, termasuk kartu ceki, handuk, kotak kaleng, perlak, dan uang tunai Rp 2.665.000. Permainan judi cap jeki tersebut dilakukan tanpa izin dari pejabat yang berwenang. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 303 Ayat (1) ke-1 KUHP jo. Pasal 2 Undang-Undang RI No. 7 Tahun 1974 tentang Penertiban Perjudian, dan dakwaan subsidair Pasal 303 Ayat (1) ke-2 KUHP, jo. Pasal 2 UU RI No. 7 Tahun 1974 Tentang Penertiban Perjudian.",
         "5.0"
        ],
        [
         "48",
         "4",
         "21",
         "8",
         "3",
         "120",
         "Wayan Suartaya",
         "Pada tanggal 21 November 2018 sekitar pukul 18.00 WITA, terdakwa I Ketut Sarjana dan Wayan Suartaya mengadakan permainan judi cap jeki di halaman rumah Ketut Sarjana di Banjar Merta, Desa Awan, Kecamatan Kintamani, Kabupaten Bangli. Mereka menyiapkan berbagai alat perjudian seperti kotak kaleng, perlak, handuk, kartu ceki, serta menyediakan hadiah uang tunai sebesar Rp 5.000.000 bagi pemenang. Ketut Sarjana bertindak sebagai kasir sekaligus bandar yang membayar kemenangan dan mengambil uang taruhan pemain yang kalah, sedangkan Wayan Suartaya bertugas mengocok kartu ceki. Permainan dilakukan dengan dua sistem, yakni sistem \"melok\" (draw) dan \"nyolot\" (menang-kalah), yang masing-masing memiliki aturan dan hadiah berbeda. Saat permainan berlangsung, petugas dari Dit. Reskrimum POLDA Bali melakukan penggerebekan dan menemukan sejumlah barang bukti, termasuk kartu ceki, handuk, kotak kaleng, perlak, dan uang tunai Rp 2.665.000. Permainan judi cap jeki tersebut dilakukan tanpa izin dari pejabat yang berwenang. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 303 Ayat (1) ke-1 KUHP jo. Pasal 2 Undang-Undang RI No. 7 Tahun 1974 tentang Penertiban Perjudian, dan dakwaan subsidair Pasal 303 Ayat (1) ke-2 KUHP, jo. Pasal 2 UU RI No. 7 Tahun 1974 Tentang Penertiban Perjudian.",
         "5.0"
        ],
        [
         "49",
         "4",
         "20",
         "8",
         "3",
         "120",
         "I Ketut Sarjana",
         "Pada tanggal 21 November 2018 sekitar pukul 18.00 WITA, terdakwa I Ketut Sarjana dan Wayan Suartaya mengadakan permainan judi cap jeki di halaman rumah Ketut Sarjana di Banjar Merta, Desa Awan, Kecamatan Kintamani, Kabupaten Bangli. Mereka menyiapkan berbagai alat perjudian seperti kotak kaleng, perlak, handuk, kartu ceki, serta menyediakan hadiah uang tunai sebesar Rp 5.000.000 bagi pemenang. Ketut Sarjana bertindak sebagai kasir sekaligus bandar yang membayar kemenangan dan mengambil uang taruhan pemain yang kalah, sedangkan Wayan Suartaya bertugas mengocok kartu ceki. Permainan dilakukan dengan dua sistem, yakni sistem \"melok\" (draw) dan \"nyolot\" (menang-kalah), yang masing-masing memiliki aturan dan hadiah berbeda. Saat permainan berlangsung, petugas dari Dit. Reskrimum POLDA Bali melakukan penggerebekan dan menemukan sejumlah barang bukti, termasuk kartu ceki, handuk, kotak kaleng, perlak, dan uang tunai Rp 2.665.000. Permainan judi cap jeki tersebut dilakukan tanpa izin dari pejabat yang berwenang. Perbuatan Terdakwa didakwa dengan dakwaan primair Pasal 303 Ayat (1) ke-1 KUHP jo. Pasal 2 Undang-Undang RI No. 7 Tahun 1974 tentang Penertiban Perjudian, dan dakwaan subsidair Pasal 303 Ayat (1) ke-2 KUHP, jo. Pasal 2 UU RI No. 7 Tahun 1974 Tentang Penertiban Perjudian.",
         "5.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 4323
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>klasifikasi_perkara_encoded</th>\n",
       "      <th>penuntut_umum_encoded</th>\n",
       "      <th>hakim_encoded</th>\n",
       "      <th>jumlah_saksi</th>\n",
       "      <th>maks_penjara_berdasarkan_pasal</th>\n",
       "      <th>terdakwa</th>\n",
       "      <th>summarized_dakwaan</th>\n",
       "      <th>total_pidana_penjara_bulan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>GEDE DARMAYASA</td>\n",
       "      <td>Terdakwa Gede Darmayasa didakwa telah melakuka...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>IDA BAGUS MADE DARMA WIGUNA</td>\n",
       "      <td>Pada bulan Februari dan Maret 2024, terdakwa I...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>HANDRI JOHANAS</td>\n",
       "      <td>Terdakwa Handri Johanes pada Rabu, 24 April 20...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>I GEDE ARIADI alias BERNAD</td>\n",
       "      <td>Pada hari Minggu, 14 April 2024 sekitar pukul ...</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>I GEDE ARIADI alias BERNAD</td>\n",
       "      <td>Pada hari Minggu, 14 April 2024 sekitar pukul ...</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>2</td>\n",
       "      <td>276</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "      <td>NURUL FIQRI SUDIRMAN als KIKI bin SUDIRMAN</td>\n",
       "      <td>Pada Jumat, 31 Maret 2023, sekitar pukul 20.30...</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>SUPRIADI BIN RATIM</td>\n",
       "      <td>Pada hari Minggu, 28 Mei 2023, sekitar pukul 1...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>SUPRIADI BIN RATIM</td>\n",
       "      <td>Pada hari Minggu, 28 Mei 2023, sekitar pukul 1...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>ANWAR RURI BIN SYARIFUDIN USMAN</td>\n",
       "      <td>Pada hari Minggu, 28 Mei 2023, sekitar pukul 1...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>ANWAR RURI BIN SYARIFUDIN USMAN</td>\n",
       "      <td>Pada hari Minggu, 28 Mei 2023, sekitar pukul 1...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4323 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      klasifikasi_perkara_encoded  penuntut_umum_encoded  hakim_encoded  \\\n",
       "0                               0                      0              0   \n",
       "1                               1                      1              1   \n",
       "2                               0                      0              2   \n",
       "3                               2                      2              1   \n",
       "4                               2                      3              1   \n",
       "...                           ...                    ...            ...   \n",
       "4318                            2                    276            128   \n",
       "4319                            0                    264            117   \n",
       "4320                            0                    287            117   \n",
       "4321                            0                    264            117   \n",
       "4322                            0                    287            117   \n",
       "\n",
       "      jumlah_saksi  maks_penjara_berdasarkan_pasal  \\\n",
       "0                6                              80   \n",
       "1                4                              48   \n",
       "2                6                              84   \n",
       "3                2                             144   \n",
       "4                2                             144   \n",
       "...            ...                             ...   \n",
       "4318             2                             240   \n",
       "4319             2                              84   \n",
       "4320             2                              84   \n",
       "4321             2                              84   \n",
       "4322             2                              84   \n",
       "\n",
       "                                        terdakwa  \\\n",
       "0                                 GEDE DARMAYASA   \n",
       "1                    IDA BAGUS MADE DARMA WIGUNA   \n",
       "2                                 HANDRI JOHANAS   \n",
       "3                     I GEDE ARIADI alias BERNAD   \n",
       "4                     I GEDE ARIADI alias BERNAD   \n",
       "...                                          ...   \n",
       "4318  NURUL FIQRI SUDIRMAN als KIKI bin SUDIRMAN   \n",
       "4319                          SUPRIADI BIN RATIM   \n",
       "4320                          SUPRIADI BIN RATIM   \n",
       "4321             ANWAR RURI BIN SYARIFUDIN USMAN   \n",
       "4322             ANWAR RURI BIN SYARIFUDIN USMAN   \n",
       "\n",
       "                                     summarized_dakwaan  \\\n",
       "0     Terdakwa Gede Darmayasa didakwa telah melakuka...   \n",
       "1     Pada bulan Februari dan Maret 2024, terdakwa I...   \n",
       "2     Terdakwa Handri Johanes pada Rabu, 24 April 20...   \n",
       "3     Pada hari Minggu, 14 April 2024 sekitar pukul ...   \n",
       "4     Pada hari Minggu, 14 April 2024 sekitar pukul ...   \n",
       "...                                                 ...   \n",
       "4318  Pada Jumat, 31 Maret 2023, sekitar pukul 20.30...   \n",
       "4319  Pada hari Minggu, 28 Mei 2023, sekitar pukul 1...   \n",
       "4320  Pada hari Minggu, 28 Mei 2023, sekitar pukul 1...   \n",
       "4321  Pada hari Minggu, 28 Mei 2023, sekitar pukul 1...   \n",
       "4322  Pada hari Minggu, 28 Mei 2023, sekitar pukul 1...   \n",
       "\n",
       "      total_pidana_penjara_bulan  \n",
       "0                            5.0  \n",
       "1                           24.0  \n",
       "2                            4.0  \n",
       "3                           14.0  \n",
       "4                           14.0  \n",
       "...                          ...  \n",
       "4318                        72.0  \n",
       "4319                        16.0  \n",
       "4320                        16.0  \n",
       "4321                        16.0  \n",
       "4322                        16.0  \n",
       "\n",
       "[4323 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4323 entries, 0 to 4322\n",
      "Data columns (total 8 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   klasifikasi_perkara_encoded     4323 non-null   int64  \n",
      " 1   penuntut_umum_encoded           4323 non-null   int64  \n",
      " 2   hakim_encoded                   4323 non-null   int64  \n",
      " 3   jumlah_saksi                    4323 non-null   int64  \n",
      " 4   maks_penjara_berdasarkan_pasal  4323 non-null   int64  \n",
      " 5   terdakwa                        4323 non-null   object \n",
      " 6   summarized_dakwaan              4323 non-null   object \n",
      " 7   total_pidana_penjara_bulan      4323 non-null   float64\n",
      "dtypes: float64(1), int64(5), object(2)\n",
      "memory usage: 270.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(df: pd.DataFrame, split_size: float = 0.8) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    unique_groups = df.groupby([\"klasifikasi_perkara_encoded\", \"penuntut_umum_encoded\", \"hakim_encoded\"]).apply(lambda x: x.index.tolist()).to_dict()\n",
    "    \n",
    "    print(unique_groups)\n",
    "    train_idx, test_idx = [], []\n",
    "    \n",
    "    for indices in unique_groups.values():        \n",
    "        if len(indices) == 1:\n",
    "            train_idx.extend(indices)\n",
    "        else:\n",
    "            train, test = train_test_split(indices, train_size=split_size, random_state=42)\n",
    "            train_idx.extend(train)\n",
    "            test_idx.extend(test)\n",
    "    \n",
    "    return df.loc[train_idx], df.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0, 0): [0, 20, 42], (0, 0, 2): [2], (0, 1, 0): [19, 37], (0, 1, 4): [35, 36], (0, 4, 1): [5], (0, 4, 3): [10], (0, 5, 21): [843], (0, 7, 1): [9], (0, 8, 0): [15, 17], (0, 9, 0): [16, 18], (0, 11, 4): [22, 23], (0, 12, 19): [775, 776, 813], (0, 12, 21): [774], (0, 12, 22): [715], (0, 12, 23): [806], (0, 13, 0): [32], (0, 13, 3): [34], (0, 14, 0): [38], (0, 14, 14): [437, 501, 595, 609], (0, 14, 16): [422], (0, 14, 18): [474, 665], (0, 14, 19): [783, 784, 785, 786], (0, 14, 20): [432, 438, 518, 578, 608, 724, 745], (0, 14, 21): [639, 822], (0, 15, 4): [33], (0, 16, 0): [39], (0, 17, 0): [40, 41], (0, 19, 7): [46], (0, 20, 37): [1051], (0, 21, 55): [1612], (0, 21, 57): [1630, 1632], (0, 22, 10): [241, 268, 269, 270, 271, 303], (0, 22, 14): [259, 381, 415, 416, 538, 545, 577, 621], (0, 22, 16): [308, 314, 315, 383, 386, 417], (0, 22, 18): [654, 655, 656], (0, 22, 19): [548, 762], (0, 22, 20): [446, 570, 571, 572, 573, 690, 725], (0, 22, 22): [719], (0, 23, 10): [52, 54], (0, 24, 10): [136, 152, 172], (0, 24, 11): [75, 104], (0, 24, 12): [173], (0, 24, 14): [119], (0, 25, 10): [100, 147, 196, 369], (0, 25, 11): [55], (0, 25, 14): [374, 403, 449, 450], (0, 25, 16): [402], (0, 25, 19): [584, 585, 769], (0, 25, 20): [737], (0, 25, 21): [586, 815, 816, 817, 842], (0, 26, 10): [56], (0, 27, 10): [57, 94], (0, 27, 12): [90], (0, 28, 9): [58], (0, 28, 10): [106, 107, 109], (0, 28, 12): [96, 97], (0, 29, 10): [59, 60, 61], (0, 29, 12): [101, 102], (0, 30, 10): [174], (0, 30, 14): [144, 162, 163, 164, 166, 177], (0, 31, 10): [63, 91, 92, 93], (0, 31, 11): [65], (0, 31, 12): [80, 175, 176], (0, 32, 12): [70, 71], (0, 34, 10): [78], (0, 34, 11): [73, 81, 89], (0, 35, 12): [110, 111], (0, 35, 15): [170], (0, 36, 12): [105, 128], (0, 37, 15): [183], (0, 38, 10): [153], (0, 39, 10): [294, 360, 387], (0, 39, 16): [291, 320, 329, 365], (0, 39, 19): [722], (0, 40, 10): [141, 165, 178], (0, 40, 12): [112], (0, 40, 14): [120], (0, 41, 10): [289, 312, 316, 348, 349], (0, 41, 14): [186, 187, 420, 421, 574, 587], (0, 41, 16): [304, 305, 306, 331, 346, 347, 362, 363], (0, 41, 17): [388], (0, 41, 18): [442, 657, 664, 711], (0, 41, 19): [495, 604], (0, 41, 20): [493, 636], (0, 41, 21): [700, 701], (0, 42, 10): [206, 212, 261, 264], (0, 42, 12): [142], (0, 42, 13): [288], (0, 45, 12): [133], (0, 46, 10): [134], (0, 46, 14): [260], (0, 47, 10): [211, 242, 243], (0, 47, 12): [145, 236, 237, 238, 239], (0, 47, 14): [149, 151], (0, 48, 10): [352], (0, 48, 16): [324, 325, 326, 384, 385], (0, 50, 12): [179, 195], (0, 52, 14): [148, 150, 430, 533, 554, 555, 556, 590], (0, 52, 18): [651, 652], (0, 52, 19): [425, 426, 429, 547, 580, 635, 643], (0, 52, 20): [448, 480, 481, 513, 514, 530, 531, 607, 622], (0, 52, 21): [628, 647, 771], (0, 54, 10): [199, 250, 251, 252, 253], (0, 54, 12): [200], (0, 54, 14): [232], (0, 54, 16): [265], (0, 55, 15): [182], (0, 56, 10): [330], (0, 56, 16): [296, 389], (0, 56, 17): [366], (0, 57, 10): [198, 282, 283], (0, 57, 12): [201], (0, 57, 17): [364], (0, 58, 10): [380], (0, 58, 14): [327, 328], (0, 58, 16): [338], (0, 59, 14): [221, 222, 223, 224, 517, 614], (0, 59, 19): [459, 460, 461, 509, 510, 511, 632, 781, 782], (0, 59, 20): [433], (0, 59, 21): [645, 746], (0, 59, 23): [810, 834], (0, 59, 48): [1257, 1259], (0, 62, 10): [318, 333, 334, 368], (0, 62, 13): [292], (0, 62, 14): [332, 337, 339, 343, 356, 357, 358, 397, 406, 482, 483], (0, 62, 16): [275, 276, 277, 302, 317, 336, 359, 367], (0, 62, 19): [440, 479, 593, 598], (0, 62, 20): [434, 454, 475, 498, 507, 559, 591, 592, 602, 603, 686], (0, 62, 21): [557], (0, 62, 22): [721], (0, 63, 10): [379], (0, 63, 19): [534, 535, 627, 814], (0, 63, 20): [630], (0, 64, 14): [408, 524, 540], (0, 64, 18): [753, 796], (0, 64, 19): [494, 508, 560, 561, 562, 588], (0, 64, 20): [455, 581], (0, 64, 21): [631, 641], (0, 65, 14): [610], (0, 65, 16): [409], (0, 65, 19): [500, 799, 800], (0, 65, 20): [476], (0, 65, 21): [638], (0, 66, 14): [484, 485], (0, 66, 20): [566, 567, 568, 738, 780], (0, 66, 21): [616, 841], (0, 66, 22): [699], (0, 67, 14): [539, 615], (0, 67, 18): [424, 528], (0, 67, 20): [523, 712], (0, 67, 21): [640, 648, 649], (0, 68, 14): [550], (0, 68, 19): [714, 730, 731, 732, 733, 736], (0, 68, 20): [716, 750], (0, 68, 21): [840], (0, 68, 31): [923], (0, 69, 14): [543], (0, 69, 20): [596, 597, 629, 718, 795], (0, 69, 21): [787, 788], (0, 69, 22): [734], (0, 69, 23): [835], (0, 69, 49): [1380], (0, 71, 18): [653], (0, 71, 21): [791, 792], (0, 72, 19): [831], (0, 72, 20): [759], (0, 73, 19): [765, 766], (0, 73, 20): [740, 741], (0, 73, 21): [767], (0, 73, 75): [2030, 2031], (0, 73, 78): [1994, 1995], (0, 73, 81): [2070], (0, 75, 19): [761, 809], (0, 75, 21): [763, 829], (0, 77, 19): [794], (0, 77, 20): [777], (0, 79, 18): [789], (0, 79, 21): [826], (0, 81, 23): [807], (0, 83, 21): [819], (0, 84, 23): [827], (0, 85, 26): [860], (0, 85, 31): [886, 907], (0, 87, 30): [871, 872], (0, 88, 28): [885], (0, 88, 31): [969, 971], (0, 88, 34): [946], (0, 88, 35): [990], (0, 88, 36): [998], (0, 88, 37): [1025, 1026], (0, 88, 43): [1022], (0, 91, 28): [913], (0, 91, 34): [911, 921], (0, 91, 36): [979, 1001, 1007], (0, 92, 29): [870], (0, 93, 31): [915, 953], (0, 93, 34): [937], (0, 93, 36): [939, 1000], (0, 95, 28): [868], (0, 95, 31): [879], (0, 97, 32): [877], (0, 98, 32): [880], (0, 100, 30): [890], (0, 100, 32): [904], (0, 103, 31): [916], (0, 103, 34): [947, 987], (0, 103, 35): [991], (0, 103, 36): [980, 981, 999], (0, 103, 39): [995], (0, 103, 40): [996], (0, 105, 33): [900, 901, 902, 903], (0, 107, 28): [914], (0, 107, 34): [912, 922, 938], (0, 107, 36): [940], (0, 108, 31): [924], (0, 109, 31): [970, 972], (0, 109, 55): [1523], (0, 110, 36): [956, 958, 960], (0, 112, 31): [943], (0, 113, 31): [944], (0, 114, 31): [945], (0, 115, 36): [955, 957, 959, 1006], (0, 115, 40): [997], (0, 116, 31): [954], (0, 116, 37): [1043], (0, 117, 35): [961], (0, 117, 36): [1008], (0, 117, 37): [992], (0, 118, 35): [962], (0, 118, 36): [1009], (0, 119, 34): [986], (0, 120, 38): [993, 994], (0, 124, 37): [1037, 1042, 1052], (0, 124, 42): [1030], (0, 126, 43): [1035], (0, 127, 37): [1036], (0, 130, 46): [1296, 1320], (0, 130, 47): [1425], (0, 130, 48): [1324, 1435, 1437, 1439, 1441], (0, 130, 49): [1358], (0, 131, 45): [1055], (0, 131, 46): [1080, 1190], (0, 131, 47): [1206, 1207], (0, 131, 48): [1192], (0, 132, 45): [1056], (0, 133, 45): [1057, 1121, 1133, 1135], (0, 133, 46): [1076, 1196, 1198], (0, 134, 45): [1058, 1063, 1122, 1134, 1136], (0, 134, 47): [1075, 1109, 1111], (0, 134, 48): [1117, 1119, 1137], (0, 135, 45): [1105], (0, 135, 47): [1096, 1098, 1395, 1397, 1401], (0, 135, 48): [1139, 1215, 1292, 1298, 1312, 1316, 1427], (0, 135, 49): [1381], (0, 136, 45): [1147], (0, 136, 47): [1061, 1062], (0, 136, 48): [1159, 1195], (0, 137, 45): [1064], (0, 138, 46): [1065], (0, 138, 47): [1225, 1227, 1411], (0, 138, 48): [1143, 1203, 1253], (0, 139, 46): [1066], (0, 140, 45): [1067, 1068, 1069], (0, 140, 46): [1077], (0, 140, 48): [1118, 1120, 1138, 1144], (0, 141, 46): [1256], (0, 141, 47): [1400], (0, 141, 48): [1291], (0, 142, 46): [1174], (0, 142, 47): [1074, 1200], (0, 143, 45): [1106], (0, 143, 46): [1081, 1191], (0, 143, 47): [1097, 1099], (0, 143, 48): [1140, 1405], (0, 143, 49): [1326, 1328, 1330, 1332, 1334, 1423, 1448, 1459], (0, 143, 50): [1451, 1454, 1457], (0, 144, 45): [1150], (0, 144, 48): [1235, 1388, 1434, 1436, 1438, 1440], (0, 146, 45): [1146, 1151], (0, 146, 46): [1197, 1199, 1229, 1295], (0, 146, 47): [1110, 1112], (0, 146, 48): [1194, 1248, 1252, 1255], (0, 147, 46): [1281, 1319], (0, 147, 47): [1410], (0, 147, 48): [1158, 1202, 1254, 1382], (0, 147, 49): [1357], (0, 148, 48): [1168], (0, 149, 48): [1169, 1216, 1236, 1249], (0, 150, 46): [1175, 1228, 1302, 1304], (0, 150, 47): [1201], (0, 150, 48): [1247, 1258, 1260, 1323, 1355, 1389], (0, 150, 50): [1450, 1453, 1456], (0, 151, 47): [1208], (0, 151, 48): [1193], (0, 152, 46): [1282], (0, 152, 47): [1224, 1226], (0, 152, 48): [1383], (0, 154, 48): [1284], (0, 155, 46): [1301, 1303], (0, 155, 47): [1394, 1396], (0, 155, 48): [1283, 1297, 1311, 1315, 1404, 1426], (0, 156, 49): [1325, 1327, 1329, 1331, 1333, 1447, 1458], (0, 156, 50): [1449, 1452, 1455], (0, 157, 47): [1424], (0, 157, 48): [1356, 1390], (0, 157, 49): [1422], (0, 161, 23): [1462], (0, 161, 51): [1531, 1535, 1552, 1554, 1575], (0, 161, 53): [1478, 1480], (0, 162, 23): [1463], (0, 162, 51): [1548], (0, 163, 51): [1464, 1486], (0, 164, 51): [1465, 1596], (0, 164, 54): [1500], (0, 164, 55): [1639, 1641], (0, 165, 51): [1472], (0, 165, 53): [1622], (0, 165, 55): [1614, 1616, 1640, 1642, 1647], (0, 167, 51): [1473, 1507, 1509, 1511, 1520, 1532, 1536], (0, 167, 53): [1479, 1481], (0, 167, 54): [1497, 1501], (0, 168, 51): [1576, 1580, 1593], (0, 168, 54): [1496], (0, 168, 55): [1581, 1599, 1604, 1605], (0, 169, 51): [1487], (0, 169, 55): [1583, 1590, 1600], (0, 170, 51): [1519, 1594], (0, 171, 54): [1544, 1546, 1574], (0, 172, 51): [1506, 1508, 1510], (0, 173, 54): [1543, 1545, 1649], (0, 173, 55): [1578, 1646], (0, 174, 55): [1524], (0, 175, 51): [1547, 1551, 1553], (0, 175, 54): [1559], (0, 175, 55): [1555], (0, 176, 51): [1579, 1595], (0, 176, 53): [1621], (0, 176, 54): [1560, 1573, 1648], (0, 176, 55): [1556, 1561, 1577, 1582, 1589, 1603, 1611, 1613, 1615], (0, 176, 56): [1584], (0, 176, 57): [1629, 1631], (0, 177, 55): [1562], (0, 178, 55): [1606], (0, 183, 62): [1675, 1681], (0, 183, 63): [1679], (0, 184, 62): [1678], (0, 184, 67): [1721, 1727, 1728], (0, 185, 62): [1723, 1733], (0, 186, 62): [1695, 1715], (0, 187, 62): [1708], (0, 187, 63): [1716, 1717, 1718, 1719], (0, 187, 67): [1735], (0, 191, 62): [1725], (0, 191, 65): [1697], (0, 191, 67): [1743], (0, 191, 69): [1710, 1711], (0, 192, 67): [1704], (0, 192, 82): [2152], (0, 192, 83): [2292], (0, 192, 84): [2174, 2205, 2336, 2440], (0, 192, 86): [2426], (0, 192, 87): [2456], (0, 192, 88): [2315, 2320, 2323, 2324, 2335, 2342, 2381, 2392], (0, 192, 89): [2441], (0, 192, 90): [2467], (0, 193, 62): [1705], (0, 197, 71): [1745], (0, 198, 71): [1746], (0, 199, 72): [1749], (0, 199, 73): [1891], (0, 199, 74): [1905, 1906, 1913], (0, 199, 77): [2004], (0, 199, 79): [2015, 2028, 2029, 2032], (0, 199, 80): [2037, 2038], (0, 199, 81): [2113], (0, 199, 82): [2114], (0, 199, 83): [2133, 2253], (0, 199, 84): [2158, 2213, 2214], (0, 199, 86): [2212, 2242], (0, 201, 75): [2020], (0, 201, 77): [2056], (0, 201, 78): [1982], (0, 201, 81): [2119], (0, 202, 73): [1789, 1790, 1791], (0, 202, 77): [1798], (0, 202, 78): [1797], (0, 203, 73): [1804, 1824, 1828, 1842, 1851, 1872, 1873, 1895, 1909, 1940], (0, 203, 74): [1803, 1819, 1825, 1833, 1834, 1835, 1839, 1840, 1845, 1850, 1852, 1871, 1876, 1879, 1885, 1890, 1902, 1907, 1916, 1932], (0, 203, 75): [1771, 1968, 1972, 1973, 1983, 2012, 2017, 2018], (0, 203, 76): [1760], (0, 203, 77): [1967], (0, 203, 78): [1948, 2000], (0, 203, 81): [2078, 2118], (0, 203, 82): [2063, 2172, 2186, 2514], (0, 203, 84): [2209, 2308, 2344, 2448, 2460, 2489], (0, 203, 86): [2217, 2237, 2238, 2463], (0, 203, 88): [2355, 2380, 2418], (0, 203, 90): [2484], (0, 204, 73): [1776, 1784, 1787], (0, 204, 74): [1818, 1820], (0, 204, 75): [1766], (0, 205, 73): [1762, 1763, 1764, 1765, 1779], (0, 206, 74): [1767], (0, 208, 73): [1914, 1915], (0, 208, 74): [1772, 1874, 1894], (0, 208, 75): [2009], (0, 208, 81): [2053, 2071, 2072, 2092, 2093], (0, 208, 82): [2076, 2102, 2115, 2130, 2162], (0, 208, 83): [2203], (0, 208, 84): [2171, 2187, 2517], (0, 208, 86): [2215, 2275, 2515, 2516], (0, 208, 87): [2257, 2452], (0, 209, 73): [1830], (0, 209, 74): [1778, 1794, 1795, 1814, 1815, 1837, 1904], (0, 211, 74): [1888, 1889], (0, 211, 75): [1949, 1981], (0, 211, 77): [2055], (0, 211, 78): [1980], (0, 211, 80): [2062], (0, 211, 81): [2058, 2090], (0, 211, 82): [2057, 2122, 2137], (0, 211, 83): [2235], (0, 211, 84): [2240, 2241, 2299, 2343], (0, 211, 86): [2221, 2236], (0, 212, 18): [2518], (0, 212, 73): [1849, 1930], (0, 212, 74): [1846, 1848, 1899], (0, 212, 75): [1976], (0, 212, 78): [2005], (0, 212, 80): [2046], (0, 212, 81): [2069, 2116], (0, 212, 82): [2079, 2080, 2134, 2135, 2167], (0, 212, 84): [2175, 2190, 2198, 2199, 2284, 2285, 2348, 2349, 2413, 2494, 2510], (0, 212, 86): [2444, 2506, 2511], (0, 212, 87): [2475], (0, 212, 88): [2370, 2438, 2496, 2497], (0, 214, 73): [1928, 1929, 1951, 1952, 1975], (0, 214, 74): [1903], (0, 214, 75): [1963, 1997], (0, 214, 78): [1987, 2003], (0, 214, 79): [2039, 2040, 2041], (0, 214, 81): [2121], (0, 214, 82): [2059, 2060, 2066], (0, 214, 83): [2131, 2239], (0, 214, 84): [2184, 2256, 2319, 2434], (0, 214, 85): [2188], (0, 214, 86): [2216, 2300, 2301, 2312, 2313, 2356], (0, 214, 87): [2362], (0, 214, 88): [2338, 2439], (0, 214, 89): [2422, 2423, 2424], (0, 215, 74): [1926], (0, 216, 73): [1931], (0, 216, 75): [1959, 1971], (0, 216, 81): [2110, 2128], (0, 216, 82): [2067], (0, 216, 83): [2274], (0, 216, 86): [2287], (0, 216, 88): [2351, 2474, 2503, 2504, 2505], (0, 217, 73): [1985], (0, 217, 75): [2016], (0, 217, 77): [1992, 1993], (0, 217, 78): [2010], (0, 217, 80): [2047, 2064], (0, 217, 81): [2061, 2095], (0, 218, 75): [2001], (0, 218, 78): [1996], (0, 218, 81): [2098, 2099, 2100], (0, 218, 82): [2077], (0, 219, 77): [2054], (0, 220, 82): [2068], (0, 221, 84): [2280], (0, 222, 83): [2270], (0, 222, 86): [2478], (0, 223, 84): [2360], (0, 224, 83): [2262, 2309], (0, 224, 84): [2411, 2443], (0, 224, 86): [2276, 2345, 2479, 2485], (0, 224, 87): [2465], (0, 224, 88): [2372, 2390, 2412, 2442, 2471, 2476], (0, 225, 18): [2523], (0, 225, 84): [2266, 2314], (0, 225, 86): [2295, 2296, 2350, 2414, 2508], (0, 225, 88): [2507], (0, 226, 82): [2513], (0, 226, 83): [2289, 2290], (0, 226, 84): [2420], (0, 226, 86): [2427], (0, 226, 88): [2389, 2459], (0, 227, 84): [2294], (0, 227, 86): [2316, 2317, 2318], (0, 228, 84): [2347, 2401], (0, 228, 86): [2337, 2521, 2524], (0, 228, 88): [2371, 2437, 2481], (0, 229, 84): [2361, 2367, 2394, 2432], (0, 229, 86): [2333], (0, 229, 87): [2428, 2429, 2430, 2431], (0, 229, 88): [2415], (0, 230, 84): [2417], (0, 232, 88): [2483], (0, 233, 86): [2509], (0, 235, 92): [2527, 2528], (0, 235, 95): [2545], (0, 235, 100): [2536, 2537], (0, 236, 93): [2529], (0, 236, 97): [2559], (0, 239, 111): [2560], (0, 241, 101): [2538], (0, 242, 99): [2535], (0, 242, 104): [2564, 2565], (0, 243, 95): [2542], (0, 245, 103): [2543], (0, 245, 110): [2558], (0, 248, 100): [2547], (0, 249, 105): [2548], (0, 250, 106): [2549], (0, 251, 98): [2550, 2551], (0, 253, 100): [2567], (0, 254, 112): [2571], (0, 255, 94): [2566], (0, 263, 115): [2583, 3525], (0, 263, 116): [2781, 2783, 2785, 2787, 3500], (0, 263, 117): [2864, 3596], (0, 263, 118): [2894], (0, 263, 119): [3035, 3433], (0, 263, 120): [2673], (0, 263, 121): [2702], (0, 263, 123): [2638], (0, 263, 124): [2850], (0, 263, 126): [2775, 3209, 3385, 3711], (0, 263, 127): [3327, 3329], (0, 263, 128): [2640, 2692], (0, 263, 129): [2677, 2979, 3432, 4027, 4029, 4031, 4033], (0, 263, 131): [3042], (0, 263, 133): [2848], (0, 263, 134): [2860, 3000, 3277, 3447], (0, 263, 135): [3117, 3119, 3523, 3535], (0, 263, 136): [3125], (0, 264, 115): [2584, 3112, 3114, 3564], (0, 264, 116): [2782, 2784, 2786, 2788, 3070, 3318, 3501, 3630, 3632, 3928, 3970, 4182, 4184], (0, 264, 117): [2610, 3193, 3451, 4314, 4319, 4321], (0, 264, 118): [2596, 2598, 2600, 2895, 3281, 3592, 3594], (0, 264, 119): [3036, 3434, 4133, 4135, 4148, 4316], (0, 264, 120): [2674, 3016, 3644, 3646], (0, 264, 122): [2612, 2614, 3149], (0, 264, 123): [2639, 3129, 3131, 3133, 4283], (0, 264, 124): [2732], (0, 264, 126): [2776, 3386, 3712], (0, 264, 127): [3151, 3152, 3328, 3330, 4046], (0, 264, 128): [2641, 2693, 2844, 3092, 3714, 3716, 4281], (0, 264, 129): [2678, 2980, 3697, 3912, 3914], (0, 264, 130): [2772, 3025, 3027], (0, 264, 131): [2897, 3276, 4216, 4218], (0, 264, 133): [2849, 3056, 3355, 3357, 3359], (0, 264, 134): [2861, 3278], (0, 264, 135): [3118, 3120, 3766, 3768, 4202], (0, 264, 136): [3126, 3882], (0, 264, 137): [3774, 4160], (0, 265, 115): [2745, 2969, 2971, 3111, 3113, 3183, 3185, 3547], (0, 265, 116): [2585, 2719, 2721, 3069, 3629, 3631, 3775, 3777, 3927, 3969, 4284], (0, 265, 117): [2629, 3229, 4203, 4313], (0, 265, 118): [3591, 3593], (0, 265, 119): [2823, 2856, 2929], (0, 265, 120): [2880, 3219, 3390, 4262, 4264, 4266], (0, 265, 121): [3157, 3472], (0, 265, 122): [2931, 2933, 2935, 2937, 2975, 2977], (0, 265, 123): [3971, 4246], (0, 265, 124): [2621, 3159, 3161, 3335, 3337, 3339, 3453, 3455], (0, 265, 125): [2623, 4013, 4015, 4139, 4178], (0, 265, 126): [3416, 3418, 3420, 3422], (0, 265, 127): [2749, 2751, 2884, 2886, 2888, 3753], (0, 265, 128): [3425, 3713, 3715, 3989, 4105, 4107], (0, 265, 129): [3431, 4067], (0, 265, 130): [2709, 2711, 3293, 3295], (0, 265, 131): [2669, 2824, 2989, 3001, 3003, 3041, 3275, 4017, 4268, 4270, 4272], (0, 265, 132): [2842], (0, 265, 133): [2987, 3398, 3542], (0, 265, 134): [2999, 3691], (0, 265, 135): [3522, 3534, 3677, 4083, 4201], (0, 265, 136): [3818, 4213], (0, 265, 137): [3896, 3898, 4179], (0, 265, 138): [4307], (0, 265, 139): [4058], (0, 265, 140): [4292], (0, 266, 116): [2586, 2919, 4112], (0, 266, 118): [2743, 3481], (0, 266, 119): [3796], (0, 266, 121): [2763, 2993, 3109], (0, 266, 124): [4042], (0, 266, 125): [2997, 3301, 3872], (0, 266, 127): [2750, 2752, 3679], (0, 266, 129): [2797, 2962, 2964, 2981], (0, 266, 130): [2710, 2712, 2915, 2917], (0, 266, 131): [3681], (0, 266, 133): [3822], (0, 266, 138): [3788, 3790, 3792, 3794], (0, 267, 121): [2671], (0, 267, 123): [2735], (0, 267, 124): [2973, 3336, 3338, 3340], (0, 267, 126): [3417, 3419, 3421, 3423], (0, 267, 127): [3392, 3410], (0, 267, 133): [3545], (0, 267, 134): [3448], (0, 267, 136): [3489], (0, 268, 115): [3548], (0, 268, 117): [3582], (0, 268, 120): [3220], (0, 268, 121): [2672], (0, 268, 123): [3405], (0, 268, 124): [2974], (0, 268, 125): [2875, 3214, 3216], (0, 268, 127): [3074], (0, 268, 133): [3218, 3546], (0, 271, 115): [2852], (0, 271, 116): [3317], (0, 271, 117): [2865, 3089], (0, 271, 118): [2595, 2597, 2599, 2854], (0, 271, 120): [3015], (0, 271, 121): [2703, 3371], (0, 271, 124): [2731], (0, 271, 126): [2866, 3210], (0, 271, 128): [3091], (0, 271, 130): [2771], (0, 272, 115): [2970, 2972], (0, 272, 116): [3776, 3778], (0, 272, 117): [2609, 2630, 2793, 2794], (0, 272, 119): [2601], (0, 272, 120): [2755, 2757, 2759, 2761, 2881, 3650, 4263, 4265, 4267], (0, 272, 121): [2925, 2926, 3158], (0, 272, 122): [2611, 2613, 2932, 2934, 2936, 2938, 2976, 2978], (0, 272, 123): [3319, 3321], (0, 272, 127): [2885, 2887, 2889, 3411, 3664], (0, 272, 132): [2843], (0, 272, 133): [2988, 3055, 3399], (0, 272, 134): [3634, 3636], (0, 272, 135): [3059, 3061], (0, 273, 116): [2661, 3148], (0, 273, 117): [2716, 2718], (0, 273, 118): [3482], (0, 273, 119): [2602, 3176], (0, 273, 121): [2994], (0, 273, 125): [3302], (0, 273, 127): [3811], (0, 273, 129): [2798], (0, 273, 131): [3682], (0, 273, 135): [3884], (0, 273, 136): [2961], (0, 273, 138): [4004], (0, 274, 116): [2660, 2720, 2722, 2920, 3147], (0, 274, 117): [2715, 2717, 3581], (0, 274, 118): [2744], (0, 274, 119): [3175], (0, 274, 120): [2756, 2758, 2760, 2762], (0, 274, 121): [2764, 3110], (0, 274, 125): [2998, 4196], (0, 274, 127): [3754], (0, 274, 129): [2963, 2965, 2982], (0, 274, 130): [2916, 2918], (0, 274, 133): [3823], (0, 274, 135): [3883], (0, 274, 136): [2960, 3881], (0, 274, 138): [4003], (0, 275, 119): [3313], (0, 275, 121): [3372], (0, 275, 123): [2736, 3404], (0, 275, 127): [3073], (0, 275, 130): [3294, 3296], (0, 276, 115): [2928, 3556, 3558], (0, 276, 116): [4111, 4181, 4183], (0, 276, 117): [3230, 3807, 3809], (0, 276, 118): [3950], (0, 276, 119): [2694, 2696, 3930, 4315], (0, 276, 122): [3088], (0, 276, 123): [3856], (0, 276, 124): [4008], (0, 276, 126): [4142], (0, 276, 127): [3978, 3980, 3982], (0, 276, 131): [2990, 4215, 4217], (0, 276, 133): [3858, 3984, 3986], (0, 276, 134): [4158], (0, 276, 135): [2950, 2952, 2954, 3266, 3268], (0, 276, 136): [4051, 4053, 4055, 4057, 4214], (0, 276, 137): [3773, 3805], (0, 276, 139): [4100], (0, 277, 115): [3300], (0, 277, 116): [3699, 3701, 3703, 3705], (0, 277, 117): [3885], (0, 277, 118): [3974, 3976], (0, 277, 123): [4282], (0, 277, 126): [4098], (0, 277, 128): [4280], (0, 277, 129): [3724, 3726], (0, 277, 134): [3920], (0, 277, 135): [3495], (0, 277, 136): [3378, 3380], (0, 278, 117): [3824], (0, 278, 118): [3949], (0, 278, 119): [3795, 3929, 4147], (0, 278, 123): [3855], (0, 278, 124): [3750, 4007], (0, 278, 125): [3871], (0, 278, 126): [4141], (0, 278, 127): [3977, 3979, 3981, 4045], (0, 278, 129): [4028, 4030, 4032, 4034], (0, 278, 130): [3931], (0, 278, 133): [3983, 3985], (0, 278, 135): [3265, 3267, 3765, 3767], (0, 278, 137): [3804], (0, 278, 139): [4099], (0, 279, 115): [2746, 3184, 3186], (0, 279, 117): [4204], (0, 279, 119): [2695, 2697, 2857], (0, 279, 120): [3475], (0, 279, 123): [3320, 3322, 3972, 4247], (0, 279, 124): [2622], (0, 279, 125): [2624], (0, 279, 128): [4106, 4108], (0, 279, 130): [3932, 4020], (0, 279, 131): [2670, 2825, 3002, 3004, 4018], (0, 279, 134): [3692], (0, 279, 135): [3060, 3062], (0, 279, 136): [3490], (0, 280, 125): [2874], (0, 281, 116): [3863], (0, 281, 117): [4143, 4145], (0, 281, 120): [3389], (0, 281, 124): [3735], (0, 281, 125): [4177], (0, 281, 126): [2667, 4235], (0, 281, 127): [4169, 4171], (0, 281, 128): [3424], (0, 281, 129): [3911, 3913, 4066], (0, 281, 130): [4019], (0, 281, 134): [3919, 4157], (0, 281, 135): [3494], (0, 281, 137): [3895, 3897, 4308], (0, 281, 138): [4306], (0, 281, 139): [4173], (0, 281, 140): [4256, 4258, 4260], (0, 282, 116): [3864], (0, 282, 117): [3886], (0, 282, 124): [3736], (0, 282, 126): [2668], (0, 282, 129): [3698], (0, 285, 115): [2927, 3459, 3555, 3557], (0, 285, 117): [3806, 3808], (0, 285, 118): [3708], (0, 285, 122): [3087], (0, 285, 123): [3012], (0, 285, 124): [3749], (0, 285, 125): [3943], (0, 285, 127): [3663], (0, 285, 133): [3857], (0, 285, 135): [2949, 2951, 2953], (0, 285, 136): [3377, 3379, 4050, 4052, 4054, 4056], (0, 286, 117): [3825], (0, 286, 126): [4236], (0, 287, 115): [2853], (0, 287, 117): [3090, 3194, 3452, 4144, 4146, 4320, 4322], (0, 287, 118): [2855, 3282], (0, 287, 119): [3314, 4134, 4136], (0, 287, 122): [3150], (0, 287, 123): [3130, 3132, 3134], (0, 287, 124): [2851, 3160, 3162], (0, 287, 126): [2867, 4279], (0, 287, 127): [4170, 4172], (0, 287, 128): [2845], (0, 287, 130): [3026, 3028], (0, 287, 131): [2898], (0, 287, 133): [3356, 3358, 3360], (0, 287, 135): [4084], (0, 287, 139): [4174], (0, 287, 140): [4257, 4259, 4261], (0, 288, 120): [3689], (0, 288, 128): [4189, 4191], (0, 288, 130): [3641], (0, 288, 133): [3665, 3667], (0, 288, 135): [3678, 4290], (0, 289, 119): [2930], (0, 291, 125): [3213, 3215], (0, 291, 133): [3217], (0, 292, 115): [3299, 3563], (0, 292, 116): [4285], (0, 292, 118): [3007, 3009, 3707, 3973, 3975], (0, 292, 120): [3474, 3649], (0, 292, 121): [3473], (0, 292, 122): [3341, 3408], (0, 292, 123): [3011], (0, 292, 124): [4041], (0, 292, 125): [3412, 4014, 4016, 4140, 4195], (0, 292, 126): [4097, 4278], (0, 292, 127): [3810], (0, 292, 128): [3297, 3990], (0, 292, 129): [3723, 3725], (0, 292, 133): [3543], (0, 292, 134): [3633, 3635], (0, 292, 136): [3819, 3933, 3935], (0, 292, 137): [4159, 4180], (0, 292, 138): [3787, 3789, 3791, 3793, 3945], (0, 292, 139): [4059], (0, 292, 140): [4293], (0, 293, 116): [3700, 3702, 3704, 3706], (0, 293, 118): [3008, 3010], (0, 293, 122): [3409], (0, 293, 124): [3454, 3456], (0, 293, 125): [3413, 3944], (0, 293, 128): [3298], (0, 293, 131): [4269, 4271, 4273], (0, 293, 134): [4219, 4221], (0, 293, 136): [3934, 3936], (0, 293, 138): [3946], (0, 296, 122): [3342], (0, 297, 115): [3524], (0, 297, 117): [3595], (0, 297, 120): [3643, 3645], (0, 299, 120): [3690], (0, 299, 127): [3680], (0, 299, 128): [4190, 4192], (0, 299, 130): [3642], (0, 299, 133): [3666, 3668], (0, 299, 134): [4220, 4222], (0, 299, 135): [4291], (0, 299, 137): [4309], (1, 1, 1): [1], (1, 10, 0): [21], (1, 22, 13): [185], (1, 22, 15): [290], (1, 22, 20): [687, 704], (1, 25, 14): [413], (1, 25, 18): [525, 544], (1, 25, 21): [751], (1, 28, 11): [99], (1, 32, 11): [64], (1, 39, 9): [103], (1, 41, 10): [246], (1, 41, 14): [521], (1, 42, 10): [121], (1, 45, 13): [184], (1, 47, 10): [143], (1, 48, 14): [180], (1, 52, 14): [412], (1, 54, 10): [218], (1, 57, 10): [323], (1, 58, 14): [216, 217], (1, 59, 21): [644, 764], (1, 62, 20): [431, 793], (1, 63, 14): [551], (1, 63, 20): [688], (1, 63, 21): [601, 743], (1, 65, 22): [720], (1, 66, 14): [496, 497], (1, 68, 14): [445], (1, 68, 21): [565], (1, 68, 23): [832], (1, 68, 25): [854], (1, 68, 28): [888], (1, 69, 18): [708], (1, 69, 22): [693], (1, 69, 46): [1233], (1, 69, 48): [1346], (1, 71, 19): [752], (1, 73, 84): [2182], (1, 77, 23): [833], (1, 83, 23): [820], (1, 89, 25): [852], (1, 90, 25): [853], (1, 91, 25): [855], (1, 92, 25): [856], (1, 94, 28): [861], (1, 96, 31): [878], (1, 130, 49): [1340], (1, 135, 46): [1059], (1, 135, 48): [1348], (1, 141, 48): [1347], (1, 143, 46): [1234], (1, 143, 48): [1368], (1, 150, 49): [1339], (1, 155, 48): [1367], (1, 161, 51): [1537], (1, 164, 55): [1650], (1, 165, 55): [1651], (1, 169, 51): [1538], (1, 172, 55): [1667], (1, 178, 57): [1655], (1, 179, 57): [1654], (1, 192, 73): [1831], (1, 194, 64): [1707], (1, 195, 62): [1742], (1, 199, 72): [1748], (1, 201, 73): [1927], (1, 201, 74): [1877, 1878], (1, 201, 78): [1957], (1, 202, 74): [1773, 1774], (1, 210, 74): [1786], (1, 212, 75): [2006], (1, 212, 81): [2104], (1, 214, 74): [1870], (1, 214, 75): [1946, 1990], (1, 214, 78): [1964], (1, 214, 86): [2303], (1, 216, 78): [1991], (1, 216, 83): [2075], (1, 216, 88): [2339], (1, 221, 82): [2155, 2178], (1, 222, 83): [2204], (1, 225, 84): [2493], (1, 225, 86): [2502], (1, 225, 87): [2387], (1, 234, 92): [2525, 2526], (1, 237, 94): [2530], (1, 241, 98): [2534], (1, 253, 113): [2578], (1, 256, 101): [2568], (1, 263, 123): [3638], (1, 263, 131): [3755], (1, 264, 136): [3239], (1, 265, 119): [3573], (1, 265, 121): [2644, 2801], (1, 265, 122): [3441], (1, 265, 124): [3540, 4129], (1, 265, 126): [3797], (1, 265, 127): [3504], (1, 265, 135): [3143], (1, 265, 137): [3733, 3947], (1, 266, 116): [3349], (1, 266, 119): [3083], (1, 266, 123): [2924], (1, 266, 129): [4114], (1, 266, 131): [3506, 3756], (1, 267, 117): [2587], (1, 267, 118): [3173], (1, 267, 129): [3171], (1, 268, 117): [2588], (1, 268, 119): [3584], (1, 268, 135): [3144], (1, 271, 134): [3031], (1, 272, 120): [4121], (1, 272, 121): [2802], (1, 272, 131): [3181], (1, 272, 134): [3426], (1, 272, 136): [3243], (1, 274, 119): [3084], (1, 274, 121): [2645], (1, 274, 131): [3507], (1, 274, 134): [3890], (1, 275, 118): [3174], (1, 275, 129): [3172], (1, 275, 132): [3269], (1, 276, 120): [2666, 4122], (1, 276, 129): [4113], (1, 276, 134): [3427], (1, 276, 136): [3244], (1, 278, 119): [3583], (1, 278, 120): [2665], (1, 278, 123): [2923], (1, 278, 134): [3889], (1, 278, 135): [3669], (1, 279, 115): [3324], (1, 279, 119): [3574], (1, 279, 127): [3505], (1, 279, 131): [3182], (1, 279, 137): [3734, 3948], (1, 281, 119): [3498], (1, 281, 123): [3637, 4035], (1, 281, 128): [2739, 3553], (1, 282, 119): [3499], (1, 282, 123): [4036], (1, 282, 124): [3541], (1, 282, 128): [2740, 3554], (1, 282, 130): [2879], (1, 285, 129): [3414], (1, 287, 122): [3442], (1, 287, 124): [4130], (1, 287, 134): [3032], (1, 287, 135): [3670], (1, 287, 136): [3240], (1, 288, 130): [2878], (1, 292, 123): [3893], (1, 292, 126): [4123, 4125], (1, 293, 126): [4124, 4126], (1, 293, 129): [3415], (1, 294, 116): [3350], (1, 294, 132): [3270], (1, 295, 115): [3323], (1, 299, 123): [3894], (2, 2, 1): [3], (2, 3, 1): [4], (2, 4, 1): [6], (2, 5, 1): [7], (2, 5, 4): [25], (2, 5, 23): [823], (2, 6, 1): [8], (2, 10, 2): [27], (2, 10, 35): [942], (2, 12, 4): [24], (2, 12, 14): [613, 619], (2, 12, 18): [633], (2, 12, 21): [646], (2, 12, 22): [695], (2, 12, 46): [1089], (2, 13, 0): [26], (2, 13, 4): [28, 29], (2, 14, 19): [808], (2, 14, 20): [772], (2, 18, 5): [43, 44], (2, 18, 6): [45], (2, 21, 51): [1489, 1491, 1516], (2, 21, 54): [1499, 1628], (2, 21, 55): [1502, 1504], (2, 21, 60): [1670, 1671], (2, 22, 9): [51], (2, 22, 10): [203, 204, 295, 310, 371, 390], (2, 22, 12): [88, 225], (2, 22, 13): [127, 284], (2, 22, 14): [258, 353, 354, 355, 423, 427, 428, 444, 491], (2, 22, 15): [298], (2, 22, 18): [527, 668], (2, 22, 19): [458, 637], (2, 22, 21): [605, 689, 748], (2, 22, 22): [705], (2, 24, 10): [53], (2, 24, 14): [123, 171], (2, 25, 10): [82], (2, 25, 12): [76], (2, 25, 13): [234, 235], (2, 25, 14): [233], (2, 25, 16): [287], (2, 25, 19): [825], (2, 27, 11): [79], (2, 28, 10): [74], (2, 28, 11): [77], (2, 28, 12): [67, 68], (2, 29, 10): [83], (2, 30, 10): [62, 113, 115], (2, 31, 10): [181], (2, 32, 11): [69], (2, 33, 11): [66], (2, 34, 10): [72], (2, 35, 10): [125], (2, 35, 14): [169], (2, 36, 10): [160], (2, 36, 12): [87], (2, 36, 14): [122], (2, 37, 10): [126], (2, 37, 12): [95, 108], (2, 37, 13): [130], (2, 37, 14): [140, 154], (2, 38, 11): [98], (2, 39, 10): [193, 205, 215, 341, 342], (2, 39, 13): [227, 286, 293], (2, 39, 16): [299, 300, 340], (2, 40, 13): [159], (2, 41, 10): [114, 116, 189, 191, 301, 313, 335], (2, 41, 12): [117, 207], (2, 41, 13): [244, 255, 257], (2, 41, 14): [132, 228, 229, 247, 322, 382, 457, 478, 552, 553, 563, 564], (2, 41, 15): [297], (2, 41, 16): [311, 319], (2, 41, 17): [321, 392, 393, 394, 400, 401], (2, 41, 18): [443, 519, 666], (2, 41, 19): [439, 505], (2, 41, 20): [451, 452, 558], (2, 41, 21): [691], (2, 42, 10): [219, 230], (2, 42, 12): [208, 226], (2, 42, 13): [131, 267], (2, 42, 16): [281], (2, 43, 10): [124], (2, 44, 14): [129], (2, 46, 13): [161], (2, 46, 15): [168], (2, 46, 20): [728], (2, 47, 12): [157], (2, 48, 12): [135], (2, 48, 14): [210], (2, 49, 10): [158], (2, 49, 14): [137, 138, 156], (2, 50, 14): [139], (2, 51, 13): [146], (2, 52, 19): [447, 811], (2, 52, 21): [541, 773], (2, 53, 10): [155, 188], (2, 54, 10): [167, 220, 262], (2, 54, 13): [245, 279, 280], (2, 56, 14): [248], (2, 56, 17): [344, 345], (2, 57, 10): [192, 309], (2, 57, 12): [197], (2, 58, 13): [272, 273, 274], (2, 58, 16): [372, 378, 405], (2, 59, 14): [473, 594], (2, 59, 19): [453], (2, 59, 21): [546], (2, 59, 23): [838], (2, 61, 13): [263], (2, 61, 37): [1027], (2, 62, 19): [536, 821], (2, 62, 21): [537], (2, 63, 14): [373, 532, 612], (2, 63, 21): [694], (2, 64, 14): [623], (2, 64, 16): [410, 411], (2, 64, 18): [599, 600], (2, 64, 21): [611], (2, 64, 22): [729], (2, 64, 23): [803], (2, 65, 14): [526, 549], (2, 65, 20): [456], (2, 65, 21): [698], (2, 65, 22): [697], (2, 65, 23): [837], (2, 66, 14): [620], (2, 66, 16): [414], (2, 66, 18): [492, 702], (2, 66, 19): [502, 845], (2, 66, 20): [489, 503, 504, 606], (2, 66, 21): [589], (2, 67, 16): [419], (2, 67, 18): [499], (2, 68, 20): [727], (2, 68, 29): [881], (2, 68, 31): [931, 933], (2, 69, 18): [650, 801], (2, 69, 19): [579], (2, 69, 20): [760], (2, 69, 21): [798], (2, 69, 47): [1317], (2, 69, 49): [1408], (2, 71, 22): [717], (2, 72, 18): [659], (2, 72, 19): [744], (2, 72, 21): [805], (2, 72, 23): [836], (2, 73, 23): [846], (2, 73, 78): [1999], (2, 73, 79): [2045], (2, 73, 83): [2141, 2202, 2306], (2, 73, 86): [2268, 2269], (2, 73, 87): [2357], (2, 74, 23): [839], (2, 75, 19): [844], (2, 76, 19): [768, 830], (2, 78, 18): [779], (2, 79, 19): [802], (2, 80, 23): [804], (2, 85, 24): [847], (2, 85, 31): [895], (2, 86, 24): [848], (2, 86, 32): [891], (2, 87, 25): [849], (2, 87, 33): [897], (2, 88, 26): [850, 851], (2, 88, 29): [864, 865], (2, 88, 30): [889], (2, 88, 31): [876, 896, 919, 920], (2, 88, 35): [927, 948, 985, 989], (2, 88, 36): [918, 977], (2, 89, 27): [857], (2, 91, 25): [862], (2, 91, 35): [950, 966, 968, 974, 976], (2, 92, 27): [859], (2, 92, 33): [899], (2, 93, 27): [858], (2, 95, 25): [863], (2, 96, 30): [867], (2, 97, 31): [883], (2, 98, 31): [884], (2, 99, 31): [882], (2, 101, 32): [892], (2, 102, 30): [893], (2, 103, 30): [894], (2, 103, 31): [905], (2, 103, 36): [935, 978], (2, 103, 44): [1038, 1039], (2, 104, 33): [898], (2, 106, 31): [906], (2, 106, 36): [936], (2, 108, 31): [932, 934], (2, 109, 35): [928], (2, 109, 55): [1526, 1528], (2, 110, 35): [952], (2, 111, 35): [941], (2, 115, 35): [949, 951, 965, 967, 973, 975, 984, 988, 1002, 1004, 1016], (2, 115, 36): [1012, 1014], (2, 116, 43): [1024], (2, 120, 35): [1003, 1005, 1017], (2, 120, 36): [1013, 1015], (2, 121, 37): [1011], (2, 122, 43): [1040], (2, 125, 37): [1031], (2, 127, 60): [1672], (2, 128, 37): [1041], (2, 130, 46): [1288, 1290], (2, 130, 47): [1415, 1429], (2, 130, 48): [1294, 1370, 1372], (2, 130, 49): [1385, 1387], (2, 131, 46): [1178], (2, 131, 47): [1261, 1263], (2, 131, 48): [1209], (2, 133, 45): [1123], (2, 133, 46): [1164], (2, 133, 47): [1113, 1152, 1211, 1213, 1230, 1239], (2, 133, 48): [1125], (2, 134, 45): [1084, 1107], (2, 134, 47): [1078, 1102, 1142], (2, 135, 45): [1072, 1073], (2, 135, 46): [1177, 1269], (2, 135, 47): [1318, 1443], (2, 135, 48): [1145, 1286, 1300], (2, 135, 49): [1350, 1409, 1413], (2, 136, 45): [1095, 1101, 1124], (2, 136, 46): [1083, 1087, 1088, 1165], (2, 136, 47): [1060, 1079, 1114, 1116, 1167, 1171, 1180], (2, 136, 48): [1126, 1172], (2, 138, 45): [1090, 1092], (2, 138, 46): [1176], (2, 138, 47): [1277, 1279, 1310], (2, 138, 48): [1149, 1205, 1217, 1274, 1276, 1379], (2, 138, 49): [1352, 1354], (2, 139, 45): [1091, 1093], (2, 140, 46): [1071], (2, 140, 47): [1155, 1157], (2, 141, 46): [1070, 1306], (2, 141, 47): [1278, 1280], (2, 141, 48): [1173, 1219, 1285, 1299, 1308], (2, 141, 49): [1349, 1412], (2, 142, 45): [1094, 1100], (2, 142, 46): [1086], (2, 142, 47): [1141, 1220, 1222], (2, 143, 46): [1179, 1270, 1272], (2, 143, 47): [1154, 1156, 1212, 1214, 1314, 1345, 1403, 1417, 1419], (2, 143, 48): [1210, 1360, 1407], (2, 143, 49): [1421], (2, 144, 46): [1082], (2, 144, 47): [1127, 1129, 1131, 1182, 1184, 1186, 1188, 1361, 1363, 1365], (2, 145, 45): [1085], (2, 146, 45): [1104, 1108], (2, 146, 46): [1271], (2, 146, 47): [1103, 1115, 1128, 1130, 1132, 1153, 1166, 1240], (2, 146, 48): [1218], (2, 147, 46): [1305], (2, 147, 47): [1170, 1309, 1414, 1428], (2, 147, 48): [1148, 1204, 1378, 1430, 1432], (2, 147, 49): [1351, 1353], (2, 149, 47): [1181, 1221, 1223], (2, 149, 48): [1251], (2, 150, 46): [1287, 1289], (2, 150, 47): [1232, 1244], (2, 150, 48): [1250, 1293, 1369, 1371, 1377, 1399], (2, 150, 49): [1391], (2, 151, 47): [1183, 1185, 1187, 1189, 1245, 1262, 1264], (2, 152, 48): [1273, 1275, 1431, 1433], (2, 153, 47): [1231], (2, 154, 47): [1246], (2, 155, 47): [1313, 1442], (2, 155, 48): [1307, 1398], (2, 155, 49): [1384, 1386, 1420], (2, 156, 47): [1416, 1418], (2, 156, 48): [1359, 1406], (2, 157, 47): [1344, 1362, 1364, 1366, 1402], (2, 157, 49): [1393], (2, 157, 50): [1445], (2, 158, 49): [1392], (2, 159, 50): [1444], (2, 160, 50): [1446], (2, 161, 51): [1474, 1476, 1495], (2, 161, 52): [1469, 1471], (2, 161, 54): [1483, 1485], (2, 162, 51): [1466], (2, 162, 54): [1512], (2, 163, 51): [1488, 1490, 1539, 1541], (2, 163, 54): [1498], (2, 164, 51): [1585, 1587], (2, 164, 53): [1617], (2, 164, 57): [1634, 1636], (2, 165, 51): [1467, 1586, 1588, 1598, 1626], (2, 165, 54): [1513], (2, 165, 55): [1653], (2, 166, 51): [1494], (2, 166, 52): [1468, 1470], (2, 166, 54): [1482, 1484], (2, 166, 55): [1557], (2, 167, 54): [1493], (2, 168, 51): [1475, 1477, 1607, 1609, 1643], (2, 168, 55): [1569, 1591], (2, 168, 57): [1633, 1635], (2, 169, 51): [1608, 1610], (2, 169, 53): [1530], (2, 170, 53): [1618], (2, 170, 54): [1492], (2, 170, 55): [1652], (2, 171, 51): [1517], (2, 171, 55): [1503, 1505], (2, 172, 51): [1540, 1542], (2, 172, 55): [1570, 1592], (2, 172, 57): [1623], (2, 173, 51): [1597], (2, 173, 55): [1550], (2, 173, 56): [1620], (2, 173, 57): [1624], (2, 174, 55): [1549], (2, 175, 53): [1529], (2, 175, 55): [1525, 1527, 1565], (2, 176, 51): [1563], (2, 176, 54): [1627], (2, 176, 56): [1619], (2, 177, 51): [1564, 1625, 1657], (2, 177, 55): [1558, 1566], (2, 178, 51): [1645], (2, 179, 51): [1644], (2, 179, 59): [1663, 1664], (2, 180, 51): [1656], (2, 180, 56): [1660, 1661], (2, 181, 55): [1665, 1666], (2, 181, 58): [1669], (2, 182, 60): [1673], (2, 184, 62): [1700, 1730, 1741], (2, 184, 63): [1676, 1692, 1693], (2, 184, 65): [1712], (2, 184, 66): [1703], (2, 184, 67): [1726, 1732], (2, 185, 62): [1677, 1738], (2, 185, 63): [1701], (2, 185, 66): [1698, 1699, 1714], (2, 185, 67): [1724, 1734, 1737], (2, 186, 63): [1680], (2, 187, 62): [1682, 1683, 1686, 1687, 1688], (2, 187, 63): [1690], (2, 188, 62): [1684], (2, 188, 64): [1696], (2, 188, 69): [1720], (2, 189, 62): [1689, 1694, 1702], (2, 189, 64): [1713], (2, 190, 62): [1691], (2, 190, 68): [1709], (2, 192, 62): [1729, 1736], (2, 192, 73): [1758, 1759, 1770, 1801, 1802, 1813, 1841], (2, 192, 82): [2161, 2181], (2, 192, 83): [2136, 2160, 2201, 2207, 2208], (2, 192, 86): [2218, 2307], (2, 192, 89): [2352, 2409, 2470], (2, 192, 90): [2512], (2, 194, 63): [1706], (2, 195, 62): [1739, 1740], (2, 196, 70): [1744], (2, 197, 72): [1747], (2, 199, 73): [1908, 1953, 1954, 1962], (2, 199, 77): [1860, 1865, 1974], (2, 199, 79): [2027], (2, 199, 81): [2074, 2085], (2, 199, 82): [2112, 2132, 2146, 2183], (2, 199, 83): [2243], (2, 199, 84): [2197], (2, 200, 73): [1752, 1753], (2, 200, 74): [1867, 1868], (2, 200, 75): [1755, 1756], (2, 200, 77): [1861, 1862], (2, 201, 73): [1857, 1911, 1943, 1944, 1945, 1950], (2, 201, 74): [1754], (2, 201, 75): [1956, 2008], (2, 201, 77): [1863, 1864, 1896, 1898], (2, 201, 78): [2007], (2, 201, 83): [2159], (2, 201, 84): [2200, 2263, 2272], (2, 201, 85): [2189, 2191], (2, 201, 86): [2288, 2332], (2, 201, 87): [2399, 2410], (2, 201, 89): [2382, 2396, 2404, 2405, 2406, 2407, 2416, 2433], (2, 202, 73): [1881, 1882], (2, 202, 74): [1757, 1869], (2, 202, 77): [1796, 1847, 1884], (2, 203, 83): [2250], (2, 203, 85): [2192], (2, 203, 86): [2373], (2, 203, 89): [2499], (2, 204, 74): [1781, 1782], (2, 205, 73): [1775, 1808, 1811, 1812, 1822, 1823], (2, 205, 74): [1777, 1816, 1827], (2, 205, 75): [1780], (2, 205, 77): [1866], (2, 206, 73): [1807], (2, 206, 74): [1810], (2, 206, 77): [1788], (2, 207, 73): [1769], (2, 207, 74): [1768, 1817], (2, 208, 73): [1836, 1942], (2, 208, 74): [1806], (2, 208, 75): [2025], (2, 208, 79): [2013, 2014], (2, 208, 82): [2073, 2117, 2157], (2, 208, 83): [2097], (2, 208, 84): [2273], (2, 208, 86): [2252, 2321, 2322], (2, 208, 89): [2435, 2446, 2453, 2454], (2, 209, 73): [1858, 1859, 1886, 1887], (2, 210, 74): [1829], (2, 211, 73): [1826, 1832, 1892, 1917, 1955, 1969], (2, 211, 74): [1799, 1800, 1855, 1856, 1933], (2, 211, 75): [1986], (2, 211, 77): [1910], (2, 211, 79): [2044], (2, 211, 80): [2042], (2, 211, 82): [2139, 2145], (2, 211, 83): [2105, 2195, 2206, 2251, 2255, 2260, 2261], (2, 211, 84): [2150, 2169, 2170, 2222, 2244], (2, 211, 86): [2245], (2, 212, 73): [1961], (2, 212, 74): [1912], (2, 212, 75): [1988, 1989], (2, 212, 78): [2011], (2, 212, 79): [2026], (2, 212, 82): [2106, 2140], (2, 212, 83): [2153, 2193], (2, 212, 84): [2365, 2386], (2, 212, 87): [2458], (2, 212, 89): [2395, 2520], (2, 212, 90): [2490], (2, 214, 73): [1880], (2, 214, 80): [2043], (2, 214, 81): [2086], (2, 214, 82): [2144, 2165, 2166], (2, 214, 83): [2124, 2125, 2129], (2, 216, 84): [2164, 2179], (2, 216, 86): [2219, 2220, 2297], (2, 216, 87): [2383], (2, 216, 88): [2482], (2, 216, 89): [2449], (2, 217, 73): [1958, 1960, 1984], (2, 217, 75): [1978, 2002, 2023, 2024], (2, 217, 79): [2048], (2, 217, 81): [2051, 2084], (2, 218, 82): [2091], (2, 220, 81): [2083], (2, 221, 82): [2123, 2163], (2, 221, 84): [2147, 2248, 2254, 2305, 2331], (2, 222, 82): [2151], (2, 222, 83): [2180, 2185, 2194], (2, 222, 84): [2148, 2149, 2234, 2425], (2, 222, 86): [2328], (2, 222, 87): [2398, 2455], (2, 222, 89): [2358, 2359, 2408, 2451, 2468], (2, 223, 83): [2265, 2282, 2283, 2310], (2, 223, 84): [2226, 2227, 2228, 2286], (2, 223, 86): [2229, 2230, 2231], (2, 223, 87): [2329], (2, 223, 89): [2391], (2, 224, 84): [2364], (2, 224, 87): [2477], (2, 225, 84): [2403], (2, 225, 86): [2495], (2, 225, 87): [2472], (2, 225, 89): [2469], (2, 226, 86): [2267], (2, 228, 83): [2311], (2, 228, 84): [2302], (2, 228, 87): [2374, 2445], (2, 228, 89): [2457, 2461, 2462, 2487, 2488, 2500, 2501], (2, 228, 90): [2491, 2492], (2, 229, 84): [2363], (2, 230, 88): [2402], (2, 230, 89): [2400], (2, 231, 87): [2450], (2, 237, 98): [2574], (2, 238, 95): [2531], (2, 238, 101): [2576], (2, 238, 108): [2556, 2570], (2, 239, 96): [2532], (2, 240, 97): [2533], (2, 241, 94): [2561], (2, 241, 105): [2563], (2, 243, 99): [2539], (2, 244, 96): [2540], (2, 246, 104): [2544], (2, 246, 112): [2581], (2, 247, 95): [2546], (2, 250, 109): [2557], (2, 251, 94): [2580], (2, 253, 107): [2555], (2, 254, 101): [2562], (2, 257, 97): [2569], (2, 258, 99): [2572, 2573], (2, 259, 103): [2575], (2, 260, 112): [2577], (2, 261, 114): [2579], (2, 262, 109): [2582], (2, 263, 118): [3430], (2, 263, 127): [4012], (2, 263, 129): [3137, 3438, 3440, 3846], (2, 263, 130): [3476], (2, 263, 133): [4252], (2, 264, 115): [3562], (2, 264, 117): [3770], (2, 264, 120): [3772, 3907], (2, 264, 126): [3958], (2, 264, 128): [3960, 3962], (2, 264, 131): [4120], (2, 264, 133): [3463, 3465, 3661], (2, 264, 134): [4116], (2, 264, 135): [3628], (2, 264, 138): [3820], (2, 264, 139): [4312], (2, 265, 115): [2846, 3225, 3388, 3449], (2, 265, 116): [2643, 2700, 3468, 3923, 3925], (2, 265, 117): [2913, 3127, 3721], (2, 265, 118): [2738, 2779, 3751, 4239], (2, 265, 119): [3196, 4298], (2, 265, 120): [2708, 2890, 3237, 3603], (2, 265, 121): [2615, 2955, 3491], (2, 265, 124): [3901], (2, 265, 125): [3169, 3255, 3835], (2, 265, 126): [2658, 3621], (2, 265, 127): [2816, 2818, 3609, 3653, 3747, 3851, 3853], (2, 265, 128): [2725, 3207, 3510], (2, 265, 129): [2807, 2991, 3343, 3345], (2, 265, 130): [3251, 3253, 3354, 3939], (2, 265, 131): [2713, 2939, 3099, 3105, 3395], (2, 265, 132): [3051, 3187, 3189], (2, 265, 133): [3167, 3743, 3745, 3951, 4310], (2, 265, 134): [2947, 3115, 4156], (2, 265, 135): [3577, 3579, 3601, 3991], (2, 265, 136): [3136, 3717, 3759, 3800, 3833, 4240], (2, 265, 138): [3937, 4109], (2, 266, 115): [2896], (2, 266, 119): [2806, 4299], (2, 266, 120): [3604], (2, 266, 121): [2811, 2813, 2956], (2, 266, 123): [2799, 3869], (2, 266, 125): [4231], (2, 266, 127): [3232, 3234], (2, 266, 128): [3657, 3831, 4302], (2, 266, 129): [2647], (2, 266, 131): [2747, 2748, 2837, 3483, 3565], (2, 266, 132): [3038, 3040], (2, 266, 134): [4115, 4300], (2, 266, 135): [3602, 3859], (2, 266, 137): [3761], (2, 266, 138): [3938], (2, 267, 115): [2590, 2698, 3045], (2, 267, 116): [2593], (2, 267, 117): [2591, 2686], (2, 267, 118): [2941], (2, 267, 119): [2627], (2, 267, 120): [3141, 3587], (2, 267, 121): [2607, 3514], (2, 267, 122): [2985], (2, 267, 123): [3145], (2, 267, 126): [2625], (2, 267, 129): [2704, 3259], (2, 267, 131): [2714], (2, 267, 132): [2832, 2834], (2, 267, 136): [3019, 3021], (2, 268, 115): [3046, 3226], (2, 268, 117): [2687], (2, 268, 118): [2831], (2, 268, 119): [3054], (2, 268, 120): [2606, 3588], (2, 268, 121): [2608, 3290, 3292, 3515], (2, 268, 122): [2683, 2986], (2, 268, 124): [2836, 3306, 3479], (2, 268, 127): [2681], (2, 268, 128): [2873], (2, 268, 129): [2766, 2768], (2, 268, 130): [2827, 3165], (2, 268, 131): [3286], (2, 268, 132): [2833, 2835], (2, 268, 136): [3020, 3022], (2, 269, 115): [2589], (2, 270, 116): [2594], (2, 270, 117): [2592], (2, 270, 125): [2656], (2, 270, 129): [2705], (2, 270, 130): [2655], (2, 271, 124): [3163], (2, 271, 125): [3256], (2, 271, 126): [3235], (2, 271, 127): [2773, 3033, 3257], (2, 271, 128): [3208], (2, 271, 129): [3260], (2, 271, 132): [3029], (2, 272, 115): [2699, 3250], (2, 272, 116): [3469, 3763, 3842, 4063, 4167], (2, 272, 117): [2769, 2892, 3569, 3571, 3814], (2, 272, 118): [2780, 3651, 3752], (2, 272, 120): [2891, 2905, 3142, 3576, 4005, 4207], (2, 272, 121): [2616], (2, 272, 122): [3283], (2, 272, 124): [2911, 3305], (2, 272, 125): [2777], (2, 272, 126): [4138], (2, 272, 127): [3654, 3748, 3852, 3854, 4068], (2, 272, 128): [2726, 3511, 3537, 3959, 3961], (2, 272, 129): [2646, 2765, 2767, 2808, 2992, 3916], (2, 272, 130): [3101], (2, 272, 131): [3100, 3106], (2, 272, 132): [3095, 3443, 3445], (2, 272, 133): [3097, 3280, 3744, 3746, 4289, 4311], (2, 272, 134): [3116, 3779, 3843, 3995, 4064, 4186, 4199], (2, 272, 135): [3058, 3578, 3580], (2, 272, 136): [3676, 3760], (2, 272, 137): [4248], (2, 273, 116): [2839], (2, 273, 122): [2959], (2, 273, 125): [4232], (2, 273, 126): [3830], (2, 273, 127): [4226], (2, 273, 128): [3832], (2, 273, 129): [3998], (2, 273, 132): [3364, 3366], (2, 273, 133): [3662], (2, 274, 116): [2838, 2966, 3307, 3918, 4022, 4024], (2, 274, 117): [2914], (2, 274, 119): [3311], (2, 274, 120): [3309, 3876], (2, 274, 121): [2812, 2814], (2, 274, 123): [2800, 2910, 3870, 4305], (2, 274, 124): [2649, 2651, 2653], (2, 274, 125): [3803], (2, 274, 126): [3829], (2, 274, 127): [3610, 4225], (2, 274, 128): [3658, 4303], (2, 274, 129): [3997], (2, 274, 131): [3566, 3612], (2, 274, 132): [3363, 3365, 3486], (2, 274, 133): [4228, 4253], (2, 274, 134): [3261, 3263, 4301], (2, 274, 136): [3370], (2, 274, 137): [3762, 3874], (2, 275, 117): [2691], (2, 275, 118): [2942], (2, 275, 119): [2628, 3493], (2, 275, 120): [2605, 3238], (2, 275, 121): [3492], (2, 275, 123): [3146], (2, 275, 124): [2648, 2650, 2652], (2, 275, 126): [3236], (2, 275, 127): [2680, 3258], (2, 275, 128): [2872], (2, 275, 130): [2826], (2, 275, 131): [2940], (2, 276, 117): [2663, 2863, 3272, 3274, 3406, 3570, 4070], (2, 276, 118): [3608, 4102], (2, 276, 119): [3955, 4072], (2, 276, 120): [3771], (2, 276, 122): [2664, 2796, 3156], (2, 276, 123): [2957, 3626], (2, 276, 124): [4243], (2, 276, 125): [3352, 3730], (2, 276, 126): [2675, 3018, 3154, 4049, 4074], (2, 276, 127): [3231, 3233, 4104, 4118], (2, 276, 128): [3879, 4076, 4318], (2, 276, 129): [3397, 3532, 3892, 3922, 4250], (2, 276, 130): [3539], (2, 276, 132): [3382, 3429], (2, 276, 133): [3906], (2, 276, 134): [4164], (2, 276, 135): [3304], (2, 276, 136): [4165], (2, 276, 138): [3838, 3954], (2, 277, 115): [2847], (2, 277, 116): [3228], (2, 277, 117): [3815, 3840, 4297], (2, 277, 118): [4009], (2, 277, 119): [3956], (2, 277, 122): [3284], (2, 277, 123): [2958, 3727], (2, 277, 124): [3044], (2, 277, 125): [3222], (2, 277, 126): [2659, 3868], (2, 277, 129): [3533], (2, 277, 130): [3783], (2, 277, 133): [3496, 3585], (2, 277, 135): [3224, 3686, 3731, 4295], (2, 277, 136): [3200], (2, 277, 137): [4249], (2, 278, 116): [3924, 3926], (2, 278, 117): [2662, 2690, 2862, 3271, 3273, 3572, 4069, 4296], (2, 278, 118): [2830, 3607, 4101], (2, 278, 119): [2805, 4071, 4206], (2, 278, 120): [3826, 3875, 4208], (2, 278, 122): [2682, 2795, 3155], (2, 278, 123): [4304], (2, 278, 124): [3531, 3567, 3590], (2, 278, 125): [3351, 3729], (2, 278, 126): [2676, 3017, 3153, 4048, 4073], (2, 278, 127): [4078, 4103, 4117], (2, 278, 128): [2679, 2904, 4075], (2, 278, 129): [3921, 4161, 4287], (2, 278, 130): [3102], (2, 278, 131): [3285, 4119], (2, 278, 132): [3381, 3428, 3485], (2, 278, 133): [3781, 3905], (2, 278, 134): [3996, 4163], (2, 278, 135): [3303], (2, 278, 137): [3873], (2, 278, 138): [3953], (2, 279, 115): [3450], (2, 279, 116): [4168], (2, 279, 117): [3722], (2, 279, 118): [3652, 3888], (2, 279, 125): [2778], (2, 279, 126): [3622], (2, 279, 128): [3559, 3624], (2, 279, 129): [3344, 3346, 4162], (2, 279, 130): [3394], (2, 279, 132): [3052, 3096, 3188, 3190, 3444, 3446], (2, 279, 133): [3098], (2, 279, 134): [2948, 3780, 4065], (2, 279, 136): [3801, 3834, 4241], (2, 279, 138): [4255], (2, 280, 117): [2770], (2, 280, 126): [2626], (2, 281, 115): [3387], (2, 281, 116): [2634, 2642, 4021, 4023], (2, 281, 117): [4233], (2, 281, 118): [2737, 3887, 4187], (2, 281, 119): [2868, 2870, 3195, 3613, 3615, 3617, 3619], (2, 281, 120): [2636, 3899, 4153], (2, 281, 122): [3400], (2, 281, 123): [2727, 2729, 3487], (2, 281, 124): [3530, 3719, 4242], (2, 281, 125): [4079], (2, 281, 126): [2821, 3245, 3671, 3957, 4137, 4209], (2, 281, 127): [2815, 2817, 4011, 4077], (2, 281, 128): [3549, 3551, 3623], (2, 281, 129): [3915], (2, 281, 130): [2803, 3353, 3393], (2, 281, 131): [3673], (2, 281, 133): [2945], (2, 281, 134): [3373, 3528, 4025, 4155], (2, 281, 135): [3597], (2, 281, 136): [3135, 3675], (2, 281, 137): [3861, 3941], (2, 281, 138): [4081, 4254], (2, 282, 116): [2635], (2, 282, 117): [4234], (2, 282, 118): [4188], (2, 282, 119): [2869, 2871, 3614, 3616, 3618, 3620], (2, 282, 120): [2637, 3248, 3458, 3900, 3908, 4154], (2, 282, 122): [3401], (2, 282, 123): [2728, 2730, 3488], (2, 282, 124): [3720], (2, 282, 126): [2822, 3246, 3672, 4210], (2, 282, 127): [3904], (2, 282, 128): [3550, 3552, 4128], (2, 282, 129): [3509], (2, 282, 130): [2804], (2, 282, 134): [3374, 3529, 4026], (2, 282, 135): [3992], (2, 282, 136): [4150], (2, 282, 137): [3862, 3942], (2, 282, 138): [4082], (2, 283, 130): [2654], (2, 284, 125): [2657], (2, 285, 115): [3249], (2, 285, 116): [2701, 4062], (2, 285, 117): [3769], (2, 285, 118): [3241], (2, 285, 119): [3333, 3816, 4205], (2, 285, 123): [3625], (2, 285, 124): [3589, 3902], (2, 285, 125): [3221], (2, 285, 127): [3367], (2, 285, 128): [2903, 4317], (2, 285, 129): [3396, 3600, 3891], (2, 285, 130): [3252, 3254], (2, 285, 131): [3964], (2, 285, 133): [4288], (2, 285, 134): [4185], (2, 285, 135): [3057, 3685, 3966, 3968], (2, 285, 136): [3199], (2, 285, 137): [4060], (2, 285, 138): [3837], (2, 286, 116): [3764], (2, 286, 120): [3247, 3457, 3827], (2, 286, 127): [3460, 3903], (2, 286, 128): [4127], (2, 286, 129): [3508], (2, 286, 131): [3674], (2, 286, 133): [2946, 3462, 3464], (2, 286, 135): [3598], (2, 286, 136): [4149, 4166], (2, 287, 117): [3128, 4047], (2, 287, 124): [3164], (2, 287, 125): [3170], (2, 287, 126): [3878], (2, 287, 127): [2774, 3034, 3461], (2, 287, 129): [3138, 4251], (2, 287, 130): [3166, 3477], (2, 287, 131): [3484], (2, 287, 132): [3030], (2, 287, 133): [3168, 3952], (2, 287, 136): [3718], (2, 287, 138): [3821], (2, 288, 116): [3917, 4197], (2, 288, 117): [2893], (2, 288, 118): [3737, 3739], (2, 288, 119): [3053], (2, 288, 123): [2909], (2, 288, 124): [2912], (2, 288, 125): [3836, 4151, 4152], (2, 288, 126): [3877], (2, 288, 129): [4223], (2, 288, 130): [3538], (2, 288, 132): [3037, 3039], (2, 288, 135): [3211], (2, 288, 136): [3369], (2, 289, 120): [2906], (2, 291, 121): [3289, 3291], (2, 291, 124): [3478, 3568], (2, 292, 116): [3093, 3227, 3841, 3993], (2, 292, 117): [3839], (2, 292, 120): [3575], (2, 292, 123): [3999], (2, 292, 124): [3043], (2, 292, 125): [4080], (2, 292, 126): [3867], (2, 292, 128): [3536], (2, 292, 129): [3599, 3865, 4286], (2, 292, 130): [3940, 4274, 4276], (2, 292, 131): [3611, 3655, 3963], (2, 292, 133): [3279, 4227], (2, 292, 135): [3223, 3965, 3967, 4294], (2, 292, 136): [3683], (2, 293, 116): [3094, 3994], (2, 293, 117): [3407], (2, 293, 118): [3242, 4010], (2, 293, 119): [3334, 3817], (2, 293, 120): [4006], (2, 293, 123): [3728, 4000], (2, 293, 128): [3560, 3880], (2, 293, 129): [3866], (2, 293, 130): [3784, 4275, 4277], (2, 293, 131): [3656], (2, 293, 133): [3497, 3586, 3782], (2, 293, 134): [3844, 4200], (2, 293, 135): [3732], (2, 293, 136): [3684], (2, 294, 116): [3308], (2, 294, 119): [3312], (2, 294, 120): [3310], (2, 294, 127): [3368], (2, 294, 134): [3262, 3264], (2, 294, 135): [3212], (2, 297, 115): [3561], (2, 297, 125): [3802], (2, 297, 129): [3437, 3439, 3845], (2, 297, 135): [3627], (2, 299, 116): [4198], (2, 299, 118): [3738, 3740], (2, 299, 129): [4224], (2, 299, 135): [3860], (2, 299, 137): [4061], (2, 299, 138): [4110], (3, 5, 1): [12, 14], (3, 7, 1): [11, 13], (3, 12, 18): [667], (3, 14, 14): [582, 583], (3, 14, 19): [713], (3, 14, 20): [797], (3, 21, 55): [1602], (3, 22, 10): [249], (3, 22, 13): [256], (3, 22, 14): [516], (3, 22, 17): [361], (3, 22, 21): [634], (3, 25, 16): [391], (3, 25, 20): [441], (3, 31, 11): [84], (3, 35, 12): [86], (3, 39, 10): [278], (3, 39, 14): [418], (3, 39, 16): [370], (3, 39, 19): [735], (3, 41, 10): [266], (3, 41, 13): [285], (3, 41, 14): [376, 399, 617, 618], (3, 41, 18): [515], (3, 41, 19): [490], (3, 42, 12): [214], (3, 42, 13): [202], (3, 46, 10): [194], (3, 46, 14): [506], (3, 47, 10): [254], (3, 48, 10): [395], (3, 48, 14): [375], (3, 48, 16): [307], (3, 52, 10): [396], (3, 52, 14): [404, 542], (3, 52, 21): [824], (3, 56, 14): [240], (3, 57, 10): [209], (3, 58, 10): [377], (3, 58, 12): [213], (3, 59, 21): [828], (3, 60, 10): [231], (3, 62, 19): [522], (3, 62, 21): [626], (3, 63, 22): [709], (3, 64, 16): [407], (3, 64, 20): [703], (3, 64, 22): [742], (3, 66, 22): [692], (3, 69, 14): [575], (3, 73, 18): [747], (3, 73, 88): [2334], (3, 78, 23): [812], (3, 91, 34): [925], (3, 91, 36): [964], (3, 104, 31): [908], (3, 104, 32): [910], (3, 107, 31): [909], (3, 107, 34): [926], (3, 115, 36): [963], (3, 116, 36): [1018], (3, 120, 36): [1019], (3, 122, 42): [1023], (3, 125, 44): [1053], (3, 127, 51): [1668], (3, 138, 46): [1321], (3, 141, 46): [1322], (3, 143, 48): [1343], (3, 146, 48): [1266, 1267], (3, 150, 48): [1265, 1341], (3, 154, 48): [1268], (3, 157, 48): [1342], (3, 161, 55): [1514], (3, 163, 53): [1522], (3, 163, 55): [1533], (3, 166, 53): [1521], (3, 168, 55): [1534], (3, 170, 61): [1674], (3, 171, 55): [1515], (3, 176, 55): [1601], (3, 181, 58): [1662], (3, 184, 62): [1722], (3, 189, 63): [1685], (3, 192, 62): [1731], (3, 192, 74): [1793], (3, 192, 75): [1783], (3, 192, 83): [2271], (3, 192, 84): [2210, 2211], (3, 192, 86): [2223], (3, 199, 73): [1925], (3, 199, 83): [2143, 2168], (3, 199, 84): [2177], (3, 201, 73): [1979], (3, 201, 74): [1805, 1875], (3, 201, 79): [2019], (3, 201, 82): [2088], (3, 201, 83): [2176, 2291], (3, 201, 86): [2264], (3, 201, 87): [2397], (3, 202, 74): [1897], (3, 203, 81): [2094], (3, 203, 89): [2366], (3, 203, 90): [2498], (3, 204, 73): [1821], (3, 204, 74): [1785, 1853], (3, 204, 75): [1792], (3, 205, 74): [1809], (3, 207, 74): [1883], (3, 207, 77): [1900], (3, 208, 75): [1947], (3, 208, 78): [1970], (3, 208, 81): [2111], (3, 208, 82): [2087], (3, 209, 75): [1843, 1844], (3, 211, 73): [1838], (3, 213, 74): [1854], (3, 214, 73): [1941], (3, 214, 75): [1998], (3, 214, 81): [2103], (3, 214, 83): [2107], (3, 214, 84): [2142, 2385], (3, 216, 79): [2050], (3, 216, 81): [2052], (3, 216, 82): [2089, 2154, 2173], (3, 216, 83): [2127], (3, 216, 84): [2247, 2281], (3, 216, 86): [2249], (3, 216, 89): [2436, 2519], (3, 217, 80): [2065], (3, 219, 80): [2022], (3, 221, 82): [2138], (3, 221, 84): [2156], (3, 222, 84): [2293], (3, 222, 89): [2447, 2480], (3, 223, 83): [2279], (3, 223, 87): [2330], (3, 224, 86): [2368, 2369], (3, 224, 91): [2522], (3, 228, 86): [2384], (3, 228, 89): [2486], (3, 229, 87): [2346], (3, 234, 102): [2541], (3, 242, 99): [2553], (3, 246, 99): [2552], (3, 252, 99): [2554], (3, 263, 116): [3178, 3180], (3, 263, 118): [2684], (3, 263, 128): [3503], (3, 264, 118): [2685], (3, 264, 126): [3348], (3, 264, 129): [2995], (3, 265, 115): [3201, 3203], (3, 265, 116): [2632, 3177, 3179], (3, 265, 118): [3647, 3849], (3, 265, 120): [2858, 3049], (3, 265, 122): [2741, 3047], (3, 265, 123): [3847], (3, 265, 125): [2828], (3, 265, 126): [3347], (3, 265, 127): [3123], (3, 265, 128): [3502], (3, 265, 129): [3909], (3, 265, 130): [2882], (3, 265, 131): [2688, 2706, 2819], (3, 265, 132): [3376], (3, 265, 136): [3544], (3, 266, 116): [3517, 3519], (3, 266, 120): [4037, 4039], (3, 266, 124): [3606], (3, 266, 126): [2753], (3, 266, 128): [2921], (3, 266, 130): [3435], (3, 266, 131): [2968], (3, 266, 132): [3076], (3, 266, 136): [2984], (3, 267, 115): [3202, 3204], (3, 267, 118): [4131], (3, 267, 129): [3361], (3, 267, 134): [3005], (3, 268, 119): [3480], (3, 268, 124): [2724], (3, 268, 129): [3362], (3, 268, 133): [3403], (3, 268, 134): [3006], (3, 270, 131): [2689], (3, 271, 119): [3103], (3, 271, 126): [2907], (3, 271, 127): [3124], (3, 272, 116): [2633], (3, 272, 117): [3383], (3, 272, 118): [3648, 3850], (3, 272, 120): [2859, 3050], (3, 272, 122): [3048, 3325], (3, 272, 125): [2829], (3, 272, 126): [3988, 4244], (3, 272, 127): [2899, 3741], (3, 272, 128): [3757], (3, 272, 130): [2883], (3, 272, 131): [2820], (3, 272, 138): [4002], (3, 273, 116): [3688], (3, 273, 120): [2604, 4038, 4040], (3, 273, 126): [2754], (3, 273, 128): [2922], (3, 273, 133): [3640, 4176], (3, 273, 135): [3332], (3, 273, 139): [4238], (3, 274, 116): [3527], (3, 274, 120): [2603], (3, 274, 124): [3316], (3, 274, 127): [3742], (3, 274, 129): [3910], (3, 274, 130): [3436], (3, 274, 133): [4175], (3, 274, 135): [3696], (3, 275, 118): [4132], (3, 275, 119): [3104], (3, 275, 124): [2723], (3, 275, 133): [3402], (3, 276, 116): [3660], (3, 276, 121): [2617, 2944], (3, 276, 123): [2620, 2841], (3, 276, 124): [3082, 3605], (3, 276, 127): [2631], (3, 276, 130): [4096], (3, 276, 132): [3075], (3, 276, 133): [3639], (3, 276, 135): [3331], (3, 277, 118): [4212], (3, 277, 121): [2618], (3, 278, 115): [2790], (3, 278, 116): [3526, 3659, 3687], (3, 278, 117): [3384], (3, 278, 118): [4211], (3, 278, 123): [2619, 2840], (3, 278, 124): [3081, 3315], (3, 278, 125): [3086], (3, 278, 128): [3758], (3, 278, 130): [4095], (3, 278, 131): [2707, 3812], (3, 279, 122): [2742, 3326], (3, 280, 127): [2900], (3, 281, 115): [2789], (3, 281, 117): [2901], (3, 281, 118): [3197], (3, 281, 126): [3191], (3, 281, 128): [3798], (3, 281, 130): [3139], (3, 281, 132): [3375], (3, 281, 133): [3693, 3785], (3, 281, 134): [3512], (3, 282, 117): [2902], (3, 282, 118): [3198], (3, 282, 123): [3391], (3, 282, 125): [3521], (3, 282, 133): [3694, 3786], (3, 282, 134): [3513], (3, 285, 121): [2943], (3, 285, 125): [3085], (3, 285, 126): [3987], (3, 287, 123): [3848], (3, 287, 126): [2908, 3192], (3, 287, 129): [2996], (3, 288, 117): [3709], (3, 288, 118): [4043], (3, 290, 131): [2967], (3, 291, 116): [3516, 3518], (3, 291, 125): [3520], (3, 291, 136): [2983], (3, 292, 127): [4193], (3, 292, 128): [3799], (3, 292, 135): [3695], (3, 292, 138): [4001], (3, 292, 139): [4237], (3, 293, 127): [4194], (3, 293, 131): [3813], (3, 294, 130): [3140], (3, 298, 134): [3466], (3, 299, 117): [3710], (3, 299, 118): [4044], (3, 299, 126): [4245], (3, 299, 134): [3467], (4, 12, 20): [790], (4, 12, 22): [696], (4, 14, 0): [30, 31], (4, 14, 18): [477], (4, 20, 8): [47, 49], (4, 20, 37): [1034], (4, 20, 42): [1028], (4, 21, 8): [48, 50], (4, 22, 17): [350], (4, 22, 18): [576, 726], (4, 22, 19): [462, 463, 464, 465, 466], (4, 22, 20): [486, 487, 488], (4, 25, 18): [660, 661, 662, 663], (4, 35, 10): [85], (4, 41, 13): [118], (4, 41, 14): [436], (4, 41, 16): [398], (4, 41, 17): [351], (4, 56, 14): [190], (4, 61, 44): [1045, 1046, 1047, 1048, 1050], (4, 62, 18): [679, 680, 681, 682, 683], (4, 63, 21): [770], (4, 64, 22): [739], (4, 66, 14): [435, 569], (4, 66, 19): [467, 468, 469, 470, 471, 472, 529], (4, 66, 21): [642], (4, 66, 22): [706, 707], (4, 67, 14): [512], (4, 67, 18): [520], (4, 68, 18): [658], (4, 68, 21): [684, 685], (4, 69, 18): [669, 670, 671, 672, 673, 674, 675, 676, 677, 678], (4, 69, 21): [710], (4, 70, 14): [624, 625], (4, 73, 18): [723], (4, 73, 21): [749], (4, 73, 75): [2033, 2034, 2035, 2036], (4, 73, 83): [2232, 2298], (4, 73, 86): [2233], (4, 73, 89): [2353, 2354], (4, 74, 18): [754, 755, 756, 757, 758], (4, 74, 19): [778], (4, 82, 23): [818], (4, 85, 28): [869, 875], (4, 85, 30): [866, 873, 874], (4, 88, 35): [917, 930], (4, 88, 41): [1010], (4, 91, 32): [887], (4, 91, 36): [983], (4, 103, 44): [1044], (4, 110, 35): [929], (4, 115, 36): [982], (4, 122, 42): [1020], (4, 123, 37): [1021, 1032], (4, 123, 42): [1029], (4, 125, 43): [1033], (4, 127, 56): [1658], (4, 129, 43): [1049], (4, 130, 37): [1054], (4, 133, 48): [1237, 1241], (4, 135, 49): [1336], (4, 136, 47): [1161, 1163], (4, 146, 48): [1238, 1243], (4, 147, 47): [1160, 1162], (4, 150, 48): [1242], (4, 150, 49): [1337], (4, 154, 47): [1374, 1376], (4, 155, 47): [1373, 1375], (4, 155, 49): [1335], (4, 155, 50): [1460], (4, 156, 50): [1461], (4, 157, 49): [1338], (4, 164, 54): [1572], (4, 164, 56): [1638], (4, 165, 54): [1568], (4, 168, 56): [1637], (4, 173, 51): [1518], (4, 175, 54): [1567, 1571], (4, 176, 56): [1659], (4, 192, 73): [1750, 1751], (4, 192, 86): [2224, 2225], (4, 192, 88): [2378, 2379], (4, 199, 77): [1901], (4, 199, 82): [2108, 2109], (4, 199, 84): [2196], (4, 201, 73): [1966], (4, 201, 77): [1918, 1919, 1920, 1921, 1922], (4, 201, 83): [2081, 2082], (4, 201, 89): [2419], (4, 203, 86): [2259, 2340, 2341], (4, 204, 76): [1761], (4, 208, 73): [1924, 1977], (4, 208, 74): [1934], (4, 208, 77): [1936, 1937], (4, 208, 82): [2096, 2101, 2120], (4, 208, 83): [2246], (4, 208, 86): [2258], (4, 209, 73): [1893], (4, 211, 73): [1923, 1965], (4, 211, 79): [2021], (4, 211, 84): [2277, 2278], (4, 212, 89): [2393], (4, 214, 77): [1938, 1939], (4, 214, 79): [2049], (4, 216, 77): [1935], (4, 216, 81): [2126], (4, 221, 84): [2304], (4, 221, 88): [2327], (4, 223, 86): [2325, 2326], (4, 223, 89): [2388], (4, 228, 84): [2421], (4, 228, 89): [2464, 2466], (4, 229, 89): [2375, 2376, 2377], (4, 231, 87): [2473], (4, 263, 118): [3071], (4, 263, 130): [2876], (4, 264, 122): [2810], (4, 265, 130): [3287], (4, 265, 133): [3121], (4, 266, 129): [4085, 4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094], (4, 267, 121): [2791], (4, 271, 118): [3072], (4, 271, 122): [2809], (4, 272, 128): [3471], (4, 272, 130): [3288], (4, 272, 132): [3107], (4, 273, 123): [4230], (4, 275, 121): [2792], (4, 279, 132): [3108], (4, 279, 133): [3122], (4, 281, 120): [2733], (4, 281, 126): [3079], (4, 281, 132): [3077], (4, 285, 116): [3064], (4, 285, 121): [3068], (4, 285, 123): [3024], (4, 285, 127): [3206], (4, 285, 131): [3066], (4, 285, 134): [3014], (4, 286, 120): [2734], (4, 286, 126): [3080], (4, 286, 132): [3078], (4, 287, 117): [3828], (4, 287, 130): [2877], (4, 292, 116): [3063], (4, 292, 121): [3067], (4, 292, 123): [3023, 4229], (4, 292, 127): [3205], (4, 292, 128): [3470], (4, 292, 131): [3065], (4, 292, 134): [3013]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalea\\AppData\\Local\\Temp\\ipykernel_7260\\635274658.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  unique_groups = df.groupby([\"klasifikasi_perkara_encoded\", \"penuntut_umum_encoded\", \"hakim_encoded\"]).apply(lambda x: x.index.tolist()).to_dict()\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = stratified_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Klasifikasi Perkara: 5\n",
      "Jumlah Data Train:  3273\n",
      "klasifikasi_perkara_encoded\n",
      "0    1378\n",
      "2    1251\n",
      "3     289\n",
      "4     193\n",
      "1     162\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "jenis_klasifikasi_perkara = train_df['klasifikasi_perkara_encoded'].unique()\n",
    "jumlah_klasifikasi_perkara = len(jenis_klasifikasi_perkara)\n",
    "print(f\"Jumlah Klasifikasi Perkara: {jumlah_klasifikasi_perkara}\")\n",
    "print(f\"Jumlah Data Train:  {len(train_df)}\")\n",
    "\n",
    "klasifikasi_perkara_values = train_df['klasifikasi_perkara_encoded'].value_counts()\n",
    "print(klasifikasi_perkara_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Klasifikasi Perkara: 5\n",
      "Jumlah Data Test:  1050\n",
      "klasifikasi_perkara_encoded\n",
      "0    490\n",
      "2    438\n",
      "4     51\n",
      "3     48\n",
      "1     23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "jenis_klasifikasi_perkara = test_df['klasifikasi_perkara_encoded'].unique()\n",
    "jumlah_klasifikasi_perkara = len(jenis_klasifikasi_perkara)\n",
    "print(f\"Jumlah Klasifikasi Perkara: {jumlah_klasifikasi_perkara}\")\n",
    "print(f\"Jumlah Data Test:  {len(test_df)}\")\n",
    "\n",
    "klasifikasi_perkara_values = test_df['klasifikasi_perkara_encoded'].value_counts()\n",
    "print(klasifikasi_perkara_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['concat_text'] = train_df[['terdakwa', 'summarized_dakwaan']].apply(lambda x: '. '.join(x), axis=1)\n",
    "test_df['concat_text'] = test_df[['terdakwa', 'summarized_dakwaan']].apply(lambda x: '. '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['total_pidana_penjara_bulan']\n",
    "y_test = test_df['total_pidana_penjara_bulan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "train_df['normalized_text'] = train_df['concat_text'].apply(normalize_text)\n",
    "test_df['normalized_text'] = test_df['concat_text'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kalea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "train_df['stopword_removal'] = train_df['normalized_text'].apply(remove_stopwords)\n",
    "test_df['stopword_removal'] = test_df['normalized_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "train_df['stemmed_text'] = train_df['stopword_removal'].apply(stem_text)\n",
    "test_df['stemmed_text'] = test_df['stopword_removal'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisasi\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(train_df['stemmed_text'])\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['stemmed_text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df['stemmed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 14906\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  # 4 + 1 = 5\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "# max_len = max(len(seq) for seq in train_sequences)\n",
    "max_len = 1024\n",
    "X_train_texts = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_texts = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TANPA LOG TRANSFORM (gunakan salah satu)\n",
    "\n",
    "train_numerical = tf.constant(train_df[['klasifikasi_perkara_encoded', 'penuntut_umum_encoded', 'hakim_encoded', 'jumlah_saksi', 'maks_penjara_berdasarkan_pasal']].values, dtype=tf.float32)\n",
    "test_numerical = tf.constant(test_df[['klasifikasi_perkara_encoded', 'penuntut_umum_encoded', 'hakim_encoded', 'jumlah_saksi', 'maks_penjara_berdasarkan_pasal']].values, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scenario_name = \"BiLSTM_13\"\n",
    "max_len = 1024\n",
    "\n",
    "model_save_path = f'../Model/{model_scenario_name}'\n",
    "tokenizer_save_path = f'../Model/{model_scenario_name}_tokenizer.pkl'\n",
    "history_training_save_path = f'../Model/{model_scenario_name}_training_history.pkl'\n",
    "    \n",
    "loaded_model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "with open(tokenizer_save_path, 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat model embedding: token integer -> embedding float\n",
    "input_text_new = tf.keras.Input(shape=(1024,), dtype=tf.int32, name='text_input_new')\n",
    "embedding_layer = loaded_model.get_layer('embedding')\n",
    "embedding_output = embedding_layer(input_text_new)\n",
    "embedding_model = tf.keras.Model(inputs=input_text_new, outputs=embedding_output)\n",
    "\n",
    "# Buat input baru: embedding dan numeric\n",
    "input_embed = tf.keras.Input(shape=(1024, 256), name='embedding_input')\n",
    "input_num = tf.keras.Input(shape=(5,), name='numeric_input')\n",
    "\n",
    "# Rekonstruksi bagian setelah embedding\n",
    "x = loaded_model.get_layer('bidirectional')(input_embed)\n",
    "x = loaded_model.get_layer('batch_normalization')(x)\n",
    "x = loaded_model.get_layer('bidirectional_1')(x)\n",
    "x = loaded_model.get_layer('batch_normalization_1')(x)\n",
    "x = loaded_model.get_layer('bidirectional_2')(x)\n",
    "x = loaded_model.get_layer('batch_normalization_2')(x)\n",
    "x = loaded_model.get_layer('global_max_pooling1d')(x)\n",
    "x = loaded_model.get_layer('dropout')(x)\n",
    "\n",
    "n = loaded_model.get_layer('batch_normalization_3')(input_num)\n",
    "n = loaded_model.get_layer('dense')(n)\n",
    "n = loaded_model.get_layer('dense_1')(n)\n",
    "n = loaded_model.get_layer('dense_2')(n)\n",
    "\n",
    "concat = loaded_model.get_layer('concatenate')([x, n])\n",
    "concat = loaded_model.get_layer('batch_normalization_4')(concat)\n",
    "concat = loaded_model.get_layer('dense_3')(concat)\n",
    "concat = loaded_model.get_layer('dropout_1')(concat)\n",
    "concat = loaded_model.get_layer('dense_4')(concat)\n",
    "output = loaded_model.get_layer('dense_5')(concat)\n",
    "\n",
    "# Final model: menerima embedding float dan numeric float\n",
    "new_model = tf.keras.Model(inputs=[input_embed, input_num], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fungsi integrated gradients input embedding float dan numerik float\n",
    "def integrated_gradients_embedding(model, embedding_input, numeric_input, baseline_embed=None, baseline_num=None, m_steps=50):\n",
    "    if baseline_embed is None:\n",
    "        baseline_embed = tf.zeros_like(embedding_input)\n",
    "    if baseline_num is None:\n",
    "        baseline_num = tf.zeros_like(numeric_input)\n",
    "\n",
    "    delta_embed = embedding_input - baseline_embed\n",
    "    delta_num = numeric_input - baseline_num\n",
    "\n",
    "    total_grads_embed = tf.zeros_like(embedding_input, dtype=tf.float32)\n",
    "    total_grads_num = tf.zeros_like(numeric_input, dtype=tf.float32)\n",
    "\n",
    "    alphas = tf.linspace(0.0, 1.0, m_steps)\n",
    "\n",
    "    for alpha in alphas:\n",
    "        interpolated_embed = baseline_embed + alpha * delta_embed\n",
    "        interpolated_num = baseline_num + alpha * delta_num\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch([interpolated_embed, interpolated_num])\n",
    "            preds = model([interpolated_embed, interpolated_num], training=False)\n",
    "\n",
    "        grads = tape.gradient(preds, [interpolated_embed, interpolated_num])\n",
    "\n",
    "        total_grads_embed += grads[0]\n",
    "        total_grads_num += grads[1]\n",
    "\n",
    "    avg_grads_embed = total_grads_embed / tf.cast(m_steps, tf.float32)\n",
    "    avg_grads_num = total_grads_num / tf.cast(m_steps, tf.float32)\n",
    "\n",
    "    integrated_grad_embed = delta_embed * avg_grads_embed\n",
    "    integrated_grad_num = delta_num * avg_grads_num\n",
    "\n",
    "    return integrated_grad_embed, integrated_grad_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_gradient_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [3:22:08<00:00, 11.55s/it] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(len(X_test_texts))):\n",
    "    sample_text_int = tf.constant([X_test_texts[i]], dtype=tf.int32)\n",
    "    embedding_float = embedding_model(sample_text_int)\n",
    "    \n",
    "    numeric_tensor = tf.reshape(test_numerical[i], (1, 5))\n",
    "\n",
    "    ig_text, ig_numeric = integrated_gradients_embedding(new_model, embedding_float, numeric_tensor)\n",
    "\n",
    "    if 'ig_text' not in integrated_gradient_results:\n",
    "        integrated_gradient_results['ig_text'] = []\n",
    "\n",
    "    if 'ig_numeric' not in integrated_gradient_results:\n",
    "        integrated_gradient_results['ig_numeric'] = []\n",
    "\n",
    "    integrated_gradient_results['ig_text'].append(ig_text)\n",
    "    integrated_gradient_results['ig_numeric'].append(ig_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1024, 256), dtype=float32, numpy=\n",
       "array([[[-0.00170077, -0.00855211, -0.00414075, ..., -0.00969422,\n",
       "         -0.02039644, -0.00937904],\n",
       "        [-0.00221879,  0.00840896, -0.00421031, ..., -0.02745531,\n",
       "         -0.01810046, -0.00128494],\n",
       "        [ 0.00038716,  0.00125626, -0.00423062, ...,  0.03831901,\n",
       "         -0.00394504,  0.02057048],\n",
       "        ...,\n",
       "        [-0.06187845, -0.00905786, -0.01349937, ...,  0.00080216,\n",
       "         -0.00968476, -0.00711572],\n",
       "        [-0.05998296, -0.00975306, -0.01909804, ...,  0.00190685,\n",
       "         -0.01366026, -0.01014192],\n",
       "        [-0.04557592, -0.01104334, -0.01590293, ...,  0.00585538,\n",
       "         -0.01516594, -0.01475155]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrated_gradient_results['ig_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan ke file\n",
    "with open('integrated_gradient_results.pkl', 'wb') as f:\n",
    "    pickle.dump(integrated_gradient_results, f)\n",
    "\n",
    "# Untuk load kembali\n",
    "with open('integrated_gradient_results.pkl', 'rb') as f:\n",
    "    loaded_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.       , 0.       , 0.       , 1.5012991, 1.7499776]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.0000000e+00,  7.5903907e-04,  0.0000000e+00,  1.7256484e+00,\n",
       "          3.8550782e-01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00, -1.6281646e-04,  1.5510552e-02,  9.4895566e-01,\n",
       "          4.8615355e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.05245126, -0.        ,  1.0658554 , 10.785488  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.05855698, -0.        ,  1.1008494 , 10.790839  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.02102938, -0.01084582,  1.3032999 ,  3.441144  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.00501573, 0.03080537, 1.0803462 , 2.3055594 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.03662729,  0.10339064,  0.7169795 ,  2.2304692 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.00435456,  0.09357447,  0.76378393,  3.4719646 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.07578523,  0.13547416,  1.8101517 ,  3.0778532 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.03624099,  0.15412953,  0.9829227 ,  2.0142422 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.00761226,  0.10928132,  1.0751307 ,  3.8908105 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       , -0.0350182,  0.1700304,  0.985651 ,  1.8335097]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        , -0.00644508,  0.        ,  0.775982  , -0.00888749]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.01072302, 0.47339186, 0.71314365, 5.76167   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.02366806, 0.03662277, 0.35238823, 2.938444  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.01185461, -0.09623577,  0.29633462,  6.186985  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.00832146, 0.05579549, 1.4170239 , 2.1512895 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.04793263, 0.03387344, 1.0432411 , 6.581277  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.01516202,  0.10456164,  0.73834914,  3.2329068 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.04035316,  0.06294561,  0.3710738 ,  2.7412279 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.02487694, 0.07551169, 0.8210775 , 7.50001   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.00926102,  0.14950913,  1.0623065 ,  4.143401  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.04254566,  0.09607121,  0.88683176,  6.126988  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.02936646, 0.11782841, 0.4271267 , 8.245975  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.19585474, 0.0459922 , 1.5721021 , 7.222273  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.04330788,  0.08106756,  1.0732975 ,  1.1039503 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.04698754,  0.06188045,  1.3219347 ,  2.9001539 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.07754114, -0.05041141,  0.8033656 ,  6.456294  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.01929337, 0.04677778, 1.462941  , 2.3532143 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        , -0.01616965,  0.17380278,  1.4264336 ,  1.1996295 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.07514178, -0.11420771,  0.85732543,  5.628491  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.0000000e+00, 4.4282135e-03, 4.4054370e-02, 1.2396454e+00,\n",
       "         4.7461500e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.11404   , -0.06113959,  1.0301218 ,  6.629107  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.03107158, 0.11721222, 0.01176627, 8.604497  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.0000000e+00, 9.1631501e-04, 4.9006514e-02, 1.1134129e+00,\n",
       "         5.3132319e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.0250069 , 0.05957145, 1.4914666 , 3.8228822 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.09636999, 0.05827237, 1.5107293 , 5.568705  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.09018306, 0.00919546, 0.9122456 , 8.492848  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.0000000e+00, 2.4923652e-03, 3.8719572e-02, 1.1030836e+00,\n",
       "         4.9207349e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.07139405, 0.0074061 , 0.8887728 , 6.9074984 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.06316784, 0.06214523, 0.43443683, 8.992038  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00, -2.6521455e-03,  5.5087052e-02,  7.6714003e-01,\n",
       "          3.3615437e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.10151826, 0.05064714, 1.7868149 , 3.175178  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.08922578,  0.21680483,  0.07664054, 12.0054035 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.20172691, 0.07190896, 0.95760405, 9.624672  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00, -3.7431321e-03,  8.8914454e-02,  1.1331631e+00,\n",
       "          4.1996417e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.10017386, 0.05535198, 1.1063777 , 7.4332094 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.01508129, 0.03111335, 1.2009194 , 4.4845138 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00, -1.2867422e-03,  6.1206229e-02,  7.5070548e-01,\n",
       "          4.4319749e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.0111274 ,  0.07784601,  0.73640335,  3.9355114 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.06381658, -0.01412101,  0.4615778 ,  8.562117  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.12827244, -0.11283915,  0.3226423 ,  7.2521906 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.0749694 , 0.07573375, 0.49234018, 8.225375  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.01414649,  0.09978493,  0.6186324 ,  5.1209984 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.01181904,  0.16659337,  1.3274856 ,  2.5173247 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.0000000e+00, 1.5213729e-03, 9.5684014e-02, 1.2378919e+00,\n",
       "         4.0317826e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.11534776, 0.04078405, 1.026596  , 8.1058035 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.09605066, 0.04858583, 1.2815663 , 5.342845  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.07567204, -0.08714514,  0.37285513,  2.7606816 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.00696178,  0.07421343,  1.2393795 ,  3.365307  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.03442151,  0.07749575,  1.2074882 ,  6.1646724 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.11510321, 0.03771242, 1.1124792 , 7.2808094 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00, -2.8830771e-03,  7.3100775e-02,  1.2305450e+00,\n",
       "          3.3448124e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.05418667,  0.07628588,  0.97929406,  4.4681454 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.00646093, 0.11797496, 1.1936692 , 3.2392118 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.15200841, -0.23103036,  0.19492717,  7.542687  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.04560832,  0.09484306,  1.4762226 ,  2.1583035 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.13573769,  0.15651333,  1.065039  ,  2.5954013 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.12640792, 0.03911883, 0.9605282 , 6.597279  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.08442754, 0.09946681, 0.47415736, 8.467098  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.11316683, 0.04972073, 1.1294383 , 5.3124757 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.05195571,  0.07438089,  0.9972595 ,  4.309357  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.2540857 , 0.03069763, 1.1293947 , 8.717868  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.02924677, -0.00717774,  1.1887171 ,  4.0583453 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.05324445, 0.04273409, 0.9443365 , 6.648632  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.06100997, 0.04182762, 0.9694264 , 6.4955716 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.05285304,  0.10139036,  0.7312916 ,  2.877214  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        , -0.03209562,  0.2737753 ,  1.0142821 ,  0.80052507]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.0762831 ,  0.11121818,  1.3931087 ,  1.9677835 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.0273435 ,  0.20247863,  1.2287469 ,  2.716556  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.0000000e+00, 2.0742512e-03, 3.0877975e-01, 5.8466542e-01,\n",
       "         9.0394344e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.05177022,  0.06107039,  1.1455768 ,  3.474434  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.363856  ,  0.10407597,  0.7675613 , 11.752968  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        , -0.05056351,  0.07883235,  0.77849543,  1.0809438 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.04729938,  0.07129572,  1.189106  ,  1.4717753 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.05105373,  0.09599235,  1.3836435 ,  2.125099  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.25992906, 0.14401384, 1.2664664 , 7.8982854 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.01657043,  0.15907247,  0.2178545 ,  3.3628755 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.13226402, 0.11065263, 0.38225093, 9.553168  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.02270286,  0.12612508,  1.1419457 ,  3.6313896 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.32356733, 0.13767058, 1.0572917 , 9.376419  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.03255871, -0.01961296,  0.87942237,  5.6889815 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.17880605, 0.0794658 , 0.7271233 , 6.715527  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00,  6.1236704e-03, -1.1778730e-02,  4.7824305e-01,\n",
       "          1.0431369e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.13502374, 0.09171452, 0.4422885 , 9.175994  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       , -0.0465038,  0.1142459,  0.7607703,  4.018567 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.01816708,  0.05802885,  1.5949235 ,  1.5308545 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.1524735 ,  0.04831347,  0.816872  ,  7.406316  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.06682536,  0.04834004,  1.3839148 ,  1.3502082 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.03268089,  0.06738996,  1.0195045 ,  4.609447  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.20244852,  0.24560022,  1.5514956 ,  4.8213844 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.04314228,  0.15799029,  0.8531952 ,  2.7999809 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.0203813 ,  0.06753074,  0.5810659 ,  2.9576702 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.01112667,  0.08401689,  1.215529  ,  4.0092516 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.11152334,  0.15064357,  0.667763  ,  2.3391628 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.03022651, 0.0291432 , 1.3268387 , 2.5991347 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.02046471, 0.07925456, 0.59523743, 5.7886143 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.02750836, 0.00371215, 1.3095363 , 2.6263316 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.15133812, 0.03990896, 0.9155997 , 8.068554  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.00696203, 0.09214272, 1.2018425 , 4.6269765 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.3487542 , 0.16146384, 0.880666  , 9.858384  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        , -0.04042564,  0.03073222,  1.5084099 ,  0.43492785]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        , -0.05218944,  0.14660871,  1.2232467 ,  0.9945262 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        , -0.08179317,  0.14949647,  1.406761  ,  0.96528006]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.10441009,  0.1661214 ,  0.98772085,  7.8082175 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.00496951, -0.42401487,  0.42897806,  1.2893398 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.05684565,  0.06393177,  1.0050929 ,  1.7644312 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  0.5964742,  0.1095103,  0.6729443, 13.554211 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.10882363,  0.14371492,  0.9700613 ,  4.988365  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.00697301, 0.2130287 , 0.8026388 , 4.049663  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        , -0.08635314,  0.23710668,  1.2038305 ,  1.6840694 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.2972085 , -0.33613965,  0.02607306, 12.21993   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.15215033, -0.0918067 ,  0.761356  ,  9.707282  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.08985654,  0.07471744,  1.4009839 ,  1.405962  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.12848723,  0.17509624,  1.201365  ,  2.0963924 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.01803067, -0.17169279,  0.2952796 ,  9.658073  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.10896841, -0.01932747,  0.65965927,  6.1987443 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.07064241,  0.04611346,  1.3852906 ,  1.3680906 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.05149286,  0.24555449,  1.2072955 ,  2.8196788 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.17554837, -0.14200988,  0.74624175,  5.518494  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        , -0.08615664,  0.20908031,  1.2407587 ,  1.7116859 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.2825425 ,  0.21631603,  0.7578833 ,  6.358666  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.27599052,  0.20192201,  0.6966907 ,  6.155331  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.29403412,  0.10036568,  0.5548041 ,  5.4551725 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.5081254 ,  0.25738296, -0.10177512, 16.404778  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.07475138, -1.3189298 , -1.485965  , 15.583853  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        , -0.06895798,  0.3576656 ,  1.1205678 ,  2.3522909 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.16871977, -0.56937975, -0.3512365 , 10.832321  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.03053087,  0.21619213,  0.14184159,  2.7303174 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.2361252 ,  0.23306213,  0.97145355,  2.292925  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.1042688 ,  0.39999598,  0.6682356 ,  3.391041  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.18400462, -0.02020304,  0.07139394, 11.589855  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.26459855,  0.3841423 ,  0.9856977 ,  1.4928466 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.16854864, -0.12277332,  0.15805066,  8.791842  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.000000e+00, -4.590231e-03,  1.531189e-02,  8.250703e-01,\n",
       "          7.467299e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.07929865,  0.2063114 ,  1.1356283 ,  3.0686164 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.05378619, -0.25377247,  0.50975585,  6.422698  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.2062437 ,  0.2875456 ,  0.90679324,  3.5153923 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.12702183,  0.5323433 ,  0.66451955,  3.585234  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.43320885,  0.46984163,  0.5401536 ,  3.2002738 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.13771965,  0.19097832,  0.972679  ,  4.1678033 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.2861632 , -0.11835928,  0.2315331 ,  9.32692   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.3800369 , -0.06871989,  0.22066088,  8.834564  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.29242334,  0.39837837,  0.773306  ,  2.6910658 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.06880045, -0.4727431 , -0.28186056, 10.730976  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.11225192, -0.01362253,  0.68945676,  7.505841  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.06890354, -0.6861565 , -0.6637966 , 11.895193  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.07187871,  0.17580035,  0.8111152 ,  5.6338    ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.3617608 ,  0.41218725,  0.71941864,  2.5047967 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.47579348,  0.23446293,  0.3838262 ,  9.207033  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.230258  ,  0.40232623,  0.873628  ,  2.2521427 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.22488822,  0.18848068,  1.2801937 ,  1.1357632 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.29132032, -0.23388815,  0.43538615,  6.0524397 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       , -0.1391747,  0.1278416,  0.3334561,  6.373466 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.5435233 ,  0.14040944,  0.34015277,  6.074506  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.3683298 , -0.16826521,  0.17252561,  8.74247   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.16949819, -1.2114347 , -1.2826563 , 15.566308  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.46374866,  0.24070175,  0.4562195 ,  8.859106  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.23339523, -0.20691258,  0.5671421 ,  6.5583925 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.21241893,  0.2730852 ,  0.8420509 ,  2.6203678 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.40281463, -0.18217246,  0.17946242,  8.777898  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.6235449 ,  0.2426838 ,  0.23632497, 10.1673975 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.60341346,  0.15486947,  0.49958116,  9.113424  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.33345273,  0.30097967,  0.39857116,  3.3643444 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.44452712,  0.00901068,  0.7016895 ,  6.5393424 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.42774302,  0.12952301,  0.3481914 ,  9.363688  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.27155042,  0.39223844,  0.13891758,  3.8784037 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.02489645, -0.54378086, -0.33003727,  5.7312913 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.07641381,  0.19200584,  0.6829883 ,  5.851452  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.0825399 ,  0.19120693,  0.7088187 ,  5.6481924 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.6063087 ,  0.03182848,  0.5809086 ,  8.997213  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.27194375,  0.17733304,  1.1232795 ,  1.1149055 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.24077539,  0.11199941,  1.000008  ,  4.2475605 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.40813538,  0.26896772,  0.603603  ,  4.59562   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00,  1.5319482e-02, -5.5195554e-03,  6.5471530e-01,\n",
       "          5.5526180e+00]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.67074317, -0.6159272 ,  0.90854037, 11.634902  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.04112289, -1.2043823 , -1.4963037 ,  8.552771  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.21815242, -0.20850672,  0.23157373,  5.5170383 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.12397023,  0.12789023,  0.33142012,  4.8801627 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.09676491, -0.773363  , -0.7984938 ,  8.0582285 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.45394623,  0.26521748,  0.5179218 ,  4.5809784 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.15268114, -1.0151348 , -1.5052196 ,  6.35268   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       , -0.2387717,  0.3509223,  0.6310329,  2.3153918]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.30748826,  0.17099774,  0.19830722,  5.6691446 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.09704343, -0.5074982 , -0.16001464,  7.761202  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.40587327,  0.24206556,  0.9874862 ,  2.6316288 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.05654638, -0.15758185,  0.6672938 ,  4.773901  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.02167674, -0.8180342 , -0.78114814,  8.053505  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.08601627, -0.16213442,  0.6648326 ,  4.762915  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.90464187, -0.42269197, -0.8616556 , 15.080152  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.40986484, -0.19421594,  0.8331379 ,  5.9718347 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.451932  , -0.749191  ,  0.88870776, 11.341428  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.02696901, 0.34211972, 0.69295347, 2.8255823 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.00838949, -0.3449148 ,  0.24405134,  5.6261635 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.38768625, -0.85866004, -1.0610445 ,  4.1374817 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.26912424, -0.12902376,  0.76716495,  5.70421   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.40261865, -0.45252177,  0.8305619 , 13.234193  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.6800293 , 0.06535026, 0.19217268, 7.602442  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.11985754, 1.0334165 , 0.4552328 , 1.7348994 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.27996156,  0.6703575 ,  0.63107085,  2.0920644 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       , -0.1754256, -1.1882182, -1.1748986, 12.885542 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.55359346, -0.02242772,  0.89871925,  1.7975402 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.07574432,  1.2682874 ,  0.526514  ,  3.105046  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -1.1145692 ,  0.4395283 ,  0.32553282,  7.5292363 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.6615238 ,  2.1313484 , -0.25913888,  1.3742411 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.87819487, -0.65351176, -0.40191835, 13.193485  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.5696492 , -1.1635978 ,  0.12466192, 11.667031  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.55828744,  0.6822202 ,  0.41876304,  4.428078  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.50267047, -0.3249358 ,  0.6059324 ,  0.6683585 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.11873219,  1.7243259 ,  0.47516   ,  2.820899  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.09941006,  1.7767262 ,  0.26289928,  2.0092587 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.62493706,  0.37375188,  0.8481539 ,  2.65219   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.13790174,  1.0446734 ,  0.6321304 ,  2.5329943 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.37086952,  0.27572802,  0.29629493,  6.3407073 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.23059432,  0.30781734,  0.31338942,  5.163595  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.7142552 , -0.13283047,  0.19661228,  9.453813  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.51697844, -0.21475337,  0.29589105,  8.047019  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.11323609,  1.370538  ,  0.54521656,  1.8678994 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.62115306,  1.6261746 , -0.24789585,  0.74002814]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.47262016,  0.799904  ,  0.28379998,  4.3479853 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.14812246, -0.8548647 , -1.5267911 ,  6.840515  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.15083973,  1.4888741 , -0.09320083,  1.6832777 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.26126352,  0.9631369 ,  0.39938474,  2.9385326 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.6207963 ,  0.7914736 ,  0.17745003,  4.3000536 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.31329238,  1.1508805 ,  0.07416228,  3.3421946 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       , -0.1149089,  1.4801584,  0.5581017,  4.2779107]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.17537245,  2.0676768 ,  0.26269853,  2.4560974 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.7066731 , -0.42676282, -0.16002825,  4.1515403 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.10654238,  1.7628489 ,  0.24436161,  1.1086953 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.6244215 ,  0.39279795, -0.05249029,  4.519208  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.38647413, 0.923736  , 0.4138162 , 3.1174982 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.32902604,  0.9978102 ,  0.13439767,  2.9824836 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       , -0.3843044, -0.2311381, -1.1900761,  7.8808637]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.420269  ,  0.63431954,  0.40728396,  5.4123874 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.01521133, 1.7945647 , 0.22613087, 3.1364255 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.14844692,  1.6697688 ,  0.21579728,  1.9036741 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.060098  ,  2.5913754 ,  0.00970913,  0.6486572 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.09464718, 1.7637482 , 0.20611084, 1.3942012 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.46950793, 0.878828  , 0.44725233, 3.4850662 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.57069784,  0.38615713,  0.7303519 ,  2.692545  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.18264136,  1.4925559 ,  0.17665917,  0.997007  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.49348393, -0.26305547, -1.0414534 ,  7.746009  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.08014847,  1.3824027 , -0.11558919,  1.8138057 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.07042646,  2.0254166 ,  0.13978902,  2.516762  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.5564926 , -0.13404629,  0.37878817,  8.009071  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.38238767,  1.124955  , -0.17301112,  2.6269841 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.6369658 ,  0.54353875,  0.15209463,  5.2804275 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.0376672 ,  1.2850175 , -0.16944428,  2.091064  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.7783624 ,  0.23888087,  0.31000188,  7.069057  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.02982025,  1.8901119 , -0.0331856 ,  0.9919024 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 1.040003  , 0.95066184, 0.2863757 , 4.785506  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.46043205,  1.3026168 ,  0.3904163 ,  2.694084  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.14165756, 1.0337826 , 0.38876784, 3.713162  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.1679255 ,  0.7214274 , -0.18631853,  5.574836  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.99288696,  1.3401041 , -0.17815681,  2.3156757 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.1234152 , 0.41609108, 0.209385  , 5.841594  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.14830954, 0.3338177 , 0.15014195, 6.618525  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.4356225 , -0.02927629, -0.37924153,  3.564178  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.00602817,  1.3144493 ,  0.3645624 ,  4.109172  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.4609295 , -0.44507903, -0.3608197 , 10.264943  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.6160448 , -0.01671994, -0.32700378,  8.614193  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.20761172,  1.9529634 ,  0.16260444,  1.7031802 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.5869961 ,  0.18189515, -0.3239697 ,  7.963408  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.22920398, 0.8215865 , 0.44678658, 5.3504777 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.8144706 ,  0.44204232,  0.5547252 ,  7.0043845 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.18072234, 0.40207285, 0.2394275 , 6.146567  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.0127263 , -0.55584663, -0.17499842, 13.8989    ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.1184607 , -0.13969536, -0.09571459, 12.517812  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.36282188, -0.68384653, -0.8740959 , 13.821806  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.30306217, 1.6033831 , 0.39781803, 2.7524014 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.95332164, 0.94554985, 0.10609276, 8.282503  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.8145476 , -0.15043987,  0.35056907,  2.2589195 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.       , 0.3828815, 0.6735442, 0.2933082, 5.3574815]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.        ,  0.09219676,  1.9559411 ,  0.08392361,  1.451213  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.46131146, 0.5803521 , 0.25048473, 5.7579203 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.55792755,  1.1310492 ,  0.22983523,  3.729578  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.4355394 , 0.80684376, 0.21920331, 5.360393  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.37129065, 0.7359981 , 0.3424082 , 5.5213118 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.19955628, 1.5808877 , 0.15804651, 3.8636498 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.3436601 ,  0.35794595, -0.07529304,  8.338236  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.        , 0.4171666 , 2.2752109 , 0.14859119, 1.9626548 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.21597566,  0.2594431 ,  0.10172752,  4.892415  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.39895457,  1.2696569 ,  0.2126605 ,  3.032608  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.19944693,  1.9406703 ,  0.25922695,  1.8592478 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.11512992,  1.7245681 ,  0.07547481,  1.4221896 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.07145855,  1.8451099 ,  0.26404554,  1.7475568 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        , -0.10550638, -0.10261361,  0.657356  ,  6.5189853 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  0.889251 , -0.1783887, -0.6881208, 11.735318 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.6248461 ,  3.1503565 , -0.15446106,  4.9529386 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.4473616 ,  3.7153478 , -0.21625003,  3.74653   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.72147995,  2.0017023 , -0.17668734,  3.309403  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.1135657 ,  2.3335216 , -0.44652656,  3.5088649 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.8700302,  0.601796 , -0.6119344, 10.268133 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.0556633,  2.8771656, -0.5250237,  2.5597045]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.8982234,  2.5734503, -0.9219191,  4.902266 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.2725611,  3.0627718, -0.6756761,  1.6085104]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.293357 ,  3.2254927, -0.9999011,  3.689331 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.2497044 ,  3.3009937 , -0.63031656,  1.6664032 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.348222 ,  3.2092135, -1.0877522,  3.7883286]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.419678 ,  3.094008 , -1.4043746,  5.2258577]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.9585656,  2.7718675, -0.6835067,  2.7274737]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.809235  ,  0.9953555 , -0.84870714, 10.181159  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.118098  ,  0.46728006, -0.60376567, 11.813799  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.712721 ,  2.497324 , -0.7677688,  4.4867883]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.0595558,  2.4684541, -0.8150562,  5.0516396]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.1677577,  0.5517902, -0.6106877, 10.47806  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.3293192 ,  2.3791387 , -0.91135144,  5.778519  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.940721  ,  2.6321812 , -0.92282647,  4.769056  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.6511688,  2.6525526, -0.9553252,  4.372773 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.6275928,  2.6105268, -0.9300562,  4.3954744]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.5367177,  2.7477367, -0.9505249,  4.3965435]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.0355093,  2.571345 , -0.9441864,  4.9258637]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.637769 ,  2.806342 , -0.8666995,  4.41249  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.4783676,  3.1017325, -1.0319705,  3.8816266]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.6224213,  2.9384115, -1.0537641,  4.205703 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.91695875,  3.348063  , -0.6742301 ,  1.2287803 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.8852909,  3.135048 , -0.9244826,  3.0773537]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.36781073,  3.141848  , -0.67528224,  0.5283939 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.2956837,  3.292126 , -0.6294627,  1.6682284]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.482767 ,  3.1134722, -1.4234979,  5.238963 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.2529124 ,  3.239934  , -0.75293976,  1.7410996 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.156036 ,  3.1309102, -1.2949045,  4.9259915]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.6997491,  3.480789 , -1.065035 ,  2.5838377]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.567685  ,  3.3611343 , -0.83297837,  2.1362665 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.9121394 ,  1.1208153 , -0.82816124, 10.145169  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.8466887,  3.4463165, -1.0058299,  3.116095 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.5727396,  2.6839783, -1.4756649,  7.247231 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.7564359,  2.647779 , -0.8213981,  4.12883  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.5525575,  2.4453208, -1.1134474,  6.213411 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.9617455,  2.4726307, -1.2309986,  7.2467523]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.6742088 ,  2.685932  , -0.53137624,  2.5222673 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.8223977 ,  2.7056322 , -0.88083315,  4.1474156 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.3616936,  2.5680933, -0.9350765,  5.2217965]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.2715342,  2.6036258, -0.7448964,  3.8621376]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.2112454,  3.0778985, -0.6003874,  1.5966557]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.3021573 ,  2.986866  , -0.66917557,  1.4883728 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.2503023,  2.8804688, -0.7614521,  4.0120215]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.3358207,  3.1506667, -0.9707217,  3.6328027]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.170981  ,  0.8075541 , -0.66808546,  9.7190695 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.1613376 ,  0.76216453, -0.6790758 ,  9.845137  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.7850132,  2.9749773, -1.2164259,  4.148725 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.640639 ,  3.1929348, -1.0912088,  4.0960307]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.6323416,  2.9137044, -1.1589117,  4.7113614]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.7269676 ,  3.0209234 , -0.96208084,  2.8973687 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.8624   ,  2.6790361, -1.2738173,  5.5164375]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.4759743,  2.7623017, -1.2165141,  5.4384217]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.9351814,  2.7382095, -1.0906352,  4.8142147]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.8781283,  2.7833204, -1.371745 ,  5.822982 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.9362538,  2.7542117, -1.1960111,  4.703974 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.5559489,  2.807494 , -0.7365099,  2.158681 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.43637  ,  1.187629 , -0.7294214,  8.708438 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.5347136 ,  3.1160765 , -0.69620985,  2.1743991 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.2906227,  3.1402555, -0.8058064,  1.6499754]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.0892255,  3.1369674, -1.1159449,  3.5184247]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.4198143,  3.2797768, -1.1161022,  3.7638028]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.6754682,  2.7630463, -1.051907 ,  3.228884 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.0964332,  3.5365121, -0.8514843,  1.9690366]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.6482258,  2.620999 , -1.4238499,  7.597143 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.9015036,  2.6042125, -1.3702098,  6.503016 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.746327  ,  2.6742983 , -0.54841137,  2.5355074 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.3769653 ,  0.87598985, -0.6617631 , 10.405999  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.5501456,  2.4734735, -1.3297896,  6.491011 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.4799318,  3.1111293, -1.0463357,  3.935383 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.5306613,  2.762091 , -1.2232351,  5.458959 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.6353533,  3.539601 , -0.9327404,  2.6890929]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.4760635,  1.1277837, -0.7628865,  8.657645 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.8948054,  3.4195416, -1.2757982,  4.308339 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.8568447,  2.9145098, -1.1694036,  4.8184414]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.9720783,  2.6594973, -1.2665561,  5.578502 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.3144205,  3.2091975, -1.0130762,  3.7348263]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.1004834,  3.4129684, -1.2801782,  4.1566386]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.8171046,  3.2676477, -1.2836827,  4.1029406]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.0477698,  2.3018584, -0.8998186,  5.324143 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.2698996,  2.57418  , -1.0567403,  4.5473485]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.537335 ,  2.5104446, -1.4617659,  7.957826 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.8172556 ,  3.085827  , -0.72884107,  1.7448455 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.0073092 ,  2.7386277 , -0.87887645,  4.0379333 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.2779949 ,  0.6637889 , -0.61529386,  9.933378  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.5229816,  2.205503 , -1.4647714,  7.8801336]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.0777903,  2.4716194, -1.3122023,  7.187704 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.017078 ,  2.9737358, -1.0128971,  4.0438013]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.3347828,  2.884389 , -0.9168873,  3.5603566]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.0367134,  2.96688  , -1.1448036,  4.1233306]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.4449027,  0.7396387, -0.6474715,  9.740785 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.4564874,  3.162482 , -0.8857721,  3.5653996]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.438349 ,  3.3847275, -1.1514755,  3.1626916]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.6525683,  3.127472 , -1.1617949,  3.7906055]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.7959566,  0.6205074, -0.8837764,  9.595874 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.7929704,  2.9921005, -1.5552039,  6.4928055]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.1697152 ,  0.42504075, -0.59671867, 10.305665  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.811052 ,  2.6099029, -1.0574615,  5.341572 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.302566  ,  0.56624776, -0.5527779 , 10.439103  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.9005725,  2.8293061, -0.7095674,  4.34835  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.8735023,  2.6784322, -1.0550301,  5.501888 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.137023 ,  2.9312487, -1.0581208,  4.095495 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.185625  ,  2.871415  , -0.81001335,  2.6330702 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.2732685,  3.151196 , -1.1907165,  4.3561945]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.9338783 ,  3.4453866 , -0.96438456,  2.7879667 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.2457662,  3.3486552, -1.2795093,  4.3751783]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.5142267,  3.4147308, -1.1851395,  3.3662133]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.761557 ,  3.0906892, -1.2076583,  4.9823866]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.0069516,  3.414482 , -1.207182 ,  3.8782313]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.8918607,  2.3874638, -1.123414 ,  6.2849164]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.7735624,  2.8537188, -1.1807464,  5.1114554]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.067054 ,  2.6915014, -1.0657507,  5.4127765]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.6782763,  2.5272133, -1.046328 ,  5.125059 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.6344414,  3.3439155, -1.1463022,  3.5678563]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.8639497 ,  1.2315186 , -0.87180495,  5.1691756 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.3811753,  3.1780307, -1.3539176,  4.48048  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.5350729,  3.1540596, -0.733315 ,  1.4469062]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.8377018,  3.7620814, -1.4989486,  4.7043815]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.8219867,  3.527967 , -1.4265394,  4.80572  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.1165173,  3.0050266, -0.9473619,  4.3649564]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.381311 ,  2.6519892, -0.9838548,  4.3973393]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.9286535,  3.5309246, -1.5000734,  4.8443723]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.3223855,  3.5665562, -1.330281 ,  4.1217723]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.296481 ,  2.8411558, -0.9835837,  4.039614 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.7222843,  3.2026918, -1.1645705,  4.971759 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.546069 ,  3.3967214, -1.1174489,  3.425729 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.8034134,  3.5286787, -1.479776 ,  4.7212834]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.693627 ,  2.3636808, -1.57504  ,  7.973421 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.3018188,  3.713156 , -1.4257866,  3.9065704]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.1302478,  3.2206893, -0.9577383,  6.027218 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.1625776,  2.649974 , -1.1679714,  5.433419 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.9309611 ,  3.1076994 , -0.96220595,  3.662245  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.7879195,  3.0910769, -1.3781517,  4.7440243]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.645117 ,  3.4055104, -0.7916414,  1.2919616]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.7468536,  2.9526544, -1.364203 ,  4.806207 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.038842 ,  2.9702332, -1.5278549,  6.452744 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  0.9036919,  3.2451959, -0.4959089,  1.0550565]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.0596974,  3.1188598, -1.1961641,  4.0012245]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.132566 ,  3.307831 , -1.4925178,  4.979935 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.7918496,  3.3387756, -1.428377 ,  4.775833 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.6143003 ,  3.5600042 , -0.81126916,  1.2508688 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.4511094,  2.2820456, -1.5358771,  6.618212 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.0441234,  1.4382048, -0.9059119,  7.6931148]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.6578648 ,  1.069915  , -0.44041103, 11.731177  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.72382  ,  3.4496396, -0.8341365,  4.88032  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.9386296,  3.267131 , -0.8183435,  1.5745658]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.3782606,  3.5094342, -1.4396328,  5.1616445]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.634666 ,  3.4864624, -1.3835597,  4.161265 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.3330865,  2.9234867, -0.8056616,  5.334364 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.0441258,  3.7145073, -1.0544846,  5.3422284]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.0223439,  3.2994237, -0.776187 ,  2.7146885]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.3539737,  3.2413738, -0.5322351,  2.008792 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.068079 ,  3.0455358, -1.3207595,  4.668709 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.5039194,  2.8099911, -1.1617284,  4.1624255]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.131071 ,  2.2746139, -1.4004579,  6.7893925]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.5085278,  3.2828078, -1.5363328,  5.0836983]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.947816 ,  2.4850843, -1.2477545,  4.473259 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.9505312 ,  3.3736172 , -0.91555846,  1.301345  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.2446187 ,  1.3160552 , -0.94757056,  7.5901914 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.857615 ,  0.8394715, -0.7304538,  9.889358 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.803161 ,  3.4475365, -1.4265189,  5.92243  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.6834893,  2.597569 , -1.6075433,  7.246229 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  5.5572386,  2.8082018, -1.6083558,  6.3378615]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.1070218,  3.2882893, -0.7912851,  5.476529 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  1.9000005,  3.075239 , -0.5087818,  2.668205 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.6678202,  3.5237255, -1.2432774,  8.047919 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.4027274 ,  3.3820043 , -0.83365256,  3.4149075 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.128407 ,  2.8712852, -1.0739303,  3.382177 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.166626 ,  2.0288305, -1.490424 ,  6.646165 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.1849785 ,  3.498642  , -0.87338454,  1.7878289 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.4839845,  3.4053512, -1.5256119,  5.044739 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  3.600053  ,  0.24330199, -0.83379745,  9.599044  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.8636181 ,  3.5230474 , -0.81894785,  1.1559592 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.771475 ,  3.6615968, -1.5121907,  5.3127546]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.2207527,  3.5036666, -1.4007858,  4.4783163]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.2526598,  3.6202028, -0.9417629,  4.6081467]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  1.9495206 ,  3.1866806 , -0.54941595,  2.6996057 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.9856093,  3.9586964, -1.3245769,  5.1249933]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.5900228,  3.3706305, -1.2469028,  4.235836 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.586051 ,  3.336683 , -1.351609 ,  3.9034467]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.4935565,  3.2581773, -1.5182464,  5.533656 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  2.761144 ,  3.2507493, -1.0735127,  2.9724522]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.        ,  2.1924174 ,  3.4311268 , -0.63218343,  2.506854  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  3.8422246,  0.8829367, -0.7776999,  9.602516 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.9411583,  3.5957386, -1.3577354,  5.9283605]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.       ,  4.6461954,  3.3719735, -1.49129  ,  5.5710354]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.02276834, 0.00543913, 0.09121705, 1.5876191 , 1.7620039 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.04366931,  0.03530211,  0.07786366,  2.2070134 ,  0.14906967]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.05516574, -0.08668444,  0.11314038,  1.4504366 ,  0.29023945]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.76643354, -0.00441202,  0.24785827,  0.35834056,  2.0449455 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.05992379, -0.0165015 ,  0.1815623 ,  1.0554237 , -0.08596622]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.21356285, 0.04360814, 0.02710709, 1.8724127 , 1.1550958 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.9168952 ,  0.10156076, -0.0501572 ,  2.0945227 ,  7.136807  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.28568012, 0.07035942, 0.03271504, 1.8771129 , 0.14254943]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.6535246 , -0.12982543,  1.2311597 ,  0.8319725 ,  1.2019261 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.69134545, -0.1893921 ,  0.958689  ,  0.7833519 ,  0.9637519 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.0309058 , -0.05735144,  0.6047903 ,  0.0143499 ,  2.1096494 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.24710736,  1.0563834 ,  2.9408097 , -0.3669428 ,  0.6987799 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.6834027,  1.1870776,  4.205395 , -0.6067612,  1.0765433]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.9826587,  1.7653555,  4.020929 , -0.6464421,  2.3505337]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.2290885,  2.8129792,  3.5667343, -0.8697023,  2.8319569]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.6405836,  1.1202867,  4.504305 , -0.7076754,  1.1382697]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.191091  ,  2.291488  ,  4.0833025 , -0.70671135,  2.9191573 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.0641034,  2.1002135,  4.5605044, -0.693975 ,  2.905932 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.0798796,  2.1513147,  4.0769353, -0.6440201,  2.879187 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.95036906,  2.0061898 ,  4.2464375 , -0.73877215,  2.1231732 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.9558446,  2.0069752,  4.2331   , -0.7460527,  2.122941 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.190185  ,  2.845084  ,  3.7081888 , -0.41571888,  5.932151  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.1903872 ,  2.8329473 ,  3.7054856 , -0.41694257,  5.8948193 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.7669134 ,  0.0537017 , -0.05005708, -1.0124576 , 21.958889  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.0986943 , -0.08763707,  0.06960917, -0.08134458, 37.84466   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.0603743 ,  0.07508019,  0.07344401,  1.9642869 , 14.043539  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.269893  ,  0.05760203, -0.40227544,  0.16648318, 32.114685  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.475973  , -0.04090317, -0.16675738, -0.23943844, 32.458263  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.6252441 ,  0.14808238,  0.53144294,  0.7628096 , 12.9598055 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8762076 , -0.10954221,  0.76216185,  0.7151538 , 26.361115  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.712695  , -0.11634544,  0.15601242, -3.2335763 , 34.427517  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.449701  , -0.26726642,  0.23809704,  1.4417652 , 33.496597  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.3895965 , -0.33330098,  0.3374746 ,  1.5438988 , 34.442383  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.400566  , -0.12124674,  0.48444432, -0.39597696, 24.602297  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.9937868e+00, -2.5251905e-02,  3.1861177e-01,  7.6826090e-01,\n",
       "          2.7939850e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.508314  , -0.24006554,  0.29661965,  0.92336535, 32.412224  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.897147  , -0.35182667,  0.54958117,  1.6685449 , 35.403805  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.43674   , -0.15968186,  0.70136297, -0.8230231 , 24.623602  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.5599122 , -0.09934919,  0.70378494, -0.36564612, 21.549072  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.4089338 , -0.37062246,  0.44156915,  1.6466224 , 31.921492  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.8482685 , -0.11494341,  0.36244616, -0.1920279 , 34.57052   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.9018488 , -0.4218418 ,  0.34763873,  1.4613779 , 32.424202  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.1879997, -0.3702599,  0.2324222,  1.5169302, 32.1627   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.2211223 , -0.9858188 ,  0.37135208,  0.31215736, 41.79726   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.082025  , -0.24538921,  0.2052079 ,  0.1528081 , 32.917625  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.3509188 ,  0.06755391,  0.11413591,  1.6956307 , 25.408358  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.1424687 , -0.7055711 ,  0.45588237,  1.430743  , 35.30459   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.866822  , -0.5621751 ,  0.71043825,  0.32669815, 21.737959  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.8170764 , -0.49886805,  0.2280386 ,  1.9241182 , 31.656773  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.7650335 , -0.4854929 ,  0.21998715,  1.9615631 , 30.956837  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.6623874 ,  0.05445283,  0.23441026,  2.0392246 , 22.512043  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.8558161e+00, -2.8074721e-01,  4.9948120e-01, -3.0441571e-03,\n",
       "          2.3023071e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.3733613 ,  0.2441605 ,  0.15751116,  2.3218234 ,  9.141031  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.4651545 , -0.26043954,  0.4712815 ,  0.904407  , 14.775494  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.1520011 , -0.74976766,  0.4995995 ,  1.4357431 , 35.806316  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[2.8714292e+00, 1.1295051e-02, 3.0369323e-01, 1.5336728e+00,\n",
       "         2.2495964e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.7347608 , -0.35237613,  0.67918944, -0.38843226, 25.979794  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.9162683 ,  0.02475857,  0.31457558,  1.6457828 , 22.68827   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.4448404 , -0.3068176 ,  0.74208534, -0.36916873, 25.153742  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.212414  , -0.30005795,  0.7191267 , -0.37540913, 24.064627  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.6230268 , -0.03875349,  0.4104349 ,  1.0574577 , 26.217604  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.5338295 , -0.70023525,  0.29177603,  1.7586603 , 31.334875  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.2280803 , -0.509153  ,  0.27708036,  1.863804  , 33.035725  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.51557  , -0.5573057,  0.5776268,  0.3700699, 20.461248 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[2.7712989e+00, 1.1703844e-02, 2.7618441e-01, 1.6811610e+00,\n",
       "         2.3239803e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.5282395, -0.8139918,  0.5494935,  1.7828839, 29.428377 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.8441176 , -0.36771142,  0.7887129 , -0.13122092, 22.533394  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.892001  , -0.4471357 ,  0.15614995,  0.10869119, 36.251408  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.7203186 , -0.83740216,  0.26007092,  1.7455877 , 32.34798   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9447799 , -0.96276957,  0.4556949 ,  1.5520008 , 34.73594   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.37787   ,  0.87588984, -0.20962062,  3.0837255 , 16.753235  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.6630373 , -0.80858153,  0.22859664,  1.7191684 , 31.335083  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.5238569 , -0.70278907,  0.30372187,  1.90562   , 29.986397  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.328679  , -0.7746885 ,  0.36247998,  1.9527423 , 33.48016   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[3.0070202e+00, 4.3865212e-04, 2.6879388e-01, 1.6646836e+00,\n",
       "         2.3471048e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.343562 , -0.6853613,  0.8625125, -0.549351 , 28.698498 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.866018  , -0.82612556,  0.62309027,  0.12532616, 22.1628    ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.0959463, -1.1591692,  0.5929936,  1.2862673, 35.069218 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.8883162 , -0.04553769,  0.4108203 ,  0.9767051 ,  3.6392534 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.7519815 , -0.7037385 ,  0.31800574,  2.6840668 , 26.828888  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.755539  , -0.45931488,  0.67521995,  0.38381433, 22.695906  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.4844644 , -1.3563294 ,  0.58222944,  1.788611  , 36.44353   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.6795847 ,  0.07999829,  0.32965672,  1.9593731 , 22.792635  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.5089478 , -0.96811837,  1.0892092 ,  0.341176  , 24.50538   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.3527226, -1.3461055,  0.6789587,  1.3187102, 37.0581   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.1240296 , -0.60081524,  0.83906853,  0.2875542 , 31.5744    ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.859232  , -0.5034461 ,  0.64708555,  0.4637583 , 30.76876   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.8021293e+00, -6.7061394e-01,  7.8234488e-01,  4.1105603e-03,\n",
       "          2.6634501e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.821759 , -0.6722182,  0.2275345, -4.5524426, 34.30137  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.4014921 ,  0.2318462 ,  0.44875687,  1.8229737 , 16.399529  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.9982748, -0.7957204,  1.2079076,  0.3440801, 24.251625 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.01932   ,  0.2909448 ,  0.11030167,  0.1751814 , 24.87499   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.3169646 , -0.5246873 ,  0.37174186, -0.2953927 , 31.580528  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.0397837,  0.2702703,  0.6338066,  1.7405486, 11.457502 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.7384706 , -0.7371006 ,  0.35615748, -0.84614074, 31.911118  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.9399482 ,  0.09201344,  0.79082894,  0.9306151 , 12.214221  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.4271047, -1.7992164,  1.1898594,  0.6703549, 24.122963 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.520606  ,  0.29647443, -0.28081608, -2.3955755 , 26.85562   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.64574057,  0.02141669,  0.573557  ,  1.5111108 ,  9.841945  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.0682892 ,  0.7547915 ,  0.27201313,  2.7837608 , 12.474324  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.6017459, -1.1825672,  0.9312321,  1.0619769, 23.720963 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.446144 ,  2.1726213, -1.1360894,  1.0387704, 19.147703 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.70436233, -1.2082808 ,  0.9485966 ,  1.0614097 , 24.046577  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.5523267 ,  2.2056844 , -1.1352752 ,  0.79331183, 19.618597  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.7481754,  1.4804661, -0.2139324,  2.5548222, 25.197662 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.56018823,  1.0921241 ,  0.16185631,  2.524296  , 10.615669  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.5062604 , -0.97214806,  0.44993457, -0.8548828 , 30.101492  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.2010255, -1.9164753,  0.9764065,  2.1290574, 28.997864 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-1.4995942 ,  0.64106536,  0.29049766,  1.1335821 ,  4.6933784 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.37229705, 0.03464269, 0.9059768 , 1.4344985 , 9.985415  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.361197 , -1.5014584,  0.7187815,  1.1795435, 30.44876  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.6974735, -1.7792226,  1.0478277,  1.4561429, 25.083258 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9724747, -1.2592261,  1.2730415,  1.8158796, 20.775196 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.9506958, -0.9200193,  0.6314685,  2.6725054, 25.381966 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8187523, -1.0118243,  1.057443 ,  2.1529217, 20.261168 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.0092344, -1.4706196,  0.7226346,  1.7211641, 30.179075 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.5579998, -2.1470222,  1.2781539,  1.0590394, 29.305178 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.8732386, -2.0396898,  1.0327332,  2.3487568, 29.015104 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.8865194, -2.8283353,  1.3264034,  1.2721992, 36.752205 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.6521964, -2.0892603,  1.7355542,  1.0822108, 30.689041 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.0449424 ,  0.12941682,  1.0660249 ,  1.1466938 , 21.08436   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9999102, -1.2160449,  1.1961243,  1.9619372, 20.766249 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.5816545, -1.3239024,  0.7016477,  1.8993813, 27.871416 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.4212866 , -1.6327553 ,  0.66131693,  1.4141238 , 31.96399   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.3166795, -2.0403361,  1.0152856,  2.8522177, 26.29456  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.0818148, -1.904581 ,  1.5450604,  1.1318225, 30.26852  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.534677  , -1.1171839 ,  0.5371346 , -0.97956836, 29.370066  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.3424192, -0.3907452,  1.0404321,  2.1962652, 15.718235 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.400436 , -1.6018909,  0.6631243,  1.5641993, 31.880451 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.08349452, -0.20270406,  0.9077785 ,  1.3451097 , 13.729282  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.7741213, -2.8175423,  1.2332592,  1.9453435, 39.53007  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.2568564, -2.1717997,  1.0144039,  3.0478046, 26.31175  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.077164 , -2.3802955,  1.0813257,  2.5331905, 29.949245 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.1702185, -1.8148981,  0.812003 ,  1.2907671, 34.627083 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.6572280e+00, -5.3479666e-01,  1.1333550e+00,  2.9932975e-03,\n",
       "          2.8950209e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.2604282, -2.2658813,  2.5500293,  0.2608225, 23.084639 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.974084 , -2.3870966,  1.2091527,  1.1107061, 31.55698  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.5008268, -2.1156948,  1.0147238,  2.4880733, 28.092134 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.13656262, -0.17012274,  0.8910383 ,  1.3272429 , 13.742721  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.7389212, -2.3298774,  1.0191088,  2.7489505, 28.499996 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.3471352 ,  0.21295078,  0.6662429 ,  2.5437078 , 17.059978  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.1522529 , -0.19763352,  0.9219093 ,  2.3033276 , 13.024039  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.5554242, -1.7351605,  0.897158 ,  1.4573972, 24.943892 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.55421084, -0.07267433,  1.236897  ,  0.75642043, 10.967912  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.081083 , -1.4471331,  0.7006005,  1.7922162, 29.989351 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.4399432, -1.5229292,  1.404321 ,  0.9693257, 25.370752 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.723856  , -1.1559757 ,  0.65523165, -0.7800026 , 29.35796   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.23736043, -0.36739942,  1.020454  ,  2.4147933 , 15.535213  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.68117976,  0.52725977,  0.6344725 ,  2.495105  , 15.346284  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.1996107 ,  1.7583687 , -0.31759688,  4.629486  , 24.080894  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.1874328, -2.0037425,  1.2036763,  1.1116512, 27.43238  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.396845 , -2.055622 ,  1.2465767,  1.0323098, 28.263838 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.814072 , -1.1943167,  0.5207075, -0.9790535, 29.992012 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.6246476 ,  0.86475223,  0.08980971,  1.7056006 , 12.32772   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.8110352 ,  0.73065805,  0.1377451 ,  1.0584626 , 15.999797  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.1267486 , -1.1939559 ,  0.69534814,  2.7679362 , 26.574919  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.78349  , -1.4004695,  0.6068517,  2.53096  , 29.514786 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.503247 , -1.989357 ,  0.6895247,  2.0098367, 29.80891  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.323688  , -1.8842063 ,  0.67475265,  2.1772323 , 28.168842  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.8679485, -1.5702368,  0.6289985,  2.2355726, 27.323538 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.2897143, -1.2902361,  0.6263676,  2.4893072, 26.936365 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.6941016 ,  0.39217713,  0.60940444,  2.662535  , 14.643045  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.4130936 , -0.25663224,  0.81590855,  0.9751117 , 26.179018  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.4112883,  2.2034667, -2.540504 ,  1.9634825, 30.801552 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.4209466, -1.219317 ,  0.7871176, -0.9357734, 32.88321  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.765811  , -1.0207541 ,  0.6652101 , -0.69320846, 30.148548  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.8637700e+00,  4.7815365e-01, -2.7080500e-02, -1.7569082e+00,\n",
       "          3.1228767e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.71926653, -0.76976216,  1.2791276 ,  1.8978925 , 17.26178   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.054464 ,  0.5708363, -0.0455262, -1.4027673, 32.324593 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.5330963,  1.9777561, -2.3641505,  2.2512414, 30.863567 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.4309096, -1.1678984,  0.7400315, -0.800925 , 32.86705  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.0064044 , -0.18946147,  0.6842667 ,  1.0039278 , 25.62382   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.6336192 ,  1.0865269 , -0.27450863,  3.9441159 , 20.961637  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.63578814, -0.66137826,  1.1909438 ,  2.070363  , 17.410652  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.6571243, -1.2130766,  1.1022236,  1.7216299, 24.064035 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.60531497,  0.8832688 ,  0.45279893,  1.9337718 , 12.860366  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.039228  ,  1.5337285 , -0.48795965,  3.9090607 , 22.550533  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.3295261 ,  0.7461172 , -0.20326594,  3.8146636 , 20.865496  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8491096 ,  1.2989626 , -0.58774537,  3.57543   , 22.37358   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.390549 , -1.0800766,  0.9230215,  3.3143597, 26.630493 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.1073961 , -2.0382404 ,  1.8088111 ,  0.79207695, 26.806322  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.86925673,  0.44182295,  0.7483237 ,  3.128433  , 15.906161  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.9634647 , -1.871367  ,  2.0831425 ,  0.46165287, 28.401134  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.4720795 , -0.7438475 ,  0.86908746,  2.5283506 , 21.366318  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.411587  , -2.95082   ,  3.8377147 ,  0.03513364, 22.333025  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.389455 , -2.8613284,  1.7124816,  1.1842332, 31.284542 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.01043  , -2.1985822,  2.626087 ,  0.5634418, 29.929035 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9131002 , -2.7353213 ,  3.6614559 ,  0.21575923, 20.471643  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.0954227, -1.6267612,  2.4740717,  1.6743639, 23.859049 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.7609184, -2.1100636,  2.5334377,  0.5573796, 28.789541 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.174098 , -2.1768484,  1.4396801,  2.4630027, 30.65228  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.707586 , -2.9006972,  1.8151739,  1.3558763, 33.738003 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8071966 ,  0.20533231,  0.5908686 ,  1.5699909 , 23.72937   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.0835457, -1.8899596,  2.201321 ,  2.4521596, 26.248272 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.6986578, -1.7057694,  2.1106594,  2.62866  , 25.09198  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9157362 , -1.0038221 ,  4.141024  ,  0.11843479, 21.857052  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9403642 , -0.9976163 ,  3.9488184 , -0.14529991, 21.935678  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8387347 , -0.2751527 ,  1.3204916 ,  0.20031852, 18.579727  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.6976223, -1.4418136,  3.9918022,  1.3700012, 26.136053 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.53419274,  0.28549752,  1.2912793 ,  1.9650712 , 17.605133  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9091907, -1.3879914,  2.243872 ,  1.3798567, 15.5715275]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.052821 , -3.0262814,  2.0709286,  1.6401258, 33.478992 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.6360474, -0.7656091,  1.4674959,  1.7916662, 29.066082 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.6292086, -1.9910222,  4.0757647,  0.3609826, 30.632029 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.264786 , -2.304536 ,  3.1511881,  0.51807  , 30.032207 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.5081434 ,  0.06759993,  1.5294149 ,  0.47650123, 20.027784  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.02153318,  0.4004472 ,  2.7128706 ,  0.81948733, 11.485658  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.8364673 , -0.21035764,  1.6716855 ,  0.08409225, 21.861115  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.9065537, -1.1798619,  1.5682302,  2.7123759, 30.792603 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.75262356e+00, -1.07701365e-02,  1.39518988e+00,\n",
       "          5.72805963e-02,  2.06795712e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.7088309, -0.8099648,  3.7353141,  0.6910114, 19.94754  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.0850837e+00, -3.2746860e-01,  1.6981068e+00, -2.1092329e-02,\n",
       "          2.3353424e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.3263187, -1.7016429,  4.007994 ,  0.7491611, 27.409636 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.9929137, -2.4963436,  4.2361617,  0.8537111, 33.8502   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.0076113 , -0.85756975,  4.06001   , -0.24391764, 20.831718  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.928435 , -1.9052429,  3.5371583,  1.8424867, 29.156057 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.8566668, -1.0284147,  3.032659 ,  1.6549954, 17.477621 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.24839668,  0.3345101 ,  1.2913536 ,  1.9482034 ,  6.1969805 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.223196 , -1.8245941,  1.9807832,  2.451067 , 26.583097 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.6952572 , -0.65280783,  2.9625635 ,  1.1024375 , 19.417223  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.7741413, -1.9407034,  2.4055316,  2.600599 , 28.21563  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.1490393, -2.1286945,  2.3494885,  2.42847  , 30.054832 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.19628859,  0.18465868,  2.3035595 ,  1.0515199 , 15.378402  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.9531333, -1.4977541,  1.8612175,  3.213458 , 25.283863 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.2173347 ,  0.43838948,  2.4496849 ,  1.1818032 , 14.729964  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.0946712, -2.1070266,  2.2985663,  2.7099154, 29.735554 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.8739753 , -1.1789364 ,  1.3556436 , -0.46151707, 34.986023  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.8453994, -1.3444048,  1.7462488,  1.9690396, 29.576614 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.907287  , -2.3982444 ,  4.79491   , -0.40699726, 26.312895  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.5048   , -1.7593032,  2.7059793,  1.5196755, 30.190008 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.8585286, -3.6020539,  3.0860844,  2.0578446, 23.033401 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.444064 , -2.303383 ,  2.1906123,  2.530071 , 30.889128 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.6436963, -1.8672048,  1.917319 ,  1.2357768, 29.275354 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.433467 , -1.655446 ,  1.9637902,  1.1573713, 28.160295 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.246694  ,  2.4860108 , -4.405773  , -0.89986485, 28.421541  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.995689 ,  1.4583385, -1.3027098, -5.1178036, 36.13538  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.0009646, -0.9443563,  3.7818637,  1.1760472, 26.247437 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.1558337 , -0.9824899 ,  1.393199  , -0.52709293, 18.87443   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.7725196 , -2.0268824 ,  4.823959  , -0.16439845, 27.126268  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.7079487, -0.7736299,  2.8366005,  1.020618 , 23.133713 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.1022174 , -1.1381443 ,  4.254089  ,  0.25919133, 21.318584  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.5453838 , -0.34201822,  1.2784564 , -0.06570163, 15.430718  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.1477442 , -1.8376412 ,  4.4133925 ,  0.15131786, 22.260479  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.5553172 , -1.3893094 ,  4.5443244 , -0.21482089, 23.701292  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.1535106, -1.2392311,  2.1023755,  2.0337315, 30.812645 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.2932034, -1.8155746,  3.3082964,  2.1361818, 31.095507 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.8663344, -1.0338084,  1.9517007,  1.8874841, 31.65782  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.5756483, -1.6151309,  3.5785348,  1.2186923, 27.81385  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.822674 , -1.9053286,  2.147445 ,  2.2208655, 28.613735 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.60720533, -0.33725095,  2.8756738 ,  1.0625763 , 23.930546  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.0953772 ,  2.0406744 , -2.3966093 ,  0.49034256, 23.419239  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.2880187 , -0.20435119,  0.7490044 , -0.44566986, 22.193375  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.7259316 , -0.37640977,  1.7481046 ,  0.5203855 ,  1.5123013 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 4.5606174 ,  4.5681024 , -3.8490748 , -0.21467459, 27.666634  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.24343632,  0.35213438,  1.4459451 ,  1.1915144 , 11.696431  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.1560795 , -1.4631526 ,  4.527047  ,  0.22607267, 23.083492  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.2987165 , -1.6644138 ,  4.183661  ,  0.36614257, 22.785936  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.15832236,  0.9867649 ,  2.8587909 ,  0.91129214, 13.588318  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8347036 , -1.9041857 ,  4.8193293 ,  0.15900433, 27.54705   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.0139099 ,  0.47923195,  1.1749243 ,  0.67629606, 10.694472  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.34415773,  0.3950314 ,  4.1162977 ,  0.6235448 , 17.288067  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.5129213, -2.8497744,  3.6501634,  1.933035 , 20.653692 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.1728735, -1.8054968,  3.447586 ,  1.6165913, 28.52924  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.4327173, -1.8136578,  3.618376 ,  1.643373 , 29.088593 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.639758 , -0.6382105,  4.8935666,  1.0530773, 33.987698 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.064808 , -2.366584 ,  4.5794797,  1.2331679, 39.76454  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.364853 ,  0.4637237,  7.646512 ,  1.5578318, 33.98562  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.489483  , -0.59949046,  7.097207  ,  1.551049  , 33.843258  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.9166474,  0.4094584,  7.5062695,  1.4641061, 32.010727 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.9153368, -1.2372985,  5.346542 ,  0.9408265, 17.868526 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 9.8068285, -1.6764859,  6.614384 ,  1.8994905, 38.8901   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.3765526 , -0.28112513,  6.095364  ,  1.3688257 , 30.380226  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.501889  ,  0.07323015,  6.132052  ,  1.3288829 , 27.255856  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.0160656 , -0.26376945,  6.09017   ,  1.2820497 , 29.486366  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.236023  , -0.07122406,  6.463413  ,  1.3070422 , 30.090208  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.065659  ,  0.04484305,  6.6241484 ,  1.3313303 , 28.965813  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.785877  ,  0.10674141,  6.217296  ,  1.2528996 , 27.562902  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.337354  , -0.29344723,  7.6990423 ,  1.4284401 , 32.983994  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.6874385,  0.3026176,  7.6248536,  1.3574617, 30.836628 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.930412  ,  0.03485425,  7.457872  ,  1.3111447 , 32.054363  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.170385  , -0.08182084,  7.5283575 ,  1.3106648 , 32.95463   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.0123353 ,  0.82856274,  7.305666  ,  1.417004  , 28.645718  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.2762303,  0.9896403,  7.6996174,  1.492055 , 29.670977 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.7093506 ,  0.71944684,  7.531494  ,  1.4319824 , 31.40169   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.780211 ,  2.0283213,  6.6957855,  1.3608629, 24.483366 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.677915 ,  0.8788751,  7.2013564,  1.4068589, 31.171457 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.886253 ,  0.9073355,  7.3293033,  1.3710699, 31.799595 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.341428 ,  1.1609085,  7.03312  ,  1.3557832, 29.68383  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.77025  ,  0.9473282,  7.6842613,  1.4663385, 34.787453 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 9.815646  ,  0.44177228,  8.050581  ,  1.6148506 , 38.320827  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.209388 ,  1.6664826,  7.038819 ,  1.2939818, 28.819614 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.262237 ,  1.6984694,  7.710081 ,  1.4892727, 32.789944 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.264286  , -0.07499361,  6.6567225 ,  1.3688745 , 30.111544  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.033633 ,  0.8920656,  6.4059105,  1.2666578, 24.729021 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.062008  , -0.38317183,  7.4021635 ,  1.4083635 , 32.028152  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.567345  , -0.10412133,  7.7666516 ,  1.4916275 , 34.305183  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.239599  ,  0.44492596,  7.0445905 ,  1.3898532 , 29.872429  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.729049 ,  1.2238872,  7.2252946,  1.3953269, 27.887829 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.7104993,  0.8268934,  7.3300304,  1.4337267, 31.428951 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.162452 ,  1.4990901,  7.4701166,  1.3515645, 28.892853 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.302924  ,  0.99590415,  7.4597497 ,  1.4282751 , 33.24233   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.2172694, -0.2741845,  5.9044   ,  1.3685373, 29.8525   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.7218    , -0.51797354,  6.3713093 ,  1.4373155 , 32.33208   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.7148194, -0.383938 ,  6.80393  ,  1.3945379, 30.716637 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.470239  , -0.23056841,  6.712986  ,  1.2930533 , 29.837217  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.8224854 ,  0.65143365,  7.787285  ,  1.4700127 , 31.314941  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.6663947,  1.1623919,  6.9684772,  1.317003 , 27.146093 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.851514 ,  1.5992445,  7.5415545,  1.4078934, 31.228855 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 9.743351 , -1.8438597,  6.428854 ,  1.8984531, 38.74966  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.6641145, -0.2880562,  6.739072 ,  1.4049684, 30.678434 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.8523116 ,  0.22503795,  6.7324867 ,  1.2730408 , 27.74002   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.578531  , -0.20276198,  6.8845243 ,  1.3416313 , 30.335598  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[8.1151514e+00, 6.4529199e-03, 7.5971622e+00, 1.3985296e+00,\n",
       "         3.2409576e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.288367  ,  0.24051915,  7.940265  ,  1.4966894 , 33.430096  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.280002 ,  0.3166383,  7.853731 ,  1.5622934, 33.411633 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.6409082,  1.1386024,  6.977413 ,  1.3368169, 27.138681 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.8501654,  1.5879047,  7.7029905,  1.4113955, 31.318764 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.542391 ,  0.2321287,  7.990674 ,  1.5038843, 30.344769 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.172726  , -0.99458563,  6.2136164 ,  1.3493028 , 33.060368  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.80943  , -1.0651507,  6.7292094,  1.6181228, 35.24969  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.42329   , -0.35717085,  6.4187565 ,  1.3312521 , 30.269709  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.256543 , -0.1997348,  6.416819 ,  1.3278781, 29.69073  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[7.0650434e+00, 2.8066099e-02, 6.5583596e+00, 1.2671933e+00,\n",
       "         2.8987707e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.180935 , -0.5215934,  7.0603285,  1.479156 , 32.494995 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.678319  ,  0.09786227,  7.6369395 ,  1.234485  , 30.64294   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.01752   ,  0.07928837,  8.17921   ,  1.5560997 , 32.171696  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.02704  ,  1.246352 ,  7.095717 ,  1.2911196, 24.803442 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.3700514 ,  0.63124174,  7.9605775 ,  1.4086567 , 29.91623   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.968635  ,  0.13125828,  8.069803  ,  1.4503527 , 32.593723  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.4903646 ,  0.80359286,  7.9043026 ,  1.4199705 , 30.766403  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.0678687,  1.4237787,  7.7201996,  1.4425174, 29.991964 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.311171 ,  0.6843033,  7.9571643,  1.4891939, 34.39609  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[10.322561 , -0.6137478,  8.201081 ,  1.914949 , 42.151066 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.26039  , -2.3785124,  6.7802286,  0.6941141, 24.528584 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.431703 ,  0.5542508,  7.9147544,  1.4039944, 33.94329  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.5612307,  1.532484 ,  7.840314 ,  1.3841966, 30.96132  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.6646767,  1.465346 ,  7.770728 ,  1.3791908, 31.12995  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.517076 ,  1.9876475,  6.682417 ,  1.273167 , 24.366508 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.8391533 , -0.23205054,  6.0146    ,  1.2686228 , 28.512718  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.89611   , -0.14120315,  6.1523743 ,  1.2496693 , 28.825666  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.321751  , -0.48187935,  7.2649093 ,  1.4646194 , 33.51819   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.3557973,  0.7146713,  6.7216744,  1.338494 , 26.358788 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.635193  ,  0.20306517,  7.423478  ,  1.4015104 , 31.060184  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.327295  ,  0.34361854,  7.393024  ,  1.2399727 , 29.286978  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.5326138 ,  0.20263714,  7.87935   ,  1.4522843 , 30.124884  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.9943295,  0.6270264,  7.8217664,  1.4415976, 28.756021 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.4583406,  1.4643061,  7.8464127,  1.3565662, 27.852524 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 5.536917 ,  1.9648783,  6.6613264,  1.2578791, 24.449158 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.607547 ,  1.1608843,  7.9485526,  1.3223166, 31.924864 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.1114063,  1.4054472,  7.6020775,  1.3014714, 30.14353  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.605079 ,  1.2124003,  8.188133 ,  1.4908825, 35.148563 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.8347106 , -0.27964735,  6.9310737 ,  1.4917696 , 31.765917  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.8822103, -0.2818058,  6.994607 ,  1.4919541, 31.925064 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.3662453 ,  0.32212153,  7.370384  ,  1.2304422 , 29.334885  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.679517 , -0.2659032,  8.699938 ,  1.6684934, 34.908752 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.240165  , -0.23237391,  6.36474   ,  1.3169584 , 29.681501  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.8965855, -0.1113475,  6.3062644,  1.3002144, 28.340372 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.757226 , -0.4076888,  6.829307 ,  1.4190092, 31.558178 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.7479143, -0.3355614,  6.8091555,  1.404858 , 31.567509 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.26767   ,  0.23827758,  7.3146873 ,  1.4351516 , 29.430225  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 9.554586  , -0.92403203,  8.094918  ,  1.5770051 , 37.579124  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.080529 ,  0.6233501,  7.554336 ,  1.4233   , 28.682693 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.719071 ,  0.7685055,  7.357379 ,  1.3826964, 27.176168 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[8.2618761e+00, 3.0551421e-02, 8.3961735e+00, 1.6348290e+00,\n",
       "         3.4075630e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.282113  ,  0.46843398,  8.312051  ,  1.3741356 , 29.825785  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.158363 ,  0.6655333,  8.1328125,  1.3857224, 29.759928 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.571612 ,  0.5684182,  7.861045 ,  1.31435  , 29.522291 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.8669677,  1.3657856,  7.654814 ,  1.3383969, 32.97068  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.8310695 , -0.47602367,  6.793145  ,  1.4582925 , 32.19963   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.5665464 ,  0.18144628,  7.5805764 ,  1.311941  , 30.100948  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.9885144e+00, -2.6984565e-02,  7.9266953e+00,  1.4593832e+00,\n",
       "          3.2280212e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.5594134 ,  0.87554604,  7.844898  ,  1.2779553 , 32.535767  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.5485826,  1.4328984,  8.135758 ,  1.3451859, 31.92785  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.106395  , -0.80587333,  6.759765  ,  1.4445634 , 32.78785   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 9.67881  , -1.8728851,  7.066663 ,  1.8792132, 39.067036 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.20211  , -0.5573906,  6.9045234,  1.6043488, 33.664814 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.9250503 , -0.5640872 ,  6.9984217 ,  0.99762726, 33.57896   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.5219665 , -0.05807539,  7.097377  ,  1.4522568 , 30.630705  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.734657 ,  0.4295928,  6.7726154,  1.389522 , 28.055477 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.2898655 ,  0.81219345,  6.7350893 ,  1.3939018 , 26.654213  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[7.9425006e+00, 1.9945279e-02, 7.8841639e+00, 1.3763455e+00,\n",
       "         3.1687967e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.0084815,  0.6269226,  7.523268 ,  1.40046  , 28.551294 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.48008   ,  0.94153535,  7.537911  ,  1.3280785 , 27.076109  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.439902  , -0.17283738,  8.446184  ,  1.5696862 , 34.32206   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.0472   ,  0.8708291,  8.266605 ,  1.4305784, 29.239794 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.020856  ,  0.83491266,  8.2566    ,  1.3093511 , 29.034084  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.728044 ,  0.9360642,  8.273471 ,  1.3059508, 28.89202  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.1045766,  0.7780711,  8.108691 ,  1.2373663, 30.092333 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.5699286 ,  0.94352084,  8.260736  ,  1.371277  , 31.85022   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.386839 ,  2.1199353,  7.65432  ,  1.3136163, 27.787785 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.2636805 ,  0.13204132,  6.821322  ,  1.3993219 , 30.098354  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.961592  ,  0.10366684,  8.410977  ,  1.4377704 , 31.96774   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.693701  ,  0.16354074,  8.452942  ,  1.3755149 , 31.717215  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.392635  ,  0.68414515,  8.304178  ,  1.2682703 , 31.060165  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.123427 ,  1.0624491,  8.501668 ,  1.2834046, 29.750387 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.9586515,  1.5205951,  7.87255  ,  1.3138483, 29.864933 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.5356727,  1.6560208,  7.9808187,  1.3975463, 32.28821  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.6395044 , -0.39645976,  6.610525  ,  1.4819417 , 32.22141   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.8337755,  0.3509318,  6.7386866,  1.394481 , 28.685827 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.469086  ,  0.10337199,  7.35844   ,  1.5345294 , 30.616604  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.5254350e+00, -1.5530768e-02,  7.3429475e+00,  1.5283029e+00,\n",
       "          3.0935108e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.1921263 ,  0.13183554,  7.03751   ,  1.4800116 , 29.975464  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.63465   ,  0.22518852,  7.9472165 ,  1.4532619 , 31.687187  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.7427716 , -0.11903518,  7.828716  ,  1.4686815 , 31.68761   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.9407873 ,  0.43194366,  7.7007704 ,  1.4561893 , 29.713715  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.1901536 ,  0.49876833,  7.971029  ,  1.4941559 , 30.313152  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.9109063 , -0.14716604,  8.074043  ,  1.3810498 , 32.237064  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.7614293 ,  0.20926814,  8.699821  ,  1.4481355 , 31.852123  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.9290442,  0.7007593,  8.506224 ,  1.3346478, 29.400118 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.9104195,  1.4188435,  7.954103 ,  1.3582348, 29.515179 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.129459 ,  1.1067234,  8.344727 ,  1.4520829, 34.09245  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.375683  ,  0.76873523,  8.118151  ,  1.4186058 , 35.42327   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.599812 ,  0.5859406,  8.091325 ,  1.5341569, 36.127426 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.4475083 ,  0.17089875,  7.306341  ,  1.5394866 , 30.661219  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.510468 ,  0.0543563,  7.2913327,  1.5337274, 31.001379 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.1355224,  0.0933679,  6.952929 ,  1.4287696, 29.868902 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.4495726 , -0.33957583,  6.9255    ,  1.3765733 , 30.817394  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.6918364 ,  0.06692829,  7.9443913 ,  1.4275343 , 31.590443  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.2284613 ,  0.30852735,  7.8673334 ,  1.4078938 , 29.980022  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.6215906,  0.2873932,  8.820765 ,  1.5154561, 32.200035 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[10.239328 , -0.8963696,  8.919815 ,  1.8598228, 42.083015 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.483262 ,  0.6547388,  8.206392 ,  1.4548129, 35.67524  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.4755187 , -0.07559285,  6.736564  ,  1.4668031 , 31.741665  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.200622  ,  0.22044738,  7.031031  ,  1.4382852 , 30.255844  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.801989 ,  0.5874232,  7.9269733,  1.3477347, 28.282658 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.1106443,  1.0258011,  7.8889217,  1.3241102, 26.82427  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.559485  , -0.08970405,  8.286611  ,  1.3814149 , 32.053677  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.4373970e+00, -2.7343262e-02,  8.5015202e+00,  1.3408463e+00,\n",
       "          3.1347677e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.622116  ,  0.70932347,  8.218795  ,  1.3483537 , 32.617104  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.3394637 , -0.13595548,  6.815611  ,  1.3677635 , 30.825447  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.698697 , -0.5959606,  8.950237 ,  1.6436031, 35.669857 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.7807264 ,  0.56333095,  8.990788  ,  1.5721817 , 33.407333  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.6518183 ,  0.89768064,  7.870032  ,  1.3844436 , 33.029617  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.873674  ,  0.16169031,  6.586517  ,  1.4357599 , 29.47152   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.1317315 ,  0.31208137,  8.2975855 ,  1.3764786 , 29.681175  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.09375  ,  1.3168756,  8.114555 ,  1.2423089, 26.579943 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.845174  ,  0.21027312,  8.935637  ,  1.5685468 , 33.14501   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.0263953 ,  0.44128004,  8.477622  ,  1.3892028 , 30.017473  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.4128175 , -0.36528164,  6.562614  ,  1.4619397 , 31.634653  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.8376436 ,  0.35508275,  6.8642282 ,  1.3729339 , 29.086306  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.4894395 , -0.07711812,  8.155527  ,  1.4529331 , 31.754923  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.589839  ,  0.29733726,  8.894905  ,  1.4003464 , 31.435844  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.170163  ,  0.84622335,  7.229344  ,  1.3332219 , 27.772606  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.9994807 , -0.57806325,  8.059269  ,  1.4371637 , 33.472054  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.863374 , -1.5034939,  7.4589634,  1.7322874, 36.709393 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.0488877,  0.470314 ,  8.483893 ,  1.3583351, 29.932209 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.658388  , -0.06973433,  8.785358  ,  1.5136387 , 32.257812  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.5672374 ,  0.76408696,  8.413411  ,  1.3094951 , 27.857828  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.2889514 ,  0.43962   ,  9.634836  ,  0.97031176, 33.41628   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.192714 ,  0.8716797,  8.760955 ,  1.3490235, 30.449202 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.8973174 , -0.18048644,  6.614177  ,  1.3925934 , 29.660215  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.780905  ,  0.33691075,  7.203505  ,  1.3363702 , 28.55614   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.572786 , -0.2910227,  7.457815 ,  1.3948851, 32.367058 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.04602   ,  0.30347073,  7.9178414 ,  1.3358287 , 29.665276  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.0461383,  0.5685907,  8.629487 ,  1.3625873, 29.419754 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.0851374 ,  0.39462957,  8.5913515 ,  1.3509079 , 30.10384   ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 8.28726   , -0.13032457,  9.436387  ,  1.4332348 , 34.624535  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.9192307, -1.6595085,  5.7400646,  0.6211158, 18.671465 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 7.293235  ,  0.43487668,  8.882338  ,  1.4062543 , 30.424482  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[8.0934715e+00, 2.0196293e-02, 8.9418421e+00, 1.5079491e+00,\n",
       "         3.4497017e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 6.730676  ,  0.09224748,  7.3479095 ,  1.3674167 , 29.168201  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.45358318,  0.01182248, -0.00087566,  0.52745736,  0.675938  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 3.7023753e-01,  1.4990519e-02, -3.9551751e-04,  5.4703516e-01,\n",
       "          6.5927333e-01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.87672293, 0.03211761, 0.31077868, 1.4075879 , 0.9461192 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9570348 , -0.06278791,  0.35550037,  0.11785076,  2.4918857 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8188117 , -0.01895591,  0.03022095, -0.16753319,  3.5962036 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.88212866, -0.10998494,  1.4600189 ,  0.5964375 ,  3.0487504 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.42997104,  0.4860821 ,  0.38000828,  1.1372927 , -0.17468953]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.0547991 , -0.8622067 ,  2.3911235 , -0.64427215,  6.2750635 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.6450499 , 0.5341184 , 0.922608  , 0.49922562, 1.9704642 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.31864974, 0.82523984, 0.421676  , 1.0256014 , 1.2337211 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.435638  ,  0.7905091 ,  0.3565377 , -0.02259968,  2.7041967 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.7188456 , -0.2565759 ,  1.9628247 ,  0.21695615,  1.0249796 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.10610075, 0.15963294, 1.5160873 , 0.93395805, 6.110397  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.5410173, -0.4337437,  1.6151133, -0.4404577,  1.9980505]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.0972176 ,  1.3929532 , -0.61731833, -0.33429042,  2.599574  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.5934091 , 0.03790657, 1.5379292 , 0.69873804, 2.156538  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.4483398 , -0.57194805,  1.7118492 , -0.46634084,  2.2743635 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[1.772629  , 0.5188604 , 1.8418812 , 0.14123602, 1.8685031 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9145167 ,  0.02056089,  1.8060603 , -0.01160914,  1.9314897 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.6227442 ,  2.003629  ,  3.274681  , -0.49638805,  1.6556704 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.6567665 ,  1.3722873 ,  1.9561319 , -0.43627894,  2.2354593 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.172194  ,  0.9296271 ,  1.7893752 , -0.38152528,  4.525963  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.23994818,  1.8232512 ,  3.1908803 , -0.55689806,  1.2123708 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9494033,  1.3259296,  2.2259326, -0.4993535,  2.7354715]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8982947,  1.3508613,  2.2963004, -0.6343817,  2.6492572]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.8889072 ,  0.7731322 ,  2.1750655 , -0.48366556,  5.3236647 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.433295  ,  0.48503745,  1.9106212 , -0.13681337,  4.165525  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8926191 ,  1.1686839 ,  1.8371378 , -0.38715392,  2.3559828 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.6454718 ,  1.5647154 ,  1.9332622 , -0.42787075,  2.244363  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.24899814,  1.9621089 ,  3.122105  , -0.60851336,  1.232544  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9262645,  1.3753119,  2.2031097, -0.5169052,  2.7083187]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.7980976,  1.4649603,  2.1986268, -0.6402848,  2.8658714]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.48015273,  1.8378464 ,  2.994476  , -0.5594265 ,  1.1917373 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.6579511,  1.6426333,  2.4448824, -0.6849272,  2.4102793]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8776107 ,  1.2331893 ,  1.6798695 , -0.50708383,  3.353545  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.2562714,  1.2903986,  2.4574292, -0.5250494,  2.7903826]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.1247538,  2.0296047,  2.9535356, -0.5423727,  1.0319848]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 2.0160608 ,  2.268383  ,  1.5240074 , -0.31365725,  3.3414195 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.4520994 ,  1.9936863 ,  2.1144981 , -0.60720104,  1.9573789 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.6574018,  1.9130574,  1.9240477, -0.4774133,  2.6276128]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.9350641 ,  2.2536907 ,  1.5196195 , -0.32158455,  3.3309236 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.8516661,  1.9631865,  2.6884122, -0.6386023,  1.6026495]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.5590866,  1.6890059,  2.4577322, -0.773399 ,  1.6916137]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.5181503 ,  1.8676039 ,  2.1561985 , -0.60866433,  2.7979228 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.6909585 ,  1.2051508 ,  1.6385895 , -0.70587397,  2.5690262 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.708072  ,  1.2852616 ,  1.6542206 , -0.69797724,  2.5572839 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.647752  ,  2.3365343 ,  1.9154589 , -0.69355464,  3.0463722 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 1.8572652 ,  1.962903  ,  1.7618771 , -0.06485223,  4.1590576 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[0.2528607 , 0.01304664, 0.        , 1.1479741 , 5.4430127 ]],\n",
       "       dtype=float32)>,\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_results['ig_numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_numeric = loaded_results['ig_numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure ig_numeric is a NumPy array first\n",
    "ig_array = np.array(ig_numeric)\n",
    "\n",
    "# Reduce over axis 0 (samples) → shape: (5,)\n",
    "mean_ig = np.mean(ig_array, axis=0)\n",
    "\n",
    "# Squeeze in case it's accidentally 2D like (5, 1) or (1, 5)\n",
    "mean_ig = np.squeeze(mean_ig)\n",
    "\n",
    "# Ensure it's 1D and contains native floats\n",
    "mean_ig = mean_ig.astype(float)\n",
    "\n",
    "# Plot bar chart\n",
    "plt.bar(range(len(mean_ig)), mean_ig)\n",
    "plt.xticks(range(len(mean_ig)), [f'Feature {i+1}' for i in range(len(mean_ig))])\n",
    "plt.ylabel('Mean IG Attribution')\n",
    "plt.title('Mean Integrated Gradients per Feature')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mig_numeric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitur numerik ke-i\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKontribusi via IG\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kalea\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\matplotlib\\pyplot.py:2956\u001b[0m, in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mbar)\n\u001b[0;32m   2946\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar\u001b[39m(\n\u001b[0;32m   2947\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BarContainer:\n\u001b[1;32m-> 2956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mbar(\n\u001b[0;32m   2957\u001b[0m         x,\n\u001b[0;32m   2958\u001b[0m         height,\n\u001b[0;32m   2959\u001b[0m         width\u001b[38;5;241m=\u001b[39mwidth,\n\u001b[0;32m   2960\u001b[0m         bottom\u001b[38;5;241m=\u001b[39mbottom,\n\u001b[0;32m   2961\u001b[0m         align\u001b[38;5;241m=\u001b[39malign,\n\u001b[0;32m   2962\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   2963\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2964\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kalea\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\matplotlib\\__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[0;32m   1474\u001b[0m             ax,\n\u001b[0;32m   1475\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args),\n\u001b[0;32m   1476\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: sanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[0;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\Kalea\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\matplotlib\\axes\\_axes.py:2583\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2580\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(left, bottom, width, height, color, edgecolor, linewidth,\n\u001b[0;32m   2581\u001b[0m            hatch, patch_labels)\n\u001b[0;32m   2582\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l, b, w, h, c, e, lw, htch, lbl \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[1;32m-> 2583\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmpatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRectangle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2586\u001b[0m \u001b[43m        \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlbl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhtch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2590\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2591\u001b[0m     r\u001b[38;5;241m.\u001b[39m_internal_update(kwargs)\n\u001b[0;32m   2592\u001b[0m     r\u001b[38;5;241m.\u001b[39mget_path()\u001b[38;5;241m.\u001b[39m_interpolation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Kalea\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\matplotlib\\patches.py:762\u001b[0m, in \u001b[0;36mRectangle.__init__\u001b[1;34m(self, xy, width, height, angle, rotation_point, **kwargs)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;129m@_docstring\u001b[39m\u001b[38;5;241m.\u001b[39mdedent_interpd\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xy, width, height, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    740\u001b[0m              angle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, rotation_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    741\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;124;03m        %(Patch:kwdoc)s\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 762\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x0 \u001b[38;5;241m=\u001b[39m xy[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y0 \u001b[38;5;241m=\u001b[39m xy[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Kalea\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\matplotlib\\patches.py:91\u001b[0m, in \u001b[0;36mPatch.__init__\u001b[1;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dash_pattern \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# offset, dash (scaled by linewidth)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_linestyle(linestyle)\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_linewidth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_antialiased(antialiased)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_hatch(hatch)\n",
      "File \u001b[1;32mc:\\Users\\Kalea\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\matplotlib\\patches.py:438\u001b[0m, in \u001b[0;36mPatch.set_linewidth\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m     w \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch.linewidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linewidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dash_pattern \u001b[38;5;241m=\u001b[39m mlines\u001b[38;5;241m.\u001b[39m_scale_dashes(\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unscaled_dash_pattern, w)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(5), loaded_results['ig_numeric'])\n",
    "plt.xlabel(\"Fitur numerik ke-i\")\n",
    "plt.ylabel(\"Kontribusi via IG\")\n",
    "plt.title(\"Sensitivitas Fitur Numerik\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Hitung skor kontribusi per token (agg dimensi embedding)\n",
    "token_contributions = tf.reduce_mean(tf.abs(ig_text[0]), axis=-1).numpy()  # shape (1024,)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(token_contributions)), token_contributions)\n",
    "plt.xlabel(\"Token ke-i\")\n",
    "plt.ylabel(\"Kontribusi rata-rata (|IG|)\")\n",
    "plt.title(\"Kontribusi Integrated Gradients per token (agregasi mean(abs))\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Konversi ke token string\n",
    "tokens = tokenizer.sequences_to_texts(sample_text_int.numpy())[0].split()\n",
    "tokens = [tokenizer.index_word.get(id, '[UNK]') for id in ASAZ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung kontribusi rata-rata per token\n",
    "token_contributions = tf.reduce_mean(tf.abs(ig_text[0]), axis=-1).numpy()\n",
    "\n",
    "# Pangkas padding \n",
    "valid_tokens = [(t, c) for t, c in zip(tokens, token_contributions) if t != '[PAD]']\n",
    "tokens_filtered, contribs_filtered = zip(*valid_tokens)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(min(0.4 * len(tokens_filtered), 20), 4))\n",
    "plt.bar(range(len(contribs_filtered)), contribs_filtered)\n",
    "plt.xticks(range(len(tokens_filtered)), tokens_filtered, rotation=90)\n",
    "plt.xlabel(\"Token\")\n",
    "plt.ylabel(\"Kontribusi rata-rata (|IG|)\")\n",
    "plt.title(\"Kontribusi IG per token\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buang padding (misal id=0 dianggap padding)\n",
    "filtered = [(t, c) for t, c in zip(tokens, token_contributions) if t != '[PAD]']\n",
    "\n",
    "# Ambil 20 token dengan kontribusi terbesar\n",
    "top_tokens = sorted(filtered, key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "# Pisahkan kembali token dan kontribusinya\n",
    "tokens_top, contribs_top = zip(*top_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(contribs_top)), contribs_top)\n",
    "plt.xticks(range(len(tokens_top)), tokens_top, rotation=45, ha='right')\n",
    "plt.xlabel(\"Token\")\n",
    "plt.ylabel(\"Kontribusi rata-rata (|IG|)\")\n",
    "plt.title(\"20 Token Paling Berpengaruh menurut Integrated Gradients\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
